{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"YTsVWwCgLAJl"},"source":["Fine-tuning best T5 Transformer ü§ñ\n","-----------------------------------\n","\n","In this notebook, we will continue the fine-tuning of T5 transformer on the sentences got from the book `Grammaire de Wolof Moderne` by Pathe Diagne additionally to the sentences got from `Wolof version of L'Africain` by Daouda Ndiaye. We provide, bellow, the main evaluation figures, obtained from the hyperparameter search step. We will evaluate the training on the validation dataset.\n","\n","- Parallel coordinates from panel:\n","\n","- Parameter importance char: \n","[t5_v3_importance](https://wandb.ai/oumar-kane-team/small-t5-cross-fw-translation-bayes-hpsearch-v3/reports/undefined-23-05-16-10-36-17---Vmlldzo0Mzc4NDY0?accessToken=eyaiyrid0qz1zg2jkq3fc65biw53084dpfitbi0dgonq6mweupw6kgjml9d2nv1w)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We can see in the above chart that the batch is the most important parameter with a negative correlation with the BLEU score (meaning that a lower batch size is better). Next, we the probability of modifying a character in the french corpus is also important and a high probability provide a better BLEU score.  "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41798,"status":"ok","timestamp":1683491387892,"user":{"displayName":"Oumar Kane","userId":"05889582343301699661"},"user_tz":0},"id":"dF37F8_nLAJr","outputId":"7f5f2bed-9b9d-49f9-c8f1-6fe427cf1502"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# let us import all necessary libraries\n","from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, T5TokenizerFast, set_seed, AdamW, get_linear_schedule_with_warmup, T5ForConditionalGeneration,\\\n","    get_cosine_schedule_with_warmup, Adafactor\n","from wolof_translate.utils.sent_transformers import TransformerSequences\n","from torch.nn import TransformerEncoderLayer, TransformerDecoderLayer\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from wolof_translate.data.dataset_v3 import SentenceDataset\n","from wolof_translate.utils.sent_corrections import *\n","from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import _LRScheduler\n","# from custom_rnn.utils.kwargs import Kwargs\n","from torch.nn.utils.rnn import pad_sequence\n","from plotly.subplots import make_subplots\n","from nlpaug.augmenter import char as nac\n","from torch.utils.data import DataLoader\n","# from datasets  import load_metric # make pip install evaluate instead\n","# and pip install sacrebleu for instance\n","from torch.nn import functional as F\n","import plotly.graph_objects as go\n","from tokenizers import Tokenizer\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm, trange\n","from functools import partial\n","from torch.nn import utils\n","from copy import deepcopy\n","from torch import optim\n","from typing import *\n","from torch import nn\n","import pandas as pd\n","import numpy as np\n","import itertools\n","import evaluate\n","import random\n","import string\n","import shutil\n","import wandb\n","import torch\n","import json\n","import copy\n","import os\n","\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"19MVywzSLAJt"},"source":["## French to wolof"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"n4tP0YGyLAJt"},"source":["### Configure dataset üî†"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":77,"status":"ok","timestamp":1683491387893,"user":{"displayName":"Oumar Kane","userId":"05889582343301699661"},"user_tz":0},"id":"t2GR0YjYuLc5"},"outputs":[],"source":["# recuperate the tokenizer from a json file\n","tokenizer = T5TokenizerFast(tokenizer_file=f\"wolof-translate/wolof_translate/tokenizers/t5_tokenizers/tokenizer_v4.json\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":77,"status":"ok","timestamp":1683491387894,"user":{"displayName":"Oumar Kane","userId":"05889582343301699661"},"user_tz":0},"id":"BIjksuH9LAJv"},"outputs":[],"source":["def recuperate_datasets(fr_char_p: float, fr_word_p: float, max_len: int):\n","\n","  # Create augmentation to add on French sentences\n","  fr_augmentation = TransformerSequences(nac.KeyboardAug(aug_char_p=fr_char_p, aug_word_p=fr_word_p,\n","                                                         aug_word_max= max_len),\n","                                        remove_mark_space, delete_guillemet_space)\n","\n","  # Recuperate the train dataset\n","  train_dataset_aug = SentenceDataset(f\"data/extractions/new_data/train_set.csv\", max_len = max_len,\n","                                        tokenizer = tokenizer,\n","                                        truncation = True,\n","                                        cp1_transformer = fr_augmentation)\n","\n","  # Recuperate the validation dataset\n","  valid_dataset = SentenceDataset(f\"data/extractions/new_data/valid_set.csv\", max_len = max_len,\n","                                        tokenizer = tokenizer,\n","                                        truncation = True)\n","  \n","  # Return the datasets\n","  return train_dataset_aug, valid_dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0vhzP3IaLAJv"},"source":["### Configure the model and the evaluation function ‚öôÔ∏è"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"R8I3tm4WLAJx"},"source":["Let us evaluate the predictions with the `bleu` metric."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":75,"status":"ok","timestamp":1683491387894,"user":{"displayName":"Oumar Kane","userId":"05889582343301699661"},"user_tz":0},"id":"IerZolDNLAJx"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting wolof-translate/wolof_translate/utils/evaluation.py\n"]}],"source":["%%writefile wolof-translate/wolof_translate/utils/evaluation.py\n","from tokenizers import Tokenizer\n","from typing import *\n","import numpy as np\n","import evaluate\n","\n","class TranslationEvaluation:\n","    \n","    def __init__(self, \n","                 tokenizer: Tokenizer,\n","                 decoder: Union[Callable, None] = None,\n","                 metric = evaluate.load('sacrebleu'),\n","                 ):\n","        \n","        self.tokenizer = tokenizer\n","        \n","        self.decoder = decoder\n","        \n","        self.metric = metric\n","    \n","    def postprocess_text(self, preds, labels):\n","        \n","        preds = [pred.strip() for pred in preds]\n","        \n","        labels = [[label.strip()] for label in labels]\n","        \n","        return preds, labels\n","\n","    def compute_metrics(self, eval_preds):\n","\n","        preds, labels = eval_preds\n","\n","        if isinstance(preds, tuple):\n","        \n","            preds = preds[0]\n","        \n","        decoded_preds = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","        labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n","        \n","        decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","        decoded_preds, decoded_labels = self.postprocess_text(decoded_preds, decoded_labels)\n","\n","        result = self.metric.compute(predictions=decoded_preds, references=decoded_labels)\n","        \n","        result = {\"bleu\": result[\"score\"]}\n","\n","        prediction_lens = [np.count_nonzero(pred != self.tokenizer.pad_token_id) for pred in preds]\n","        \n","        result[\"gen_len\"] = np.mean(prediction_lens)\n","        \n","        result = {k: round(v, 4) for k, v in result.items()}\n","        \n","        return result"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IuppKYiyLAJx"},"source":["Let us initialize the evaluation object."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":74,"status":"ok","timestamp":1683491387896,"user":{"displayName":"Oumar Kane","userId":"05889582343301699661"},"user_tz":0},"id":"a7Bpd4UPLAJy"},"outputs":[],"source":["%run wolof-translate/wolof_translate/utils/evaluation.py\n","evaluation = TranslationEvaluation(tokenizer)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xT17hB19LAJy"},"source":["### Searching for the best parameters üïñ"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from wolof_translate.models.transformers.optimization import TransformerScheduler\n","from wolof_translate.trainers.transformer_trainer import ModelRunner\n","from wolof_translate.utils.evaluation import TranslationEvaluation\n","from wolof_translate.models.transformers.main import Transformer\n","from wolof_translate.utils.split_with_valid import split_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["-------------"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ---"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# let us initialize the hyperparameter configuration\n","config = {\n","    'random_state': 0,\n","    'fr_char_p': 0.33865575033761214,\n","    'fr_word_p': 0.1215427458724321,\n","    'learning_rate': 0.009397216172457796,\n","    'weight_decay': 0.036296976653260773,\n","    'batch_size': 16,\n","    'warmup_ratio': 0.0,\n","    'max_epoch': 1175,\n","    'max_len': 104,\n","    'bleu': 0.5746,\n","    'model_dir': 'data/checkpoints/fw_t5_small_custom_train_v4_checkpoints/',\n","    'new_model_dir': 'data/checkpoints/t5_small_custom_train_results_fw_v4/'\n","}\n","\n","# Initialize the model name\n","model_name = 't5-small'\n","\n","# import the model with its pre-trained weights\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","# resize the token embeddings\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# let us initialize the evaluation class\n","evaluation = TranslationEvaluation(tokenizer)\n","\n","# let us initialize the trainer\n","trainer = ModelRunner(model, seed = 0, version = 1, evaluation = evaluation, optimizer=Adafactor)\n","\n","# split the data\n","split_data(config['random_state'], csv_file=\"corpora_v4.csv\")\n","\n","# recuperate train and test set\n","train_dataset, test_dataset = recuperate_datasets(config['fr_char_p'], \n","                                                    config['fr_word_p'],\n","                                                    max_len=config['max_len'])\n","\n","# let us calculate the appropriate warmup steps (let us take a max epoch of 100)\n","length = len(train_dataset)\n","\n","n_steps = length // config['batch_size']\n","\n","num_steps = config['max_epoch'] * n_steps\n","\n","warmup_steps = (config['max_epoch'] * n_steps) * config['warmup_ratio']\n","\n","# Initialize the scheduler parameters\n","scheduler_args = {'num_warmup_steps': warmup_steps, 'num_training_steps': num_steps}\n","\n","# Initialize the optimizer parameters\n","optimizer_args = {\n","    'lr': config['learning_rate'],\n","    'weight_decay': config['weight_decay'],\n","    # 'betas': (0.9, 0.98),\n","    'relative_step': False\n","}\n","\n","# Initialize the loaders parameters\n","train_loader_args = {'batch_size': config['batch_size']}\n","\n","# Add the datasets and hyperparameters to trainer\n","trainer.compile(train_dataset, test_dataset, tokenizer, train_loader_args,\n","                optimizer_kwargs = optimizer_args,\n","                lr_scheduler=get_linear_schedule_with_warmup,\n","                lr_scheduler_kwargs=scheduler_args, \n","                predict_with_generate = True,\n","                hugging_face = True,\n","                logging_dir=\"data/logs/t5_small_custom_train_fw_v4\"\n","                )\n","\n","# We will from checkpoints so let us the model\n","trainer.load(config['model_dir'], load_best=True) # Only for the first loading\n","# trainer.load(config['new_model_dir'])\n","\n","        "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1172 [00:00<?, ?it/s]c:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:257: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"]},{"name":"stdout","output_type":"stream","text":["For epoch 4: {Learning rate: [0.009373032860321989]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:57<00:00,  2.22batches/s]\n","Test batch number 1:   0%|          | 0/15 [00:00<?, ?batches/s]c:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.65batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.6396655408650871, 'test_loss': 0.8404125978549322, 'bleu': 0.6164, 'gen_len': 12.0844}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 1/1172 [01:11<23:22:31, 71.86s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 5: {Learning rate: [0.009364971756276718]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.32batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.87batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.5658696134259381, 'test_loss': 0.8473371063669523, 'bleu': 0.4908, 'gen_len': 10.1778}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 2/1172 [02:17<22:07:05, 68.06s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 6: {Learning rate: [0.009356910652231449]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.44batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:06<00:00,  2.30batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.49778958122561295, 'test_loss': 0.8723774358630181, 'bleu': 0.9595, 'gen_len': 11.4044}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 3/1172 [03:18<21:09:48, 65.17s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 7: {Learning rate: [0.00934884954818618]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.41batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.04batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.42908084885341913, 'test_loss': 0.9052557662129402, 'bleu': 0.7864, 'gen_len': 11.2311}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 4/1172 [04:21<20:45:52, 64.00s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 8: {Learning rate: [0.00934078844414091]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.38batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.54batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.35951348534953875, 'test_loss': 0.9593725110093753, 'bleu': 1.0326, 'gen_len': 10.2133}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 5/1172 [05:30<21:25:07, 66.07s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 9: {Learning rate: [0.00933272734009564]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.36batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.45batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.30335200492908637, 'test_loss': 0.9855174926420053, 'bleu': 1.2899, 'gen_len': 11.9378}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 6/1172 [06:38<21:32:18, 66.50s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 10: {Learning rate: [0.009324666236050373]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.28batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.96batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.25331692374128056, 'test_loss': 1.0313124624391397, 'bleu': 1.8498, 'gen_len': 11.44}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 7/1172 [07:44<21:29:45, 66.43s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 11: {Learning rate: [0.009316605132005102]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.39batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.02batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.20675146122147717, 'test_loss': 1.0892622527976832, 'bleu': 2.0299, 'gen_len': 11.3778}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 8/1172 [08:48<21:11:59, 65.57s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 12: {Learning rate: [0.009308544027959833]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.31batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.76batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.16950597643382906, 'test_loss': 1.122325330848495, 'bleu': 2.0449, 'gen_len': 11.9822}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 9/1172 [09:54<21:15:15, 65.79s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 13: {Learning rate: [0.009300482923914563]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:57<00:00,  2.23batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.82batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.13726942035860903, 'test_loss': 1.168237425883611, 'bleu': 1.9491, 'gen_len': 11.3289}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 10/1172 [11:02<21:28:46, 66.55s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 14: {Learning rate: [0.009292421819869293]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:02<00:00,  2.04batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.54batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.11747406276426917, 'test_loss': 1.1858299940824508, 'bleu': 2.2116, 'gen_len': 12.1467}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 11/1172 [12:18<22:21:48, 69.34s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 15: {Learning rate: [0.009284360715824024]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:00<00:00,  2.10batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.13batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.09862760216819019, 'test_loss': 1.2158544386426609, 'bleu': 2.2682, 'gen_len': 11.5422}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 12/1172 [13:29<22:29:03, 69.78s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 16: {Learning rate: [0.009276299611778754]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.38batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.93batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.08470561959612088, 'test_loss': 1.2195446595549584, 'bleu': 2.4208, 'gen_len': 12.0978}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 13/1172 [14:35<22:08:28, 68.77s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 17: {Learning rate: [0.009268238507733485]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.41batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.11batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.07481852125405795, 'test_loss': 1.2567684551080067, 'bleu': 2.5894, 'gen_len': 11.9422}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 14/1172 [15:38<21:32:37, 66.98s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 18: {Learning rate: [0.009260177403688216]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.45batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.12batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.06829568648373517, 'test_loss': 1.2564526585241158, 'bleu': 2.434, 'gen_len': 12.2489}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|‚ñè         | 15/1172 [16:39<20:57:11, 65.20s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 19: {Learning rate: [0.009252116299642947]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.41batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.96batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.06131653473015845, 'test_loss': 1.2523178145289422, 'bleu': 3.0307, 'gen_len': 12.28}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|‚ñè         | 16/1172 [17:42<20:41:32, 64.44s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 20: {Learning rate: [0.009244055195597676]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.40batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.89batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.054507003613109666, 'test_loss': 1.251902869095405, 'bleu': 2.4038, 'gen_len': 11.6311}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  1%|‚ñè         | 17/1172 [18:45<20:33:53, 64.10s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 21: {Learning rate: [0.009235994091552407]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.37batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:06<00:00,  2.17batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.05156587171331635, 'test_loss': 1.2569687803586325, 'bleu': 2.5742, 'gen_len': 12.4489}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 18/1172 [19:48<20:24:50, 63.68s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 22: {Learning rate: [0.009227932987507138]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.41batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.00batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.04465526181793823, 'test_loss': 1.2829449673493702, 'bleu': 2.715, 'gen_len': 11.7067}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 19/1172 [20:51<20:18:21, 63.40s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 23: {Learning rate: [0.009219871883461869]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.32batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.66batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.042608285601448824, 'test_loss': 1.2911169464389483, 'bleu': 2.3709, 'gen_len': 11.6711}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 20/1172 [21:56<20:31:08, 64.12s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 24: {Learning rate: [0.0092118107794166]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.39batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.04batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.04329907415273387, 'test_loss': 1.2854806527495384, 'bleu': 2.299, 'gen_len': 11.4578}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 21/1172 [22:59<20:23:19, 63.77s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 25: {Learning rate: [0.009203749675371329]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.42batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.89batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.0389226196245767, 'test_loss': 1.2795045914749303, 'bleu': 2.716, 'gen_len': 11.8178}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 22/1172 [24:03<20:19:54, 63.65s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 26: {Learning rate: [0.00919568857132606]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.38batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.96batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.03928799622171507, 'test_loss': 1.2956522847215335, 'bleu': 2.6126, 'gen_len': 11.8267}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 23/1172 [25:06<20:16:45, 63.54s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 27: {Learning rate: [0.00918762746728079]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.29batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.81batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.03471670787429481, 'test_loss': 1.2946669047077497, 'bleu': 2.5913, 'gen_len': 11.7556}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 24/1172 [26:12<20:31:59, 64.39s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 28: {Learning rate: [0.009179566363235522]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.27batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.98batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.03405567647991922, 'test_loss': 1.2661456694205602, 'bleu': 2.6605, 'gen_len': 11.7467}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 25/1172 [27:19<20:43:55, 65.07s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 29: {Learning rate: [0.009171505259190253]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.29batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.78batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.03291528374983335, 'test_loss': 1.286092329521974, 'bleu': 3.0035, 'gen_len': 12.4}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 26/1172 [28:26<20:51:10, 65.51s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 30: {Learning rate: [0.009163444155144983]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.38batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.96batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.0320729845108127, 'test_loss': 1.2685337488849957, 'bleu': 2.8018, 'gen_len': 12.3467}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 27/1172 [29:29<20:38:00, 64.87s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 31: {Learning rate: [0.009155383051099713]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.36batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.90batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.029723278730814384, 'test_loss': 1.2981869881351789, 'bleu': 2.7537, 'gen_len': 12.1733}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 28/1172 [30:33<20:31:55, 64.61s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 32: {Learning rate: [0.009147321947054443]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.38batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.89batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.02869540852619203, 'test_loss': 1.2921462843815485, 'bleu': 2.8654, 'gen_len': 11.7778}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|‚ñè         | 29/1172 [31:37<20:29:22, 64.53s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 33: {Learning rate: [0.009139260843009174]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.44batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.79batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.02840149535350208, 'test_loss': 1.3130461330215135, 'bleu': 3.294, 'gen_len': 14.8356}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 30/1172 [32:41<20:23:00, 64.26s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 34: {Learning rate: [0.009131199738963905]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:56<00:00,  2.27batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.96batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.02682523680924196, 'test_loss': 1.3025061771273614, 'bleu': 2.6165, 'gen_len': 12.0978}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 31/1172 [33:47<20:33:18, 64.85s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 35: {Learning rate: [0.009123138634918636]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.41batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.66batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.02616055567902843, 'test_loss': 1.2735323302447796, 'bleu': 3.3245, 'gen_len': 12.5111}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 32/1172 [34:52<20:30:04, 64.74s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 36: {Learning rate: [0.009115077530873365]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.34batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.86batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.025541117766828048, 'test_loss': 1.2743814662098885, 'bleu': 2.7384, 'gen_len': 11.9289}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 33/1172 [35:57<20:31:54, 64.89s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 37: {Learning rate: [0.009107016426828096]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.33batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.50batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.023586882560653246, 'test_loss': 1.2806941814720632, 'bleu': 2.6625, 'gen_len': 11.8133}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 34/1172 [37:04<20:44:25, 65.61s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 38: {Learning rate: [0.009098955322782827]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.47batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.05batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.023501737303591855, 'test_loss': 1.2785256519913673, 'bleu': 2.6888, 'gen_len': 12.0089}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 35/1172 [38:05<20:18:10, 64.28s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 39: {Learning rate: [0.009090894218737558]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.48batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.69batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.021979067518603145, 'test_loss': 1.2787995643913745, 'bleu': 2.6452, 'gen_len': 11.8978}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 36/1172 [39:08<20:08:28, 63.83s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 40: {Learning rate: [0.009082833114692289]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.45batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.07batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.022176320525252913, 'test_loss': 1.2804197664062182, 'bleu': 2.9022, 'gen_len': 11.7244}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 37/1172 [40:09<19:52:51, 63.06s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 41: {Learning rate: [0.00907477201064702]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.45batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.12batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.021343534420002398, 'test_loss': 1.2591455115626256, 'bleu': 2.9153, 'gen_len': 11.7911}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 38/1172 [41:10<19:40:21, 62.45s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 42: {Learning rate: [0.009066710906601749]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.47batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.07batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.020047769658120832, 'test_loss': 1.2841236010193824, 'bleu': 2.7043, 'gen_len': 11.4711}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 39/1172 [42:11<19:31:25, 62.03s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 43: {Learning rate: [0.00905864980255648]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.48batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.04batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.019886214227422955, 'test_loss': 1.2833851118882498, 'bleu': 2.9588, 'gen_len': 11.8444}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 40/1172 [43:13<19:25:06, 61.75s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 44: {Learning rate: [0.00905058869851121]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.45batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.99batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.019945380050600984, 'test_loss': 1.2755233585834502, 'bleu': 3.0222, 'gen_len': 12.5467}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|‚ñé         | 41/1172 [44:14<19:23:21, 61.72s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 45: {Learning rate: [0.00904252759446594]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.47batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.00batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.019396390762238754, 'test_loss': 1.2594849308331808, 'bleu': 3.0171, 'gen_len': 11.4933}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñé         | 42/1172 [45:15<19:19:45, 61.58s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 46: {Learning rate: [0.009034466490420672]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.43batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.58batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.019182914812997803, 'test_loss': 1.2727840319275856, 'bleu': 3.0137, 'gen_len': 12.2222}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñé         | 43/1172 [46:20<19:33:33, 62.37s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 47: {Learning rate: [0.009026405386375402]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:57<00:00,  2.21batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.90batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.019076449173231293, 'test_loss': 1.285535177588463, 'bleu': 2.9168, 'gen_len': 11.6978}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 44/1172 [47:28<20:04:49, 64.09s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 48: {Learning rate: [0.009018344282330133]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.37batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.81batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.01728074785915944, 'test_loss': 1.2777830402056376, 'bleu': 2.9735, 'gen_len': 11.6089}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 45/1172 [48:32<20:05:38, 64.19s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 49: {Learning rate: [0.009010283178284863]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:59<00:00,  2.15batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.59batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.017291182655782448, 'test_loss': 1.2619646539290745, 'bleu': 3.1722, 'gen_len': 11.8933}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 46/1172 [49:44<20:45:42, 66.38s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 50: {Learning rate: [0.009002222074239594]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:56<00:00,  2.25batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.94batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.016589510250895275, 'test_loss': 1.2690670763452847, 'bleu': 3.0906, 'gen_len': 11.9511}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 47/1172 [50:51<20:48:52, 66.61s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 51: {Learning rate: [0.008994160970194323]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.35batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.87batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.015968054368006666, 'test_loss': 1.2776118824879328, 'bleu': 3.1052, 'gen_len': 12.3111}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 48/1172 [51:55<20:35:43, 65.96s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 52: {Learning rate: [0.008986099866149056]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.28batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.82batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.01618501619531179, 'test_loss': 1.290345831712087, 'bleu': 3.0273, 'gen_len': 11.8267}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 49/1172 [53:02<20:36:26, 66.06s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 53: {Learning rate: [0.008978038762103785]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.33batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.56batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.01655503252418492, 'test_loss': 1.2790705849726995, 'bleu': 2.7919, 'gen_len': 11.56}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 50/1172 [54:09<20:43:45, 66.51s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 54: {Learning rate: [0.008969977658058516]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:58<00:00,  2.16batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.62batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.015960717584761815, 'test_loss': 1.2592861304680507, 'bleu': 3.2477, 'gen_len': 11.9689}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 51/1172 [55:20<21:08:10, 67.88s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 55: {Learning rate: [0.008961916554013247]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.35batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.66batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.015214998617870953, 'test_loss': 1.277988630036513, 'bleu': 3.0649, 'gen_len': 11.9689}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  4%|‚ñç         | 52/1172 [56:26<20:57:49, 67.38s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 56: {Learning rate: [0.008953855449967976]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.33batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.66batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.014713839160307772, 'test_loss': 1.264412888387839, 'bleu': 3.2779, 'gen_len': 11.96}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñç         | 53/1172 [57:33<20:50:00, 67.02s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 57: {Learning rate: [0.008945794345922707]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.31batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.97batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.014775067956487494, 'test_loss': 1.2535011400779088, 'bleu': 2.921, 'gen_len': 12.0267}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñç         | 54/1172 [58:39<20:42:50, 66.70s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 58: {Learning rate: [0.008937733241877438]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.29batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.88batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.015316532240945875, 'test_loss': 1.2525913447141648, 'bleu': 3.0528, 'gen_len': 11.7244}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñç         | 55/1172 [59:45<20:38:22, 66.52s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 59: {Learning rate: [0.008929672137832169]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.34batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.75batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.015251041267169859, 'test_loss': 1.2623561958471934, 'bleu': 2.801, 'gen_len': 11.6044}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñç         | 56/1172 [1:00:50<20:31:29, 66.21s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 60: {Learning rate: [0.0089216110337869]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:59<00:00,  2.13batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.59batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.014266353899862354, 'test_loss': 1.2725721513231596, 'bleu': 2.8484, 'gen_len': 12.04}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñç         | 57/1172 [1:02:02<20:59:40, 67.78s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 61: {Learning rate: [0.00891354992974163]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.35batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.87batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.014286225778967376, 'test_loss': 1.2677295366923014, 'bleu': 2.6808, 'gen_len': 11.7111}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñç         | 58/1172 [1:03:07<20:42:59, 66.95s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 62: {Learning rate: [0.00890548882569636]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.38batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.56batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.01468441715669327, 'test_loss': 1.254246364037196, 'bleu': 3.0833, 'gen_len': 12.4089}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñå         | 59/1172 [1:04:12<20:35:05, 66.58s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 63: {Learning rate: [0.00889742772165109]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.36batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.62batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.013914496080553907, 'test_loss': 1.2674093589186668, 'bleu': 3.1902, 'gen_len': 12.2089}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñå         | 60/1172 [1:05:18<20:29:36, 66.35s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 64: {Learning rate: [0.008889366617605822]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.37batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.04batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.013801654219612713, 'test_loss': 1.2633440082271894, 'bleu': 2.9605, 'gen_len': 11.9422}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñå         | 61/1172 [1:06:22<20:14:37, 65.60s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 65: {Learning rate: [0.008881305513560553]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.32batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.97batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.013372923196183415, 'test_loss': 1.2586288223663966, 'bleu': 3.2671, 'gen_len': 12.1556}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñå         | 62/1172 [1:07:27<20:08:04, 65.30s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 66: {Learning rate: [0.008873244409515283]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.44batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.10batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.012618114299133537, 'test_loss': 1.253600569566091, 'bleu': 3.1416, 'gen_len': 12.2133}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñå         | 63/1172 [1:08:28<19:43:49, 64.05s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 67: {Learning rate: [0.008865183305470013]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:51<00:00,  2.46batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.72batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.011483285317608104, 'test_loss': 1.244955080250899, 'bleu': 3.0369, 'gen_len': 11.7422}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñå         | 64/1172 [1:09:30<19:35:06, 63.63s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 68: {Learning rate: [0.008857122201424743]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.33batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.73batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.011518455312154658, 'test_loss': 1.2464750468730927, 'bleu': 3.2783, 'gen_len': 11.7378}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 65/1172 [1:10:36<19:45:20, 64.25s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 69: {Learning rate: [0.008849061097379474]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.28batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.81batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.01128906418393388, 'test_loss': 1.2438841914137204, 'bleu': 3.5055, 'gen_len': 11.8933}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 66/1172 [1:11:44<20:02:49, 65.25s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 70: {Learning rate: [0.008840999993334205]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.35batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.86batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.01139642784782634, 'test_loss': 1.2490117887655894, 'bleu': 3.1016, 'gen_len': 11.7022}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 67/1172 [1:12:48<19:58:08, 65.06s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 71: {Learning rate: [0.008832938889288936]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.37batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.77batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.010796213924048805, 'test_loss': 1.2551923568050067, 'bleu': 3.0572, 'gen_len': 11.9556}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 68/1172 [1:13:52<19:52:03, 64.79s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 72: {Learning rate: [0.008824877785243667]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:56<00:00,  2.27batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.92batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.011415059196095414, 'test_loss': 1.2575892224907874, 'bleu': 3.0184, 'gen_len': 11.7467}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 69/1172 [1:14:59<19:58:31, 65.20s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 73: {Learning rate: [0.008816816681198396]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.33batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.94batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.011356013984690735, 'test_loss': 1.2533033097783723, 'bleu': 2.9738, 'gen_len': 11.8}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 70/1172 [1:16:03<19:55:36, 65.10s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 74: {Learning rate: [0.008808755577153127]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.27batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.05batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.01157918280379216, 'test_loss': 1.2663427953918776, 'bleu': 2.7826, 'gen_len': 11.9911}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 71/1172 [1:17:10<20:01:02, 65.45s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 75: {Learning rate: [0.008800694473107858]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.32batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.90batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.010977354973158616, 'test_loss': 1.24895894775788, 'bleu': 3.1457, 'gen_len': 12.0178}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 72/1172 [1:18:15<19:58:36, 65.38s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 76: {Learning rate: [0.008792633369062589]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:56<00:00,  2.23batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.83batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.01068192625997632, 'test_loss': 1.237419489522775, 'bleu': 3.1233, 'gen_len': 12.0844}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñå         | 73/1172 [1:19:23<20:10:16, 66.08s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 77: {Learning rate: [0.00878457226501732]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.29batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.81batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.010671870625306537, 'test_loss': 1.2685782119631768, 'bleu': 3.0597, 'gen_len': 11.84}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñã         | 74/1172 [1:20:29<20:13:30, 66.31s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 78: {Learning rate: [0.008776511160972049]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.31batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.65batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.010841947168067802, 'test_loss': 1.238839610417684, 'bleu': 3.0547, 'gen_len': 12.0356}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñã         | 75/1172 [1:21:37<20:19:52, 66.72s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 79: {Learning rate: [0.00876845005692678]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:02<00:00,  2.03batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.44batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.010681639848951631, 'test_loss': 1.264217951397101, 'bleu': 3.0239, 'gen_len': 11.8178}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  6%|‚ñã         | 76/1172 [1:22:53<21:09:14, 69.48s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 80: {Learning rate: [0.00876038895288151]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:01<00:00,  2.06batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.52batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.010533636670530313, 'test_loss': 1.2479702283938725, 'bleu': 3.1835, 'gen_len': 11.5067}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 77/1172 [1:24:08<21:39:36, 71.21s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 81: {Learning rate: [0.008752327848836242]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:57<00:00,  2.23batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.79batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.010373710476844681, 'test_loss': 1.2457130586107572, 'bleu': 3.1153, 'gen_len': 12.1733}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 78/1172 [1:25:18<21:29:56, 70.75s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 82: {Learning rate: [0.008744266744790972]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:02<00:00,  2.02batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.47batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.009749921220244737, 'test_loss': 1.2578890115022658, 'bleu': 3.4427, 'gen_len': 12.0356}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 79/1172 [1:26:34<21:55:32, 72.22s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 83: {Learning rate: [0.008736205640745703]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:57<00:00,  2.21batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.84batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008704951016496367, 'test_loss': 1.2561772247155507, 'bleu': 3.5245, 'gen_len': 11.8178}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 80/1172 [1:27:43<21:37:13, 71.28s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 84: {Learning rate: [0.008728144536700433]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:02<00:00,  2.02batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:16<00:00,  1.13s/batches]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.009714044119033404, 'test_loss': 1.2473492483297983, 'bleu': 3.1548, 'gen_len': 11.8089}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 81/1172 [1:29:06<22:41:11, 74.86s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 85: {Learning rate: [0.008720083432655163]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:57<00:00,  2.20batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.00batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.009715430532017445, 'test_loss': 1.2578106611967086, 'bleu': 3.0339, 'gen_len': 11.6533}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 82/1172 [1:30:14<22:03:48, 72.87s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 86: {Learning rate: [0.008712022328609894]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.33batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.73batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.009467858157494641, 'test_loss': 1.2422298987706502, 'bleu': 3.0377, 'gen_len': 11.7689}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 83/1172 [1:31:20<21:23:49, 70.73s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 87: {Learning rate: [0.008703961224564623]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.33batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.72batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.009166292780203613, 'test_loss': 1.2621286322673162, 'bleu': 2.9259, 'gen_len': 11.9022}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 84/1172 [1:32:26<20:55:25, 69.23s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 88: {Learning rate: [0.008695900120519356]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:57<00:00,  2.20batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:12<00:00,  1.23batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.009470785187014679, 'test_loss': 1.241885278125604, 'bleu': 3.2487, 'gen_len': 11.4667}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 85/1172 [1:33:38<21:13:41, 70.31s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 89: {Learning rate: [0.008687839016474085]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:03<00:00,  2.01batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.49batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.00923583906063238, 'test_loss': 1.240811205903689, 'bleu': 3.7498, 'gen_len': 12.0178}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 86/1172 [1:34:55<21:47:40, 72.25s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 90: {Learning rate: [0.008679777912428816]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:58<00:00,  2.17batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.64batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008812962680153079, 'test_loss': 1.2554672588904698, 'bleu': 2.7211, 'gen_len': 11.48}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  7%|‚ñã         | 87/1172 [1:36:06<21:37:06, 71.73s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 91: {Learning rate: [0.008671716808383547]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:00<00:00,  2.11batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.47batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008352183812026551, 'test_loss': 1.240593791504701, 'bleu': 3.0456, 'gen_len': 11.88}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 88/1172 [1:37:21<21:53:52, 72.72s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 92: {Learning rate: [0.008663655704338278]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:01<00:00,  2.05batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.85batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.007838771295345088, 'test_loss': 1.260141459107399, 'bleu': 2.9027, 'gen_len': 11.5556}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 89/1172 [1:38:35<22:03:21, 73.32s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 93: {Learning rate: [0.008655594600293007]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:58<00:00,  2.19batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.77batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008547606161157564, 'test_loss': 1.244903488457203, 'bleu': 3.3342, 'gen_len': 12.0933}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 90/1172 [1:39:45<21:40:53, 72.14s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 94: {Learning rate: [0.00864753349624774]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:55<00:00,  2.30batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.85batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008085974222635777, 'test_loss': 1.2459709386030833, 'bleu': 2.8157, 'gen_len': 12.1689}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 91/1172 [1:40:51<21:05:04, 70.22s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 95: {Learning rate: [0.008639472392202469]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:53<00:00,  2.37batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.68batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.00823400850869774, 'test_loss': 1.2464361131191253, 'bleu': 3.1481, 'gen_len': 11.72}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 92/1172 [1:41:56<20:35:58, 68.67s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 96: {Learning rate: [0.0086314112881572]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:00<00:00,  2.09batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.42batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008565918553444579, 'test_loss': 1.2408836990594865, 'bleu': 2.8425, 'gen_len': 11.6889}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 93/1172 [1:43:10<21:05:05, 70.35s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 97: {Learning rate: [0.00862335018411193]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:03<00:00,  2.00batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.40batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008901374671226881, 'test_loss': 1.2536312202612558, 'bleu': 3.2971, 'gen_len': 11.96}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 94/1172 [1:44:27<21:40:41, 72.39s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 98: {Learning rate: [0.00861528908006666]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:00<00:00,  2.11batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:11<00:00,  1.26batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008308192878213572, 'test_loss': 1.2490251590808232, 'bleu': 3.282, 'gen_len': 11.7867}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 95/1172 [1:45:42<21:54:24, 73.23s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 99: {Learning rate: [0.00860722797602139]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:06<00:00,  1.91batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  2.00batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008718898024879337, 'test_loss': 1.2336109509070714, 'bleu': 3.2139, 'gen_len': 12.08}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 96/1172 [1:47:00<22:17:30, 74.58s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 100: {Learning rate: [0.008599166871976122]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:01<00:00,  2.06batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:11<00:00,  1.35batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008138679501446566, 'test_loss': 1.252328943212827, 'bleu': 2.7632, 'gen_len': 11.8889}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 97/1172 [1:48:17<22:27:02, 75.18s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 101: {Learning rate: [0.008591105767930853]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:59<00:00,  2.14batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.78batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008658011974656852, 'test_loss': 1.2516943742831548, 'bleu': 3.3903, 'gen_len': 11.6933}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 98/1172 [1:49:27<21:59:04, 73.69s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 102: {Learning rate: [0.008583044663885583]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:52<00:00,  2.41batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:07<00:00,  1.92batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008323601119799583, 'test_loss': 1.2326380034287772, 'bleu': 3.0034, 'gen_len': 11.8978}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  8%|‚ñä         | 99/1172 [1:50:29<20:58:43, 70.38s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 103: {Learning rate: [0.008574983559840314]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:59<00:00,  2.14batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.45batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008425784555784478, 'test_loss': 1.2456810176372528, 'bleu': 3.5155, 'gen_len': 11.6133}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  9%|‚ñä         | 100/1172 [1:51:42<21:10:18, 71.10s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 104: {Learning rate: [0.008566922455795043]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:08<00:00,  1.86batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:11<00:00,  1.26batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008773180291305964, 'test_loss': 1.247572856148084, 'bleu': 3.3875, 'gen_len': 11.9378}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  9%|‚ñä         | 101/1172 [1:53:06<22:16:57, 74.90s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 105: {Learning rate: [0.008558861351749776]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:01<00:00,  2.06batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.86batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.00891343998634733, 'test_loss': 1.2530828575293222, 'bleu': 3.304, 'gen_len': 11.9556}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  9%|‚ñä         | 102/1172 [1:54:20<22:11:07, 74.64s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 106: {Learning rate: [0.008550800247704505]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:54<00:00,  2.31batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:08<00:00,  1.72batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.007870847318966792, 'test_loss': 1.2429321552316348, 'bleu': 2.9701, 'gen_len': 11.6578}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  9%|‚ñâ         | 103/1172 [1:55:26<21:24:05, 72.07s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 107: {Learning rate: [0.008542739143659236]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:56<00:00,  2.26batches/s]\n","Test batch number 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:11<00:00,  1.35batches/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics: {'train_loss': 0.008017809968075062, 'test_loss': 1.2528435369332631, 'bleu': 2.9606, 'gen_len': 11.7111}\n","\n","=============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["  9%|‚ñâ         | 104/1172 [1:56:36<21:11:17, 71.42s/it]"]},{"name":"stdout","output_type":"stream","text":["For epoch 108: {Learning rate: [0.008534678039613967]}\n"]},{"name":"stderr","output_type":"stream","text":["Train batch number 12:   9%|‚ñä         | 11/127 [00:05<00:55,  2.09batches/s]\n","  9%|‚ñâ         | 104/1172 [1:56:46<19:59:10, 67.37s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Oumar Kane\\OneDrive\\Documents\\subject2\\fw_training_t5_small_custom_train_best_model_v4.ipynb Cell 19\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Oumar%20Kane/OneDrive/Documents/subject2/fw_training_t5_small_custom_train_best_model_v4.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(epochs \u001b[39m=\u001b[39;49m config[\u001b[39m'\u001b[39;49m\u001b[39mmax_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m-\u001b[39;49m trainer\u001b[39m.\u001b[39;49mcurrent_epoch, auto_save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, metric_for_best_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbleu\u001b[39;49m\u001b[39m'\u001b[39;49m, metric_objective\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m, log_step\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Oumar%20Kane/OneDrive/Documents/subject2/fw_training_t5_small_custom_train_best_model_v4.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m               saving_directory \u001b[39m=\u001b[39;49m config[\u001b[39m'\u001b[39;49m\u001b[39mnew_model_dir\u001b[39;49m\u001b[39m'\u001b[39;49m])\n","File \u001b[1;32mc:\\users\\oumar kane\\onedrive\\documents\\subject2\\wolof-translate\\wolof_translate\\trainers\\transformer_trainer.py:350\u001b[0m, in \u001b[0;36mModelRunner.train\u001b[1;34m(self, epochs, auto_save, log_step, saving_directory, file_name, save_best, metric_for_best_model, metric_objective)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[39m# R√©cup√©ration de identifiant token du padding (par d√©faut = 3)\u001b[39;00m\n\u001b[0;32m    347\u001b[0m pad_token_id \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token_id\n\u001b[0;32m    349\u001b[0m preds, loss \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 350\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_train(input_, input_mask, labels, labels_mask, pad_token_id)\n\u001b[0;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    352\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_eval(input_, input_mask, labels, labels_mask, pad_token_id)\n\u001b[0;32m    353\u001b[0m )\n\u001b[0;32m    355\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    357\u001b[0m \u001b[39m# let us add the predictions and labels in the list of predictions and labels after their determinations\u001b[39;00m\n","File \u001b[1;32mc:\\users\\oumar kane\\onedrive\\documents\\subject2\\wolof-translate\\wolof_translate\\trainers\\transformer_trainer.py:91\u001b[0m, in \u001b[0;36mModelRunner.batch_train\u001b[1;34m(self, input_, input_mask, labels, labels_mask, pad_token_id)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_train\u001b[39m(\u001b[39mself\u001b[39m, input_: torch\u001b[39m.\u001b[39mTensor, input_mask: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m     87\u001b[0m                 labels: torch\u001b[39m.\u001b[39mTensor, labels_mask: torch\u001b[39m.\u001b[39mTensor, pad_token_id: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhugging_face: \u001b[39m# Nous allons utilise un mod√®le text to text de hugging face (but only for fine-tuning)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[0;32m     90\u001b[0m       \u001b[39m# effectuons un passage vers l'avant\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m       outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_ids \u001b[39m=\u001b[39;49m input_, attention_mask \u001b[39m=\u001b[39;49m input_mask, \n\u001b[0;32m     92\u001b[0m                            labels \u001b[39m=\u001b[39;49m labels)\n\u001b[0;32m     94\u001b[0m       \u001b[39m# recuperate the predictions and the loss\u001b[39;00m\n\u001b[0;32m     95\u001b[0m       preds, loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlogits, outputs\u001b[39m.\u001b[39mloss\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1716\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1713\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[0;32m   1715\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[1;32m-> 1716\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[0;32m   1717\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1718\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1719\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1720\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1721\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m   1722\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1723\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1724\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1725\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1726\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1727\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1728\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1729\u001b[0m )\n\u001b[0;32m   1731\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1733\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1086\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[0;32m   1074\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m   1075\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     )\n\u001b[0;32m   1085\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1086\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m   1087\u001b[0m         hidden_states,\n\u001b[0;32m   1088\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1089\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m   1090\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1091\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1092\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[0;32m   1093\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m   1094\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[0;32m   1095\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m   1096\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1097\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1098\u001b[0m     )\n\u001b[0;32m   1100\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:753\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    750\u001b[0m     attention_outputs \u001b[39m=\u001b[39m attention_outputs \u001b[39m+\u001b[39m cross_attention_outputs[\u001b[39m2\u001b[39m:]\n\u001b[0;32m    752\u001b[0m \u001b[39m# Apply Feed Forward layer\u001b[39;00m\n\u001b[1;32m--> 753\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m](hidden_states)\n\u001b[0;32m    755\u001b[0m \u001b[39m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[39mif\u001b[39;00m hidden_states\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16:\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:343\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[0;32m    342\u001b[0m     forwarded_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 343\u001b[0m     forwarded_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mDenseReluDense(forwarded_states)\n\u001b[0;32m    344\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(forwarded_states)\n\u001b[0;32m    345\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:290\u001b[0m, in \u001b[0;36mT5DenseActDense.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    288\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwi(hidden_states)\n\u001b[0;32m    289\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(hidden_states)\n\u001b[1;32m--> 290\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(hidden_states)\n\u001b[0;32m    291\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    292\u001b[0m     \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwo\u001b[39m.\u001b[39mweight, torch\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m    293\u001b[0m     \u001b[39mand\u001b[39;00m hidden_states\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwo\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    294\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwo\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mint8\n\u001b[0;32m    295\u001b[0m ):\n\u001b[0;32m    296\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwo\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdtype)\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n","File \u001b[1;32mc:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\torch\\nn\\functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[1;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train(epochs = config['max_epoch'] - trainer.current_epoch, auto_save=True, metric_for_best_model='bleu', metric_objective='maximize', log_step=1,\n","              saving_directory = config['new_model_dir'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sQVOIX4lqGMg"},"source":["### Predictions and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# let us get the best model\n","# model = T5ForConditionalGeneration.from_pretrained('data/checkpoints/t5_results_fw_v3/...')\n","\n","# let us get the test set\n","test_dataset = SentenceDataset(f\"data/extractions/new_data/test_set.csv\",\n","                                        tokenizer,\n","                                        truncation = True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us make the evaluation and print the predicted sentences."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluation batch number 1:   0%|          | 0/11 [00:00<?, ?batches/s]c:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Evaluation batch number 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  1.88batches/s]\n"]}],"source":["# evaluation with test set\n","df_ft_to_wf = trainer.evaluate(test_dataset)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us display the 10 last sentences."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>original_text</th>\n","      <th>original_label</th>\n","      <th>predicted_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>152</th>\n","      <td>Homme, lion, boeuf... allaient de concert.</td>\n","      <td>Nit, gaynd√©, nag... √†ndoon na√±u fi.</td>\n","      <td>Nit, gaynd√©, nag, √†ndoon na√±u fi.</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>C'est toi qui eusses √©t√© √©lu</td>\n","      <td>Yaa doonkoon falu</td>\n","      <td>Yaa doonkoon wax</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>L'homme ne cultivera pas</td>\n","      <td>G√≥or gi du b√†y</td>\n","      <td>G√≥or gi b√´ggul</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>S'agiter simplement ne suffit √† rien r√©soudre.</td>\n","      <td>Di tel-teli do≈ã≈ã taxul sotal dara.</td>\n","      <td>Nit √±enn √±i yegseegu√±u.</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>C'√©tait son h√¥te habituellement.</td>\n","      <td>Moo doon ganam.</td>\n","      <td>Man xar m√©pp.</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>Je parle de ceux-l√†!</td>\n","      <td>Yenn xar yooyuu laa wax!</td>\n","      <td>Yaw moomu laa wax</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>Tu reconnais cet enfant-ci?</td>\n","      <td>Xammee ≈ãga bee xale?</td>\n","      <td>Xammee ≈ãga waa jooju?</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>Alors l'homme entra, les enfants le virent, il...</td>\n","      <td>Noona g√≥or gi dugg, xale yi gis ka, mu toog, √±...</td>\n","      <td>Noona G√≥or gaa ≈ãgi, mu √±√´w.</td>\n","    </tr>\n","    <tr>\n","      <th>160</th>\n","      <td>C'est leur ami!</td>\n","      <td>Su√±u xarit la!</td>\n","      <td>Su demee</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>Il √©tait Lebou de Yoff.</td>\n","      <td>Mu doon Lebu Yoff.</td>\n","      <td>Dafa doon nitu d√´gg.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         original_text  \\\n","152         Homme, lion, boeuf... allaient de concert.   \n","153                       C'est toi qui eusses √©t√© √©lu   \n","154                           L'homme ne cultivera pas   \n","155     S'agiter simplement ne suffit √† rien r√©soudre.   \n","156                   C'√©tait son h√¥te habituellement.   \n","157                               Je parle de ceux-l√†!   \n","158                        Tu reconnais cet enfant-ci?   \n","159  Alors l'homme entra, les enfants le virent, il...   \n","160                                    C'est leur ami!   \n","161                            Il √©tait Lebou de Yoff.   \n","\n","                                        original_label  \\\n","152                Nit, gaynd√©, nag... √†ndoon na√±u fi.   \n","153                                  Yaa doonkoon falu   \n","154                                     G√≥or gi du b√†y   \n","155                 Di tel-teli do≈ã≈ã taxul sotal dara.   \n","156                                    Moo doon ganam.   \n","157                           Yenn xar yooyuu laa wax!   \n","158                               Xammee ≈ãga bee xale?   \n","159  Noona g√≥or gi dugg, xale yi gis ka, mu toog, √±...   \n","160                                     Su√±u xarit la!   \n","161                                 Mu doon Lebu Yoff.   \n","\n","                       predicted_label  \n","152  Nit, gaynd√©, nag, √†ndoon na√±u fi.  \n","153                   Yaa doonkoon wax  \n","154                     G√≥or gi b√´ggul  \n","155            Nit √±enn √±i yegseegu√±u.  \n","156                      Man xar m√©pp.  \n","157                  Yaw moomu laa wax  \n","158              Xammee ≈ãga waa jooju?  \n","159        Noona G√≥or gaa ≈ãgi, mu √±√´w.  \n","160                           Su demee  \n","161               Dafa doon nitu d√´gg.  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_ft_to_wf.tail(10)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us display 100 samples."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>original_text</th>\n","      <th>original_label</th>\n","      <th>predicted_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>105</th>\n","      <td>Qui est-ce?</td>\n","      <td>√ëan la?</td>\n","      <td>Ku mu?</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>Tu as dit cela.</td>\n","      <td>La ≈ãga wax la.</td>\n","      <td>Li ≈ãga wax loolu.</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>A Moussa!</td>\n","      <td>Musaa!</td>\n","      <td>Musaa</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>Je connais l'enfant.</td>\n","      <td>Xam naa xale bi.</td>\n","      <td>Xam naa xale bi.</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>L'homme qui e√ªt travaill√©</td>\n","      <td>Waa ji ligg√©eykoon</td>\n","      <td>G√≥or gi waxkoon na</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>Le voil√† qui part!</td>\n","      <td>Mi ≈ãgiiy!</td>\n","      <td>Ma ≈ãgee doon dem</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>Que tu partes ou que tu ne partes pas il viendra.</td>\n","      <td>Dana √±√´w soo demul ag soo demee itam.</td>\n","      <td>Soo demee ag soo demul itam, dana √±√´w.</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>C'est l'homme qui a soutenu qu'il est sain d'e...</td>\n","      <td>G√≥or gee ni nit la, soo demee!</td>\n","      <td>G√≥or gee ni soo demee nit la</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>J'ai vu mes amis!</td>\n","      <td>Gis naa sana xarit yi!</td>\n","      <td>Gis naa sama xarit yeneen yooyuu</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>Appelle l'homme qui ne part pas</td>\n","      <td>Wool g√≥or gi dul dem</td>\n","      <td>Wool g√≥or gi dul dem</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>Tu as vu celui-ci?</td>\n","      <td>Gis ≈ãga kooku?</td>\n","      <td>Gis ≈ãga buu?</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>Cet homme pr√®s de moi et celui l√† pr√®s de toi ...</td>\n","      <td>Nit ki ci sama wet ak nit kooku mbokk la √±u.</td>\n","      <td>Nit kookuu ci sama wet.</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>Il n'est Ardo d'aucun Dieri que tu ne connaisses!</td>\n","      <td>Amul ardo benn J√©eri boo xamul!</td>\n","      <td>Wax ji y√©pp, ba√±-≈ãga-√±√´w la.</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>Ta m√®re dit qu'elle viendra ce soir.</td>\n","      <td>Sa yay nee na ci ≈ãgoon dana √±√´w.</td>\n","      <td>Sa yay nee dana √±√´w ci ≈ãgoon.</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>C'est toi qui aimes la jeune femme</td>\n","      <td>Yaw la ndaw si sopp</td>\n","      <td>Yaa √±√´wk√≥on</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Que j'attrape quelles vaches?</td>\n","      <td>Ma japp nag yee yan?</td>\n","      <td>Mbaa jan?</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>Qui est parti?</td>\n","      <td>Kan dem na?</td>\n","      <td>Ku dem?</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>C'√©tait son h√¥te habituellement.</td>\n","      <td>Moo doon ganam.</td>\n","      <td>Man xar m√©pp.</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>Ceux-l√†, il ne les appr√©cie gu√®re!</td>\n","      <td>Yooyale deey b√´ggu leen!</td>\n","      <td>Yooyale deey b√´ggu leen!</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>L'homme n'est pas venu.</td>\n","      <td>G√≥or gi rekk a √±√´wul.</td>\n","      <td>Nit ki rekk a √±√´wul.</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Tu √©tais d'habitude l'h√¥te de Mustapha</td>\n","      <td>Yaa daan ganu Mustaf</td>\n","      <td>Waxtaan ≈ãga ag g√≥or gi doon dem</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Et pourtant, les enfants sont venus</td>\n","      <td>Moontin, xale yi √±√´w na√±u</td>\n","      <td>Moontin nag, b√´gg na√±u dem</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>Celui qui est parti, c'est quelqu'un que j'app...</td>\n","      <td>Kooku dem ku m√´ b√´gg la!</td>\n","      <td>Kenn ki dem na</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>L'endroit, o√π l'homme est parti, est beau.</td>\n","      <td>Foofu, g√≥or gi dem, fu rafet la.</td>\n","      <td>Foofu, g√≥or gi dem ba mi ≈ãgi fi.</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>Comme il avait ainsi √©t√© en ce lieu</td>\n","      <td>Noonu mu demoon foofa</td>\n","      <td>Su dee dem</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Et que nul ne bouge!</td>\n","      <td>Te bu fi kenn jog√©!</td>\n","      <td>G√≥or gi kenn ba√± Moom</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>As-tu vu ces autres femmes?</td>\n","      <td>Gis ≈ãga jig√©en √±eneen √±oo√±u?</td>\n","      <td>Gis ≈ãga xale yooyule?</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Lesquels sont arriv√©s?</td>\n","      <td>Yan √±oo yeksi?</td>\n","      <td>Yan √±oo √±√´w?</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>Qui est-ce?</td>\n","      <td>Kan la?</td>\n","      <td>Ku mu?</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>Pouah!</td>\n","      <td>Cam!</td>\n","      <td>Ibraayima</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>J'ai vu un mouton.</td>\n","      <td>Gis naa am xar.</td>\n","      <td>Gis naa xar.</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>J'ai vu cet enfant-l√†?</td>\n","      <td>Gis naa xale booba?</td>\n","      <td>Gis naa booba xale?</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>Tu n'es pas un homme de paix!</td>\n","      <td>Doo nitu jamm!</td>\n","      <td>Doo nitu jamm</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>Tu parles de quelle maison (ici)?</td>\n","      <td>Bii n√©eg ban ≈ãga wax?</td>\n","      <td>Boobu n√©eg ban ≈ãga wax?</td>\n","    </tr>\n","    <tr>\n","      <th>103</th>\n","      <td>L'homme n'est pas mauvais!</td>\n","      <td>Nit bonul!</td>\n","      <td>G√≥or gi du t</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>Tu vas vers qui?</td>\n","      <td>Ci √±an ≈ãga j√´m?</td>\n","      <td>Loo j√´m?</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>L'endroit ce n'est pas par-l√†.</td>\n","      <td>Ber√´b bi du foofu.</td>\n","      <td>Loolule l√©pp.</td>\n","    </tr>\n","    <tr>\n","      <th>104</th>\n","      <td>Tu as √©t√© et il a √©t√© et moi aussi j'ai √©t√©.</td>\n","      <td>Dem ≈ãga, te dem na, te dem naa.</td>\n","      <td>Dem ≈ãga dem te mu dem ag sama xarit ya.</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>Je parle de ceux-l√†!</td>\n","      <td>Yenn xar yooyuu laa wax!</td>\n","      <td>Yaw moomu laa wax</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>Homme et lion ne cohabitent.</td>\n","      <td>Nit ag gaynde du√±u d√´kk√≥o.</td>\n","      <td>Nit ag gaynde du√±u d√´kk√≥o.</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Qui est venu?</td>\n","      <td>Ku √±√´w?</td>\n","      <td>Ku √±√´w?</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>Viens pour que les enfants soient des travaill...</td>\n","      <td>√ë√´w√´l ndax xale yi di mb√´r te it √±u di ay jamb...</td>\n","      <td>√ë√´w√´l ndax xale yi di ay ligg√©eykat, di ay jam...</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>Des boeufs que tu vois, celui-l√† tout pr√®s est...</td>\n","      <td>Gis ≈ãga nag yii y√©pp, woowuu moo ci g√´n.</td>\n","      <td>Gis ≈ãga nag yii y√©pp, woowuu moo ci g√´n.</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>Je te confie celui-l√†.</td>\n","      <td>De≈ãk naa la boobule woon.</td>\n","      <td>Waw kookule.</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>La pr√©sence de celui-l√† m√™me ne justifie pas q...</td>\n","      <td>Taxawaayu kooka sax taxul n√´w</td>\n","      <td>Ci kooku, ndax mu wett√´liku</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>Il √©tait Lebou de Yoff.</td>\n","      <td>Mu doon Lebu Yoff.</td>\n","      <td>Dafa doon nitu d√´gg.</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>J'ai vu l'homme.</td>\n","      <td>Gis naa nit ki.</td>\n","      <td>Gis na keneen ki woon.</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>Celui-ci serait parti</td>\n","      <td>Kii dafa demkoon</td>\n","      <td>Kii dafa demkoon</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>Chez les Peul, les S√©r√®re, et les Niominka.</td>\n","      <td>Ci P√´l yi ag ci S√©er√©er si, ag ci √ëomi≈ãka yi.</td>\n","      <td>Ci S√©er√©er yi ag P√´l yi</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>Sois un √™tre de raison!</td>\n","      <td>Dil nit!</td>\n","      <td>Dafa di nitu tay.</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>Dis : ¬´ woy ¬ª!</td>\n","      <td>Nil : w√≥oy!</td>\n","      <td>Waxal ak √±oo√±ule!</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>Pourquoi?</td>\n","      <td>Lu tax?</td>\n","      <td>Lii lan?</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>Tu ne partiras donc pas?</td>\n","      <td>Xanaa doo dem?</td>\n","      <td>Doo dem?</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>J'ai aper√ßu un homme.</td>\n","      <td>S√©en naa ak nit.</td>\n","      <td>S√©en naa am xar.</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>Fais sortir tout mouton que tu vois!</td>\n","      <td>G√©nn√©el m√©pp xar moo gis!</td>\n","      <td>G√©nn√©el k√©pp nit koo gis!</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>Tu ne vas pas dans un autre lieu!</td>\n","      <td>Demuloo feneen!</td>\n","      <td>Seet ≈ãga √±oo√±ale √±an?</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>Avoir √©t√©, e√ªt √©t√© bon!</td>\n","      <td>Dem, rafetoon na!</td>\n","      <td>Nit, demkoon</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Vous, vous n'avez pas √©t√©</td>\n","      <td>Y√©en demuleenwoon</td>\n","      <td>Y√©en demulwoon</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Tout cet endroit-l√†?</td>\n","      <td>Foofule f√©pp?</td>\n","      <td>Ku Loolu?</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>L'enfant n'a rien donn√© √† celui-ci.</td>\n","      <td>Xale bi mayul kii dara.</td>\n","      <td>Xale bi mayul dara kii.</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Il est l√† √† l'int√©rieur.</td>\n","      <td>Mi ≈ãgi foofule ci biir.</td>\n","      <td>Y√©en mi ≈ãgi ci foofu</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>Ceux-ci ne partent peut-√™tre pas!</td>\n","      <td>√ëii da√±u demul xanaa!</td>\n","      <td>Soo demee ag soo demul</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>Aujourd'hui dans la soir√©e.</td>\n","      <td>Tay ci ≈ãgoon.</td>\n","      <td>Feneen fi b√´tt√≥on foofu.</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>Redresse-le avec un baton!</td>\n","      <td>Jub√´nti ko ak bant!</td>\n","      <td>Su dee Lawbe</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>L'homme n'a pas vu cet enfant-l√†.</td>\n","      <td>G√≥or gi gisul xale boobale woon.</td>\n","      <td>G√≥or gi gisul meneen.</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>Aucun lion ne s'est √©gar√©.</td>\n","      <td>Gaynd√© genn r√©erul.</td>\n","      <td>Menn xar r√©erul.</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>Alors l'homme entra, les enfants le virent, il...</td>\n","      <td>Noona g√≥or gi dugg, xale yi gis ka, mu toog, √±...</td>\n","      <td>Noona G√≥or gaa ≈ãgi, mu √±√´w.</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>Quel d√©mon!</td>\n","      <td>Moo di loola!</td>\n","      <td>J√´nd √±aa menn xar mi.</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>Tu as choisi la fille d'une femme.</td>\n","      <td>Tann ≈ãga doomu benn jig√©en.</td>\n","      <td>Tann ≈ãga doomu benn jig√©en.</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>L√† o√π tu es</td>\n","      <td>Ci foofu ≈ãga taxaw</td>\n","      <td>Bi ≈ãga dee dem</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>Celles-ci!</td>\n","      <td>Yooyuu!</td>\n","      <td>Dem na√±u</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>Celui-l√†, lui, il refusera!</td>\n","      <td>Kookule, moom, du na≈ãgu!</td>\n","      <td>Kookule,?</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>Qu'as-tu vu?</td>\n","      <td>Loo gis?</td>\n","      <td>Koo gis?</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>L'homme ira</td>\n","      <td>G√≥or gi dana demi</td>\n","      <td>G√≥or gi j√´m</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Je ne parle pas de ces enfants?</td>\n","      <td>Waxuma xale yooyale?</td>\n","      <td>Waxuma yooyale xale?</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>Homme, lion, boeuf... allaient de concert.</td>\n","      <td>Nit, gaynd√©, nag... √†ndoon na√±u fi.</td>\n","      <td>Nit, gaynd√©, nag, √†ndoon na√±u fi.</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>J'esp√®re que nul n'est sorti?</td>\n","      <td>Mbaa kenn g√©nnul?</td>\n","      <td>Mbaa kenn demul?</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>J'ai d√©j√† vu tous les moutons.</td>\n","      <td>Gisoon naa xar yi y√©pp.</td>\n","      <td>Gis naa xar yi gannaaw yaw.</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>Tu vois, cet homme l√†?</td>\n","      <td>Gis ≈ãga nit kookee?</td>\n","      <td>Gis ≈ãga nit kee?</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Cet homme qui est Laobe de Saint-Louis.</td>\n","      <td>Gor gii di Lawbe Ndar.</td>\n","      <td>Gor gii di Lawbe Ndar.</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Fais comme tes pairs!</td>\n","      <td>Defal naka sa moroom yi!</td>\n","      <td>Noona sa waajur √±√´w</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>C'est lui qui part.</td>\n","      <td>Dafa di dem.</td>\n","      <td>Moo di dem.</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>Il a √©t√© quelqu'un!</td>\n","      <td>Nit la!</td>\n","      <td>Dem na</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>J'ai aper√ßu un homme.</td>\n","      <td>S√©en naa aw nit.</td>\n","      <td>S√©en naa am xar.</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>Ces gens qui sont sortis sont des lutteurs.</td>\n","      <td>Nit √±oo√±ii g√©nn ay mb√´r lanu.</td>\n","      <td>Xale bi tawat la wax.</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>Je n'y avais pas √©t√©</td>\n","      <td>Demuma fa woon</td>\n","      <td>Demkoonuma</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>Du reste la g√©n√©rosit√© est une bonne chose dan...</td>\n","      <td>Te dey addina laabiir dafa ci baax.</td>\n","      <td>Nit kookuu g√©nn laa wax.</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Toi, tu es l√†!</td>\n","      <td>Yaw, yaa ≈ãgi!</td>\n","      <td>Yaw mi ≈ãga</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Va et reviens!</td>\n","      <td>Demal ba √±√´w!</td>\n","      <td>Demal rekk</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>Il ne s'est pas m√™l√© √† eux.</td>\n","      <td>Dogul cu seen biir.</td>\n","      <td>Waxu la.</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>C'est l'homme qui n'a pas √©t√©</td>\n","      <td>G√≥or gi moo demulwoon</td>\n","      <td>G√≥or gi moo demulwoon</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>Vous parlez de quelle dame (ici)?</td>\n","      <td>Jile jig√©en jan ≈ãgeen wax?</td>\n","      <td>Jile jig√©en jan ≈ãgeen wax?</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>Vous seriez morts</td>\n","      <td>Deekoon ≈ãgeen</td>\n","      <td>Du ≈ãgeen</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>J'ai vu celui en question.</td>\n","      <td>Gis naa ki woon.</td>\n","      <td>Gis naa ki woon.</td>\n","    </tr>\n","    <tr>\n","      <th>110</th>\n","      <td>C'est de celui-l√† que parlent les enfants?</td>\n","      <td>Kooku la xale yiy wax?</td>\n","      <td>Baax na?</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>Qu'il parte s'il ne veut pas!</td>\n","      <td>Su b√´ggul, na dem!</td>\n","      <td>Na dem su b√´ggul</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Si tu pars, il vient.</td>\n","      <td>Soo dem√©e, mu √±√´w.</td>\n","      <td>Soo demee, mu √±√´w.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Tu iras?</td>\n","      <td>Da≈ãga dem?</td>\n","      <td>Doo j√´m?</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>C'est celui-l√† celui-l√† l'un que je te donne.</td>\n","      <td>Benn boobule laa la may.</td>\n","      <td>Benn boobule laa la may.</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Range les affaires!</td>\n","      <td>De√±cal y√´f yi!</td>\n","      <td>Noona xale yi set na√±u</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         original_text  \\\n","105                                        Qui est-ce?   \n","80                                     Tu as dit cela.   \n","52                                           A Moussa!   \n","132                               Je connais l'enfant.   \n","59                           L'homme qui e√ªt travaill√©   \n","54                                  Le voil√† qui part!   \n","115  Que tu partes ou que tu ne partes pas il viendra.   \n","114  C'est l'homme qui a soutenu qu'il est sain d'e...   \n","46                                   J'ai vu mes amis!   \n","147                    Appelle l'homme qui ne part pas   \n","66                                  Tu as vu celui-ci?   \n","82   Cet homme pr√®s de moi et celui l√† pr√®s de toi ...   \n","42   Il n'est Ardo d'aucun Dieri que tu ne connaisses!   \n","91                Ta m√®re dit qu'elle viendra ce soir.   \n","35                  C'est toi qui aimes la jeune femme   \n","0                        Que j'attrape quelles vaches?   \n","148                                     Qui est parti?   \n","156                   C'√©tait son h√¥te habituellement.   \n","47                  Ceux-l√†, il ne les appr√©cie gu√®re!   \n","14                             L'homme n'est pas venu.   \n","17              Tu √©tais d'habitude l'h√¥te de Mustapha   \n","29                 Et pourtant, les enfants sont venus   \n","41   Celui qui est parti, c'est quelqu'un que j'app...   \n","126         L'endroit, o√π l'homme est parti, est beau.   \n","48                 Comme il avait ainsi √©t√© en ce lieu   \n","1                                 Et que nul ne bouge!   \n","21                         As-tu vu ces autres femmes?   \n","24                              Lesquels sont arriv√©s?   \n","62                                         Qui est-ce?   \n","71                                              Pouah!   \n","149                                 J'ai vu un mouton.   \n","101                             J'ai vu cet enfant-l√†?   \n","67                       Tu n'es pas un homme de paix!   \n","106                  Tu parles de quelle maison (ici)?   \n","103                         L'homme n'est pas mauvais!   \n","72                                    Tu vas vers qui?   \n","89                      L'endroit ce n'est pas par-l√†.   \n","104       Tu as √©t√© et il a √©t√© et moi aussi j'ai √©t√©.   \n","157                               Je parle de ceux-l√†!   \n","90                        Homme et lion ne cohabitent.   \n","33                                       Qui est venu?   \n","117  Viens pour que les enfants soient des travaill...   \n","64   Des boeufs que tu vois, celui-l√† tout pr√®s est...   \n","37                              Je te confie celui-l√†.   \n","118  La pr√©sence de celui-l√† m√™me ne justifie pas q...   \n","161                            Il √©tait Lebou de Yoff.   \n","113                                   J'ai vu l'homme.   \n","49                               Celui-ci serait parti   \n","146        Chez les Peul, les S√©r√®re, et les Niominka.   \n","102                            Sois un √™tre de raison!   \n","63                                      Dis : ¬´ woy ¬ª!   \n","119                                          Pourquoi?   \n","53                            Tu ne partiras donc pas?   \n","7                                J'ai aper√ßu un homme.   \n","139               Fais sortir tout mouton que tu vois!   \n","135                  Tu ne vas pas dans un autre lieu!   \n","138                            Avoir √©t√©, e√ªt √©t√© bon!   \n","36                           Vous, vous n'avez pas √©t√©   \n","10                                Tout cet endroit-l√†?   \n","97                 L'enfant n'a rien donn√© √† celui-ci.   \n","18                            Il est l√† √† l'int√©rieur.   \n","65                   Ceux-ci ne partent peut-√™tre pas!   \n","84                         Aujourd'hui dans la soir√©e.   \n","108                         Redresse-le avec un baton!   \n","76                   L'homme n'a pas vu cet enfant-l√†.   \n","141                         Aucun lion ne s'est √©gar√©.   \n","159  Alors l'homme entra, les enfants le virent, il...   \n","143                                        Quel d√©mon!   \n","60                  Tu as choisi la fille d'une femme.   \n","122                                        L√† o√π tu es   \n","87                                          Celles-ci!   \n","68                         Celui-l√†, lui, il refusera!   \n","120                                       Qu'as-tu vu?   \n","125                                        L'homme ira   \n","30                     Je ne parle pas de ces enfants?   \n","152         Homme, lion, boeuf... allaient de concert.   \n","6                        J'esp√®re que nul n'est sorti?   \n","127                     J'ai d√©j√† vu tous les moutons.   \n","38                              Tu vois, cet homme l√†?   \n","23             Cet homme qui est Laobe de Saint-Louis.   \n","32                               Fais comme tes pairs!   \n","16                                 C'est lui qui part.   \n","99                                 Il a √©t√© quelqu'un!   \n","116                              J'ai aper√ßu un homme.   \n","100        Ces gens qui sont sortis sont des lutteurs.   \n","144                               Je n'y avais pas √©t√©   \n","75   Du reste la g√©n√©rosit√© est une bonne chose dan...   \n","8                                       Toi, tu es l√†!   \n","12                                      Va et reviens!   \n","137                        Il ne s'est pas m√™l√© √† eux.   \n","56                       C'est l'homme qui n'a pas √©t√©   \n","131                  Vous parlez de quelle dame (ici)?   \n","121                                  Vous seriez morts   \n","34                          J'ai vu celui en question.   \n","110         C'est de celui-l√† que parlent les enfants?   \n","45                       Qu'il parte s'il ne veut pas!   \n","19                               Si tu pars, il vient.   \n","5                                             Tu iras?   \n","26       C'est celui-l√† celui-l√† l'un que je te donne.   \n","22                                 Range les affaires!   \n","\n","                                        original_label  \\\n","105                                            √ëan la?   \n","80                                      La ≈ãga wax la.   \n","52                                              Musaa!   \n","132                                   Xam naa xale bi.   \n","59                                  Waa ji ligg√©eykoon   \n","54                                           Mi ≈ãgiiy!   \n","115              Dana √±√´w soo demul ag soo demee itam.   \n","114                     G√≥or gee ni nit la, soo demee!   \n","46                              Gis naa sana xarit yi!   \n","147                               Wool g√≥or gi dul dem   \n","66                                      Gis ≈ãga kooku?   \n","82        Nit ki ci sama wet ak nit kooku mbokk la √±u.   \n","42                     Amul ardo benn J√©eri boo xamul!   \n","91                    Sa yay nee na ci ≈ãgoon dana √±√´w.   \n","35                                 Yaw la ndaw si sopp   \n","0                                 Ma japp nag yee yan?   \n","148                                        Kan dem na?   \n","156                                    Moo doon ganam.   \n","47                            Yooyale deey b√´ggu leen!   \n","14                               G√≥or gi rekk a √±√´wul.   \n","17                                Yaa daan ganu Mustaf   \n","29                           Moontin, xale yi √±√´w na√±u   \n","41                            Kooku dem ku m√´ b√´gg la!   \n","126                   Foofu, g√≥or gi dem, fu rafet la.   \n","48                               Noonu mu demoon foofa   \n","1                                  Te bu fi kenn jog√©!   \n","21                        Gis ≈ãga jig√©en √±eneen √±oo√±u?   \n","24                                      Yan √±oo yeksi?   \n","62                                             Kan la?   \n","71                                                Cam!   \n","149                                    Gis naa am xar.   \n","101                                Gis naa xale booba?   \n","67                                      Doo nitu jamm!   \n","106                              Bii n√©eg ban ≈ãga wax?   \n","103                                         Nit bonul!   \n","72                                     Ci √±an ≈ãga j√´m?   \n","89                                  Ber√´b bi du foofu.   \n","104                    Dem ≈ãga, te dem na, te dem naa.   \n","157                           Yenn xar yooyuu laa wax!   \n","90                          Nit ag gaynde du√±u d√´kk√≥o.   \n","33                                             Ku √±√´w?   \n","117  √ë√´w√´l ndax xale yi di mb√´r te it √±u di ay jamb...   \n","64            Gis ≈ãga nag yii y√©pp, woowuu moo ci g√´n.   \n","37                           De≈ãk naa la boobule woon.   \n","118                      Taxawaayu kooka sax taxul n√´w   \n","161                                 Mu doon Lebu Yoff.   \n","113                                    Gis naa nit ki.   \n","49                                    Kii dafa demkoon   \n","146      Ci P√´l yi ag ci S√©er√©er si, ag ci √ëomi≈ãka yi.   \n","102                                           Dil nit!   \n","63                                         Nil : w√≥oy!   \n","119                                            Lu tax?   \n","53                                      Xanaa doo dem?   \n","7                                     S√©en naa ak nit.   \n","139                          G√©nn√©el m√©pp xar moo gis!   \n","135                                    Demuloo feneen!   \n","138                                  Dem, rafetoon na!   \n","36                                   Y√©en demuleenwoon   \n","10                                       Foofule f√©pp?   \n","97                             Xale bi mayul kii dara.   \n","18                             Mi ≈ãgi foofule ci biir.   \n","65                               √ëii da√±u demul xanaa!   \n","84                                       Tay ci ≈ãgoon.   \n","108                                Jub√´nti ko ak bant!   \n","76                    G√≥or gi gisul xale boobale woon.   \n","141                                Gaynd√© genn r√©erul.   \n","159  Noona g√≥or gi dugg, xale yi gis ka, mu toog, √±...   \n","143                                      Moo di loola!   \n","60                         Tann ≈ãga doomu benn jig√©en.   \n","122                                 Ci foofu ≈ãga taxaw   \n","87                                             Yooyuu!   \n","68                            Kookule, moom, du na≈ãgu!   \n","120                                           Loo gis?   \n","125                                  G√≥or gi dana demi   \n","30                                Waxuma xale yooyale?   \n","152                Nit, gaynd√©, nag... √†ndoon na√±u fi.   \n","6                                    Mbaa kenn g√©nnul?   \n","127                            Gisoon naa xar yi y√©pp.   \n","38                                 Gis ≈ãga nit kookee?   \n","23                              Gor gii di Lawbe Ndar.   \n","32                            Defal naka sa moroom yi!   \n","16                                        Dafa di dem.   \n","99                                             Nit la!   \n","116                                   S√©en naa aw nit.   \n","100                      Nit √±oo√±ii g√©nn ay mb√´r lanu.   \n","144                                     Demuma fa woon   \n","75                 Te dey addina laabiir dafa ci baax.   \n","8                                        Yaw, yaa ≈ãgi!   \n","12                                       Demal ba √±√´w!   \n","137                                Dogul cu seen biir.   \n","56                               G√≥or gi moo demulwoon   \n","131                         Jile jig√©en jan ≈ãgeen wax?   \n","121                                      Deekoon ≈ãgeen   \n","34                                    Gis naa ki woon.   \n","110                             Kooku la xale yiy wax?   \n","45                                  Su b√´ggul, na dem!   \n","19                                  Soo dem√©e, mu √±√´w.   \n","5                                           Da≈ãga dem?   \n","26                            Benn boobule laa la may.   \n","22                                      De√±cal y√´f yi!   \n","\n","                                       predicted_label  \n","105                                             Ku mu?  \n","80                                   Li ≈ãga wax loolu.  \n","52                                               Musaa  \n","132                                   Xam naa xale bi.  \n","59                                  G√≥or gi waxkoon na  \n","54                                    Ma ≈ãgee doon dem  \n","115             Soo demee ag soo demul itam, dana √±√´w.  \n","114                       G√≥or gee ni soo demee nit la  \n","46                    Gis naa sama xarit yeneen yooyuu  \n","147                               Wool g√≥or gi dul dem  \n","66                                        Gis ≈ãga buu?  \n","82                             Nit kookuu ci sama wet.  \n","42                        Wax ji y√©pp, ba√±-≈ãga-√±√´w la.  \n","91                       Sa yay nee dana √±√´w ci ≈ãgoon.  \n","35                                         Yaa √±√´wk√≥on  \n","0                                            Mbaa jan?  \n","148                                            Ku dem?  \n","156                                      Man xar m√©pp.  \n","47                            Yooyale deey b√´ggu leen!  \n","14                                Nit ki rekk a √±√´wul.  \n","17                     Waxtaan ≈ãga ag g√≥or gi doon dem  \n","29                          Moontin nag, b√´gg na√±u dem  \n","41                                      Kenn ki dem na  \n","126                   Foofu, g√≥or gi dem ba mi ≈ãgi fi.  \n","48                                          Su dee dem  \n","1                                G√≥or gi kenn ba√± Moom  \n","21                               Gis ≈ãga xale yooyule?  \n","24                                        Yan √±oo √±√´w?  \n","62                                              Ku mu?  \n","71                                           Ibraayima  \n","149                                       Gis naa xar.  \n","101                                Gis naa booba xale?  \n","67                                       Doo nitu jamm  \n","106                            Boobu n√©eg ban ≈ãga wax?  \n","103                                       G√≥or gi du t  \n","72                                            Loo j√´m?  \n","89                                       Loolule l√©pp.  \n","104            Dem ≈ãga dem te mu dem ag sama xarit ya.  \n","157                                  Yaw moomu laa wax  \n","90                          Nit ag gaynde du√±u d√´kk√≥o.  \n","33                                             Ku √±√´w?  \n","117  √ë√´w√´l ndax xale yi di ay ligg√©eykat, di ay jam...  \n","64            Gis ≈ãga nag yii y√©pp, woowuu moo ci g√´n.  \n","37                                        Waw kookule.  \n","118                        Ci kooku, ndax mu wett√´liku  \n","161                               Dafa doon nitu d√´gg.  \n","113                             Gis na keneen ki woon.  \n","49                                    Kii dafa demkoon  \n","146                            Ci S√©er√©er yi ag P√´l yi  \n","102                                  Dafa di nitu tay.  \n","63                                   Waxal ak √±oo√±ule!  \n","119                                           Lii lan?  \n","53                                            Doo dem?  \n","7                                     S√©en naa am xar.  \n","139                          G√©nn√©el k√©pp nit koo gis!  \n","135                              Seet ≈ãga √±oo√±ale √±an?  \n","138                                       Nit, demkoon  \n","36                                      Y√©en demulwoon  \n","10                                           Ku Loolu?  \n","97                             Xale bi mayul dara kii.  \n","18                                Y√©en mi ≈ãgi ci foofu  \n","65                              Soo demee ag soo demul  \n","84                            Feneen fi b√´tt√≥on foofu.  \n","108                                       Su dee Lawbe  \n","76                               G√≥or gi gisul meneen.  \n","141                                   Menn xar r√©erul.  \n","159                        Noona G√≥or gaa ≈ãgi, mu √±√´w.  \n","143                              J√´nd √±aa menn xar mi.  \n","60                         Tann ≈ãga doomu benn jig√©en.  \n","122                                     Bi ≈ãga dee dem  \n","87                                            Dem na√±u  \n","68                                           Kookule,?  \n","120                                           Koo gis?  \n","125                                        G√≥or gi j√´m  \n","30                                Waxuma yooyale xale?  \n","152                  Nit, gaynd√©, nag, √†ndoon na√±u fi.  \n","6                                     Mbaa kenn demul?  \n","127                        Gis naa xar yi gannaaw yaw.  \n","38                                    Gis ≈ãga nit kee?  \n","23                              Gor gii di Lawbe Ndar.  \n","32                                 Noona sa waajur √±√´w  \n","16                                         Moo di dem.  \n","99                                              Dem na  \n","116                                   S√©en naa am xar.  \n","100                              Xale bi tawat la wax.  \n","144                                         Demkoonuma  \n","75                            Nit kookuu g√©nn laa wax.  \n","8                                           Yaw mi ≈ãga  \n","12                                          Demal rekk  \n","137                                           Waxu la.  \n","56                               G√≥or gi moo demulwoon  \n","131                         Jile jig√©en jan ≈ãgeen wax?  \n","121                                           Du ≈ãgeen  \n","34                                    Gis naa ki woon.  \n","110                                           Baax na?  \n","45                                    Na dem su b√´ggul  \n","19                                  Soo demee, mu √±√´w.  \n","5                                             Doo j√´m?  \n","26                            Benn boobule laa la may.  \n","22                              Noona xale yi set na√±u  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# let us display 100 samples\n","pd.options.display.max_rows = 100\n","df_ft_to_wf.sample(100)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"pytorch1-HleOW5am-py3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07b148611e0445068ec4ae2a289f968d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08fc0c2dc9b94689b80e085b682e54a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07b148611e0445068ec4ae2a289f968d","placeholder":"‚Äã","style":"IPY_MODEL_4b5ea7f279854a01aaa4f5043372df2d","value":"0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"}},"347e2725b013421a951237d46b26d5e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"378d2507f5d5418681817fdbe4f227fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b5ea7f279854a01aaa4f5043372df2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d964dc7e08d48f0be400d45c09f16e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abcbe273e5604d2383a7a1f03e79c682":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_08fc0c2dc9b94689b80e085b682e54a5","IPY_MODEL_bb425d8fef6e41f4bc1f1097477d1502"],"layout":"IPY_MODEL_378d2507f5d5418681817fdbe4f227fd"}},"bb425d8fef6e41f4bc1f1097477d1502":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d964dc7e08d48f0be400d45c09f16e8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_347e2725b013421a951237d46b26d5e3","value":1}}}}},"nbformat":4,"nbformat_minor":0}
