{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Transformer Training\n",
    "-------------------------------\n",
    "\n",
    "In this notebook we will train the custom transformer on multiple GPUs if they are available. The GPUs are in a single machine. In [multiple](_custom_transformer_train_multiple.ipynb), we will use sagemaker to distribute the training of the model over multiple instances. \n",
    "\n",
    "We will pursue the following steps:\n",
    "\n",
    "- Load the libraries\n",
    "- Creating function to recuperate datasets (arguments: char_p, word_p, max_len, end_mark, corpus_1, corpus_2, data_directory)\n",
    "- Training (The model is automatically saved)(arguments: config dictionary initialized before)\n",
    "- Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### French-Wolof v5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolof_translate import *\n",
    "\n",
    "# specify a seed for everything\n",
    "lt.seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Function to recuperate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wolof-translate/wolof_translate/utils/recuperate_datasets.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile wolof-translate/wolof_translate/utils/recuperate_datasets.py\n",
    "from wolof_translate import *\n",
    "\n",
    "def recuperate_datasets(char_p: float, word_p: float, max_len: int, end_mark: int, tokenizer: T5TokenizerFast,\n",
    "                        corpus_1: str = 'french', corpus_2: str = 'wolof', \n",
    "                        train_file: str = 'data/extractions/new_data/train_set.csv', \n",
    "                        test_file: str = 'data/extractions/new_data/test_file.csv'):\n",
    "\n",
    "  # Let us recuperate the end_mark adding option\n",
    "  if end_mark == 1:\n",
    "    # Create augmentation to add on French sentences\n",
    "    fr_augmentation_1 = TransformerSequences(nac.KeyboardAug(aug_char_p=char_p, aug_word_p=word_p,\n",
    "                                                             aug_word_max = max_len),\n",
    "                                          remove_mark_space, delete_guillemet_space, add_mark_space)\n",
    "\n",
    "    fr_augmentation_2 = TransformerSequences(remove_mark_space, delete_guillemet_space, add_mark_space)\n",
    "    \n",
    "  else:\n",
    "    \n",
    "    if end_mark == 2:\n",
    "\n",
    "      end_mark_fn = partial(add_end_mark, end_mark_to_remove = '!', replace = True)\n",
    "    \n",
    "    elif end_mark == 3:\n",
    "\n",
    "      end_mark_fn = partial(add_end_mark)\n",
    "    \n",
    "    elif end_mark == 4:\n",
    "\n",
    "      end_mark_fn = partial(add_end_mark, end_mark_to_remove = '!')\n",
    "    \n",
    "    else:  \n",
    "        \n",
    "        raise ValueError(f'No end mark number {end_mark}')\n",
    "\n",
    "    # Create augmentation to add on French sentences\n",
    "    fr_augmentation_1 = TransformerSequences(nac.KeyboardAug(aug_char_p=char_p, aug_word_p=word_p,\n",
    "                                                             aug_word_max = max_len),\n",
    "                                          remove_mark_space, delete_guillemet_space, add_mark_space, end_mark_fn)\n",
    "    \n",
    "    fr_augmentation_2 = TransformerSequences(remove_mark_space, delete_guillemet_space, add_mark_space, end_mark_fn)\n",
    "    \n",
    "  # Recuperate the train dataset\n",
    "  train_dataset_aug = SentenceDataset(train_file,\n",
    "                                        tokenizer,\n",
    "                                        truncation = False,\n",
    "                                        cp1_transformer = fr_augmentation_1,\n",
    "                                        cp2_transformer = fr_augmentation_2,\n",
    "                                        corpus_1=corpus_1,\n",
    "                                        corpus_2=corpus_2\n",
    "                                        )\n",
    "\n",
    "  # Recuperate the valid dataset\n",
    "  valid_dataset = SentenceDataset(test_file,\n",
    "                                        tokenizer,\n",
    "                                        cp1_transformer = fr_augmentation_2,\n",
    "                                        cp2_transformer = fr_augmentation_2,\n",
    "                                        corpus_1=corpus_1,\n",
    "                                        corpus_2=corpus_2,\n",
    "                                        truncation = False)\n",
    "  \n",
    "  # Return the datasets\n",
    "  return train_dataset_aug, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run wolof-translate/wolof_translate/utils/recuperate_datasets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the configurations\n",
    "config = {\n",
    "    'epochs': 21,\n",
    "    'max_epoch': None,\n",
    "    'log_step': 1,\n",
    "    'metric_for_best_model': 'test_loss',\n",
    "    'metric_objective': 'minimize',\n",
    "    'corpus_1': 'french',\n",
    "    'corpus_2': 'wolof',\n",
    "    'train_file': 'data/extractions/new_data/train_set.csv',\n",
    "    'test_file': 'data/extractions/new_data/valid_set.csv',\n",
    "    'drop_out_rate': 0.291121690756753,\n",
    "    'd_model': 512,\n",
    "    'n_head': 8,\n",
    "    'dim_ff': 2024,\n",
    "    'n_encoders': 6,\n",
    "    'n_decoders': 6,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 0.0,\n",
    "    'char_p': 0.8986208054599546,\n",
    "    'word_p': 0.7876712525708085,\n",
    "    'end_mark': 3,\n",
    "    'label_smoothing': 0.1,\n",
    "    'max_len': 20,\n",
    "    'random_state': 0,\n",
    "    'boundaries': [2, 23, 43, 64, 84, 104],\n",
    "    'batch_sizes': [256, 128, 64, 32, 16, 8, 4],\n",
    "    'batch_size': None, \n",
    "    'warmup_init': False,\n",
    "    'relative_step': False,\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False,\n",
    "    # --------------------> Must be changed when continuing a training\n",
    "    'model_dir': 't5_small_v5_fw',\n",
    "    'new_model_dir': 't5_small_v5_fw',\n",
    "    'continue': False, # --------------------------> Must be changed when continuing training\n",
    "    'logging_dir': 'data/logs/t5_small_fw',\n",
    "    'save_best': True,\n",
    "    'tokenizer_path': 'wolof-translate/wolof_translate/tokenizers/t5_tokenizers/tokenizer_v4.model',\n",
    "    'data_directory': 'data/extractions/new_data/',\n",
    "    'data_file': 'ad_sentences.csv',\n",
    "    'version': 5,\n",
    "    # in the case of a distributed training\n",
    "    'backend': None,\n",
    "    'hosts': [],\n",
    "    'current_host': None,\n",
    "    'num_gpus': 5,\n",
    "    'logger': None,\n",
    "    'return_trainer': True,\n",
    "    'include_split': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wolof-translate/wolof_translate/utils/hg_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile wolof-translate/wolof_translate/utils/hg_training.py\n",
    "from wolof_translate import *\n",
    "import warnings\n",
    "\n",
    "def train(config: dict):\n",
    "    \n",
    "    # ---------------------------------------\n",
    "    # add distribution if necessary (https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-python-sdk/pytorch_mnist/mnist.py)\n",
    "    \n",
    "    logger = config['logger']\n",
    "    \n",
    "    is_distributed = len(config['hosts']) > 1 and config['backend'] is not None\n",
    "    \n",
    "    use_cuda = config['num_gpus'] > 0\n",
    "    \n",
    "    config.update({\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {})\n",
    "\n",
    "    if not logger is None:\n",
    "        \n",
    "        logger.debug(\"Distributed training - {}\".format(is_distributed))\n",
    "        \n",
    "        logger.debug(\"Number of gpus available - {}\".format(config['num_gpus']))\n",
    "        \n",
    "    if is_distributed:\n",
    "        # Initialize the distributed environment.\n",
    "        world_size = len(config['hosts'])\n",
    "        \n",
    "        os.environ[\"WORLD_SIZE\"] = str(world_size)\n",
    "        \n",
    "        host_rank = config['hosts'].index(config['current_host'])\n",
    "        \n",
    "        os.environ[\"RANK\"] = str(host_rank)\n",
    "        \n",
    "        dist.init_process_group(backend=config['backend'], rank=host_rank, world_size=world_size)\n",
    "        \n",
    "        if not logger is None: logger.info(\n",
    "            \"Initialized the distributed environment: '{}' backend on {} nodes. \".format(\n",
    "                config['backend'], dist.get_world_size()\n",
    "            )\n",
    "            + \"Current host rank is {}. Number of gpus: {}\".format(dist.get_rank(), config['num_gpus'])\n",
    "        )\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    # split the data\n",
    "    if config['include_split']: split_data(config['random_state'], config['data_directory'], config['data_file'])\n",
    "\n",
    "    # recuperate the tokenizer\n",
    "    tokenizer = T5TokenizerFast(config['tokenizer_path'])\n",
    "    \n",
    "    # Initialize the model name\n",
    "    model_name = 't5-small'\n",
    "\n",
    "    # import the model with its pre-trained weights\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    # resize the token embeddings\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    # recuperate train and test set\n",
    "    train_dataset, test_dataset = recuperate_datasets(config['char_p'],\n",
    "                                                        config['word_p'], config['max_len'],\n",
    "                                                        config['end_mark'], tokenizer, config['corpus_1'],\n",
    "                                                        config['corpus_2'],\n",
    "                                                        config['train_file'], config['test_file'])\n",
    "    \n",
    "    # initialize the evaluation object\n",
    "    evaluation = TranslationEvaluation(tokenizer, train_dataset.decode)\n",
    "\n",
    "    # let us initialize the trainer\n",
    "    trainer = ModelRunner(model = model, version=config['version'], seed = 0, evaluation = evaluation, optimizer = Adafactor)\n",
    "\n",
    "    #-------------------------------------\n",
    "    # in the case when the linear learning rate scheduler with warmup is used\n",
    "    \n",
    "    # let us calculate the appropriate warmup steps (let us take a max epoch of 100)\n",
    "    # length = len(train_dataset)\n",
    "\n",
    "    # n_steps = length // config['batch_size']\n",
    "\n",
    "    # num_steps = config['max_epoch'] * n_steps\n",
    "\n",
    "    # warmup_steps = (config['max_epoch'] * n_steps) * config['warmup_ratio']\n",
    "\n",
    "    # Initialize the scheduler parameters\n",
    "    # scheduler_args = {'num_warmup_steps': warmup_steps, 'num_training_steps': num_steps}\n",
    "    #-------------------------------------\n",
    "\n",
    "    # Initialize the optimizer parameters\n",
    "    optimizer_args = {\n",
    "        'lr': config['learning_rate'],\n",
    "        'weight_decay': config['weight_decay'],\n",
    "        # 'betas': (0.9, 0.98),\n",
    "        'warmup_init': config['warmup_init'],\n",
    "        'relative_step': config['relative_step']\n",
    "    }\n",
    "\n",
    "    # ----------------------------\n",
    "    # initialize the bucket samplers for distributed environment\n",
    "    boundaries = config['boundaries']\n",
    "    batch_sizes = config['batch_sizes']\n",
    "\n",
    "    train_sampler = SequenceLengthBatchSampler(train_dataset,\n",
    "                                                boundaries = boundaries,\n",
    "                                                batch_sizes = batch_sizes)\n",
    "\n",
    "    test_sampler = SequenceLengthBatchSampler(test_dataset,\n",
    "                                                boundaries = boundaries,\n",
    "                                                batch_sizes = batch_sizes)\n",
    "\n",
    "    # ------------------------------\n",
    "    # initialize a bucket sampler with fixed batch size in the case of single machine\n",
    "    # with parallelization on multiple gpus\n",
    "    # train_sampler = BucketSampler(train_dataset, config['batch_size'])\n",
    "\n",
    "    # test_sampler = BucketSampler(test_dataset, config['batch_size'])\n",
    "    \n",
    "    # ------------------------------\n",
    "\n",
    "    # Initialize the loaders parameters\n",
    "    train_loader_args = {'batch_sampler': train_sampler, 'collate_fn': collate_fn,\n",
    "                        'num_workers': config['num_workers'], 'pin_memory': config['pin_memory']}\n",
    "\n",
    "    test_loader_args = {'batch_sampler': test_sampler, 'collate_fn': collate_fn,\n",
    "                        'num_workers': config['num_workers'], 'pin_memory': config['pin_memory']}\n",
    "\n",
    "    # Add the datasets and hyperparameters to trainer\n",
    "    trainer.compile(train_dataset, test_dataset, tokenizer, train_loader_args,\n",
    "                    test_loader_args, optimizer_kwargs = optimizer_args,\n",
    "                    # lr_scheduler=get_linear_schedule_with_warmup,\n",
    "                    # lr_scheduler_kwargs=scheduler_args,\n",
    "                    predict_with_generate = True,\n",
    "                    hugging_face = True,\n",
    "                    is_distributed=is_distributed,\n",
    "                    logging_dir=config['logging_dir'],\n",
    "                    dist=dist\n",
    "                    )\n",
    "\n",
    "    # load the model\n",
    "    trainer.load(config['model_dir'], load_best = not config['continue'])\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(config['epochs'] - trainer.current_epoch, auto_save = True, log_step = config['log_step'], saving_directory=config['new_model_dir'], save_best = config['save_best'],\n",
    "                  metric_for_best_model = config['metric_for_best_model'], metric_objective = config['metric_objective'])\n",
    "    \n",
    "    if config['return_trainer']:\n",
    "        \n",
    "        return trainer\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below train and save if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wolof_translate.utils.hg_training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.41batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.23batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.5114653375916345, 'test_loss': 2.7761967109911367, 'bleu': 2.266399494949495, 'gen_len': 13.217162121212121}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:10<04:22, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.40batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.98batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.42468051816903, 'test_loss': 2.6943533950381813, 'bleu': 2.4339045454545456, 'gen_len': 12.560631313131314}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:22<04:17, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.49batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.98batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.3517192236461786, 'test_loss': 2.634918566906091, 'bleu': 2.3541358585858587, 'gen_len': 13.671723737373739}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:33<04:06, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.39batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.99batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.2777167031615697, 'test_loss': 2.590723254463889, 'bleu': 2.4163686868686867, 'gen_len': 14.858569696969699}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:44<03:56, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 10: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.29batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.13batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.223224872882271, 'test_loss': 2.6014229601079766, 'bleu': 2.3500434343434353, 'gen_len': 11.525243434343436}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:54<03:35, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 11: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:06<00:00,  7.09batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.07batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.1764694935607425, 'test_loss': 2.5320193478555386, 'bleu': 2.618009595959596, 'gen_len': 12.217173737373738}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [01:06<03:29, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 12: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.34batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.32batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.1303964158841753, 'test_loss': 2.5434020721551147, 'bleu': 2.744057070707071, 'gen_len': 11.03030404040404}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [01:15<03:09, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 13: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.40batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.02batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.0804740817089926, 'test_loss': 2.5099077537806354, 'bleu': 2.563536868686869, 'gen_len': 12.616167676767677}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [01:27<03:03, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 14: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.33batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.17batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.0455848709229487, 'test_loss': 2.52968150919134, 'bleu': 3.1110070707070716, 'gen_len': 11.015133333333333}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [01:36<02:47, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 15: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.37batches/s]\n",
      "Test batch number 3:  14%|█▍        | 1/7 [00:00<00:01,  4.58batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.09batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.9926729948742343, 'test_loss': 2.5232395668222445, 'bleu': 2.864400505050505, 'gen_len': 11.368671212121212}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [01:46<02:34, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 16: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.33batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.00batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.9518446629745607, 'test_loss': 2.5120888189835986, 'bleu': 2.8665191919191924, 'gen_len': 11.176735858585861}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [01:56<02:23, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 17: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.32batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.07batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.9194935183974475, 'test_loss': 2.5144295403451626, 'bleu': 3.2974808080808082, 'gen_len': 11.974762626262626}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [02:06<02:11, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 18: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:06<00:00,  7.16batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.09batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.8835548197144882, 'test_loss': 2.5088922808868714, 'bleu': 2.9407616161616166, 'gen_len': 11.671747474747475}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [02:18<02:05, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 19: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.24batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.14batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.842434627055217, 'test_loss': 2.5319321829863273, 'bleu': 2.9120015151515157, 'gen_len': 10.03538484848485}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [02:28<01:53, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 20: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.34batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.05batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.8105094993061694, 'test_loss': 2.497430601505318, 'bleu': 2.875379292929293, 'gen_len': 11.111095454545456}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [02:39<01:45, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 21: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.26batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.26batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.7762581537525384, 'test_loss': 2.4893684290876292, 'bleu': 3.0885227272727276, 'gen_len': 11.181794444444446}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [02:50<01:36, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 22: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.25batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:02<00:00,  2.47batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.7403693729228116, 'test_loss': 2.5324128372500643, 'bleu': 2.810114141414142, 'gen_len': 9.777791919191921}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [02:59<01:22, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 23: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.26batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.31batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.6994967128113057, 'test_loss': 2.506803387343282, 'bleu': 2.749485858585859, 'gen_len': 10.61617676767677}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [03:09<01:11, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 24: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.27batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.06batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.6744661027309942, 'test_loss': 2.52493722992714, 'bleu': 2.8192727272727276, 'gen_len': 12.17172676767677}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [03:19<01:00, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 25: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.19batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.08batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.6336687108069412, 'test_loss': 2.5186826291710447, 'bleu': 3.126379797979798, 'gen_len': 11.545429292929294}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [03:29<00:50, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 26: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.23batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.04batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.595658942463276, 'test_loss': 2.5293197246512986, 'bleu': 3.3226782828282833, 'gen_len': 11.797979292929293}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [03:39<00:40, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 27: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.20batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.08batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.5806173942723958, 'test_loss': 2.5458529356754185, 'bleu': 3.031581818181818, 'gen_len': 12.040430303030304}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [03:49<00:30, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 28: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.21batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.96batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.5406483437802352, 'test_loss': 2.5303414036529235, 'bleu': 3.12880101010101, 'gen_len': 12.808074747474748}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [03:59<00:20, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 29: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:05<00:00,  7.20batches/s]\n",
      "Test batch number 3:  14%|█▍        | 1/7 [00:00<00:01,  4.60batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.09batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.5093537220692503, 'test_loss': 2.5414568535005206, 'bleu': 3.5049414141414146, 'gen_len': 12.07069797979798}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [04:09<00:10, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 30: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/43 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 44: 100%|██████████| 43/43 [00:06<00:00,  7.15batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.11batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.4772157685655651, 'test_loss': 2.5400167571173777, 'bleu': 3.1790439393939396, 'gen_len': 12.126261111111113}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [04:20<00:00, 10.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# with warnings.catch_warnings():\n",
    "    # warnings.simplefilter(\"ignore\")\n",
    "trainer = train(config)\n",
    "\n",
    "# save if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# with warnings.catch_warnings():\n",
    "    # warnings.simplefilter(\"ignore\")\n",
    "trainer = train(config)\n",
    "\n",
    "# save if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation batch number 2:   0%|          | 0/6 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation batch number 7: 100%|██████████| 6/6 [00:03<00:00,  1.64batches/s]\n"
     ]
    }
   ],
   "source": [
    "if not trainer is None:\n",
    "    \n",
    "    # recuperate the tokenizer\n",
    "    tokenizer = T5TokenizerFast(config['tokenizer_path'])\n",
    "    \n",
    "    # recuperate the test dataset\n",
    "    # initialize the transformation sequence\n",
    "    end_mark_fn = partial(add_end_mark)\n",
    "    augmentation = TransformerSequences(remove_mark_space, delete_guillemet_space, add_mark_space, end_mark_fn)\n",
    "\n",
    "\n",
    "    # let us get the test set\n",
    "    test_dataset = SentenceDataset(f\"{config['data_directory']}test_set.csv\",\n",
    "                                            tokenizer = tokenizer,\n",
    "                                            cp1_transformer = augmentation,\n",
    "                                            cp2_transformer = augmentation,\n",
    "                                            corpus_1=config['corpus_1'],\n",
    "                                            corpus_2=config['corpus_2'],\n",
    "                                            truncation = False)\n",
    "\n",
    "    # initialize the bucket samplers for distributed environment\n",
    "    boundaries = config['boundaries']\n",
    "    batch_sizes = config['batch_sizes']\n",
    "\n",
    "    test_sampler = SequenceLengthBatchSampler(test_dataset,\n",
    "                                                boundaries = boundaries,\n",
    "                                                batch_sizes = batch_sizes)\n",
    "\n",
    "    test_loader_args = {'batch_sampler': test_sampler, 'collate_fn': collate_fn,\n",
    "                            'num_workers': config['num_workers'], 'pin_memory': config['pin_memory']}\n",
    "\n",
    "    metrics, prediction = trainer.evaluate(test_dataset, test_loader_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 2.249727627243659,\n",
       " 'bleu': 2.7937212121212123,\n",
       " 'gen_len': 7.303034343434343}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentences</th>\n",
       "      <th>translations</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C'est des femmes.</td>\n",
       "      <td>Jigéen lanu.</td>\n",
       "      <td>Nit la.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cet homme qui avait voulu.</td>\n",
       "      <td>Góor gii bëggóon.</td>\n",
       "      <td>Góor gii ŋga dem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Par ici?</td>\n",
       "      <td>Ci fii?</td>\n",
       "      <td>Ci wax?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qu'il entre!</td>\n",
       "      <td>Na dugg ci biir su bëggée!</td>\n",
       "      <td>Koo dem!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>À l'intérieur si tu ne veux pas!</td>\n",
       "      <td>Ci biir soo bëggul!</td>\n",
       "      <td>Ci biir!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Ceux-là, cependant, sont des cases. Celle qui ...</td>\n",
       "      <td>Waaw lii nag ay néegi ñax la, néegi ñax bi ci ...</td>\n",
       "      <td>Lii ab néeg la, néeg bi dañ kooale, néeg bi d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>On voit sur la photo beaucoup de personnes sor...</td>\n",
       "      <td>Ñu gis ci nataal bi ay nit ñu bari ñu génn ci ...</td>\n",
       "      <td>Nataal bii de gis naa ci benn bool bu weex ak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Ceux-là, aussi, sont des gendarmes. Ils siègen...</td>\n",
       "      <td>Ñii moom tamit ay takk-der nañ. Ñi ñi ngi bàyy...</td>\n",
       "      <td>Lii ab néeg la, néeg bi dañ kooale, néeg bi d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Ceci, cependant, on a l'habitude de faire les ...</td>\n",
       "      <td>Lii nag dañ ciy faral di def ndugg maanaam jig...</td>\n",
       "      <td>Waaw nataal bii de ay bunt yu dóomu-taal moo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>À l'intérieur de cette photo je vois beaucoup ...</td>\n",
       "      <td>Ci biir nataal bii maa ngi ciy gis ay batã, ba...</td>\n",
       "      <td>Waaw nataal bii de ay bunt yu dóomu-taal moo ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    original_sentences  \\\n",
       "0                                    C'est des femmes.   \n",
       "1                           Cet homme qui avait voulu.   \n",
       "2                                             Par ici?   \n",
       "3                                         Qu'il entre!   \n",
       "4                     À l'intérieur si tu ne veux pas!   \n",
       "..                                                 ...   \n",
       "193  Ceux-là, cependant, sont des cases. Celle qui ...   \n",
       "194  On voit sur la photo beaucoup de personnes sor...   \n",
       "195  Ceux-là, aussi, sont des gendarmes. Ils siègen...   \n",
       "196  Ceci, cependant, on a l'habitude de faire les ...   \n",
       "197  À l'intérieur de cette photo je vois beaucoup ...   \n",
       "\n",
       "                                          translations  \\\n",
       "0                                         Jigéen lanu.   \n",
       "1                                    Góor gii bëggóon.   \n",
       "2                                              Ci fii?   \n",
       "3                           Na dugg ci biir su bëggée!   \n",
       "4                                  Ci biir soo bëggul!   \n",
       "..                                                 ...   \n",
       "193  Waaw lii nag ay néegi ñax la, néegi ñax bi ci ...   \n",
       "194  Ñu gis ci nataal bi ay nit ñu bari ñu génn ci ...   \n",
       "195  Ñii moom tamit ay takk-der nañ. Ñi ñi ngi bàyy...   \n",
       "196  Lii nag dañ ciy faral di def ndugg maanaam jig...   \n",
       "197  Ci biir nataal bii maa ngi ciy gis ay batã, ba...   \n",
       "\n",
       "                                           predictions  \n",
       "0                                              Nit la.  \n",
       "1                                    Góor gii ŋga dem.  \n",
       "2                                              Ci wax?  \n",
       "3                                             Koo dem!  \n",
       "4                                             Ci biir!  \n",
       "..                                                 ...  \n",
       "193   Lii ab néeg la, néeg bi dañ kooale, néeg bi d...  \n",
       "194   Nataal bii de gis naa ci benn bool bu weex ak...  \n",
       "195   Lii ab néeg la, néeg bi dañ kooale, néeg bi d...  \n",
       "196   Waaw nataal bii de ay bunt yu dóomu-taal moo ...  \n",
       "197   Waaw nataal bii de ay bunt yu dóomu-taal moo ...  \n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wolof-French v5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolof_translate import *\n",
    "\n",
    "# specify a seed for everything\n",
    "lt.seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Function to recuperate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wolof-translate/wolof_translate/utils/recuperate_datasets.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile wolof-translate/wolof_translate/utils/recuperate_datasets.py\n",
    "from wolof_translate import *\n",
    "\n",
    "def recuperate_datasets(char_p: float, word_p: float, max_len: int, end_mark: int, tokenizer: T5TokenizerFast,\n",
    "                        corpus_1: str = 'french', corpus_2: str = 'wolof', \n",
    "                        train_file: str = 'data/extractions/new_data/train_set.csv', \n",
    "                        test_file: str = 'data/extractions/new_data/test_file.csv'):\n",
    "\n",
    "  # Let us recuperate the end_mark adding option\n",
    "  if end_mark == 1:\n",
    "    # Create augmentation to add on French sentences\n",
    "    fr_augmentation_1 = TransformerSequences(nac.KeyboardAug(aug_char_p=char_p, aug_word_p=word_p,\n",
    "                                                             aug_word_max = max_len),\n",
    "                                          remove_mark_space, delete_guillemet_space, add_mark_space)\n",
    "\n",
    "    fr_augmentation_2 = TransformerSequences(remove_mark_space, delete_guillemet_space, add_mark_space)\n",
    "    \n",
    "  else:\n",
    "    \n",
    "    if end_mark == 2:\n",
    "\n",
    "      end_mark_fn = partial(add_end_mark, end_mark_to_remove = '!', replace = True)\n",
    "    \n",
    "    elif end_mark == 3:\n",
    "\n",
    "      end_mark_fn = partial(add_end_mark)\n",
    "    \n",
    "    elif end_mark == 4:\n",
    "\n",
    "      end_mark_fn = partial(add_end_mark, end_mark_to_remove = '!')\n",
    "    \n",
    "    else:  \n",
    "        \n",
    "        raise ValueError(f'No end mark number {end_mark}')\n",
    "\n",
    "    # Create augmentation to add on French sentences\n",
    "    fr_augmentation_1 = TransformerSequences(nac.KeyboardAug(aug_char_p=char_p, aug_word_p=word_p,\n",
    "                                                             aug_word_max = max_len),\n",
    "                                          remove_mark_space, delete_guillemet_space, add_mark_space, end_mark_fn)\n",
    "    \n",
    "    fr_augmentation_2 = TransformerSequences(remove_mark_space, delete_guillemet_space, add_mark_space, end_mark_fn)\n",
    "    \n",
    "  # Recuperate the train dataset\n",
    "  train_dataset_aug = SentenceDataset(train_file,\n",
    "                                        tokenizer,\n",
    "                                        truncation = False,\n",
    "                                        cp1_transformer = fr_augmentation_1,\n",
    "                                        cp2_transformer = fr_augmentation_2,\n",
    "                                        corpus_1=corpus_1,\n",
    "                                        corpus_2=corpus_2\n",
    "                                        )\n",
    "\n",
    "  # Recuperate the valid dataset\n",
    "  valid_dataset = SentenceDataset(test_file,\n",
    "                                        tokenizer,\n",
    "                                        cp1_transformer = fr_augmentation_2,\n",
    "                                        cp2_transformer = fr_augmentation_2,\n",
    "                                        corpus_1=corpus_1,\n",
    "                                        corpus_2=corpus_2,\n",
    "                                        truncation = False)\n",
    "  \n",
    "  # Return the datasets\n",
    "  return train_dataset_aug, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run wolof-translate/wolof_translate/utils/recuperate_datasets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the configurations\n",
    "config = {\n",
    "    'epochs': 50,\n",
    "    'max_epoch': None,\n",
    "    'log_step': 1,\n",
    "    'metric_for_best_model': 'test_loss',\n",
    "    'metric_objective': 'minimize',\n",
    "    'corpus_1': 'wolof',\n",
    "    'corpus_2': 'french',\n",
    "    'train_file': 'data/extractions/new_data/train_set.csv',\n",
    "    'test_file': 'data/extractions/new_data/valid_set.csv',\n",
    "    'drop_out_rate': 0.291121690756753,\n",
    "    'd_model': 512,\n",
    "    'n_head': 8,\n",
    "    'dim_ff': 2024,\n",
    "    'n_encoders': 6,\n",
    "    'n_decoders': 6,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 0.0,\n",
    "    'char_p': 0.5275538662009825,\n",
    "    'word_p': 0.8981250882159111,\n",
    "    'end_mark': 3,\n",
    "    'label_smoothing': 0.1,\n",
    "    'max_len': 20,\n",
    "    'random_state': 0,\n",
    "    'boundaries': [2, 23, 43, 64, 84, 104],\n",
    "    'batch_sizes': [256, 128, 64, 32, 16, 8, 4],\n",
    "    'batch_size': None, \n",
    "    'warmup_init': False,\n",
    "    'relative_step': False,\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False,\n",
    "    # --------------------> Must be changed when continuing a training\n",
    "    'model_dir': 't5_small_v5_wf',\n",
    "    'new_model_dir': 't5_small_v5_wf',\n",
    "    'continue': True, # --------------------------> Must be changed when continuing training\n",
    "    'logging_dir': 'data/logs/t5_small_wf',\n",
    "    'save_best': True,\n",
    "    'tokenizer_path': 'wolof-translate/wolof_translate/tokenizers/t5_tokenizers/tokenizer_v4.model',\n",
    "    'data_directory': 'data/extractions/new_data/',\n",
    "    'data_file': 'ad_sentences.csv',\n",
    "    'version': 5,\n",
    "    # in the case of a distributed training\n",
    "    'backend': None,\n",
    "    'hosts': [],\n",
    "    'current_host': None,\n",
    "    'num_gpus': 5,\n",
    "    'logger': None,\n",
    "    'return_trainer': True,\n",
    "    'include_split': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wolof-translate/wolof_translate/utils/hg_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile wolof-translate/wolof_translate/utils/hg_training.py\n",
    "from wolof_translate import *\n",
    "import warnings\n",
    "\n",
    "def train(config: dict):\n",
    "    \n",
    "    # ---------------------------------------\n",
    "    # add distribution if necessary (https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-python-sdk/pytorch_mnist/mnist.py)\n",
    "    \n",
    "    logger = config['logger']\n",
    "    \n",
    "    is_distributed = len(config['hosts']) > 1 and config['backend'] is not None\n",
    "    \n",
    "    use_cuda = config['num_gpus'] > 0\n",
    "    \n",
    "    config.update({\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {})\n",
    "\n",
    "    if not logger is None:\n",
    "        \n",
    "        logger.debug(\"Distributed training - {}\".format(is_distributed))\n",
    "        \n",
    "        logger.debug(\"Number of gpus available - {}\".format(config['num_gpus']))\n",
    "        \n",
    "    if is_distributed:\n",
    "        # Initialize the distributed environment.\n",
    "        world_size = len(config['hosts'])\n",
    "        \n",
    "        os.environ[\"WORLD_SIZE\"] = str(world_size)\n",
    "        \n",
    "        host_rank = config['hosts'].index(config['current_host'])\n",
    "        \n",
    "        os.environ[\"RANK\"] = str(host_rank)\n",
    "        \n",
    "        dist.init_process_group(backend=config['backend'], rank=host_rank, world_size=world_size)\n",
    "        \n",
    "        if not logger is None: logger.info(\n",
    "            \"Initialized the distributed environment: '{}' backend on {} nodes. \".format(\n",
    "                config['backend'], dist.get_world_size()\n",
    "            )\n",
    "            + \"Current host rank is {}. Number of gpus: {}\".format(dist.get_rank(), config['num_gpus'])\n",
    "        )\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    # split the data\n",
    "    if config['include_split']: split_data(config['random_state'], config['data_directory'], config['data_file'])\n",
    "\n",
    "    # recuperate the tokenizer\n",
    "    tokenizer = T5TokenizerFast(config['tokenizer_path'])\n",
    "    \n",
    "    # Initialize the model name\n",
    "    model_name = 't5-small'\n",
    "\n",
    "    # import the model with its pre-trained weights\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    # resize the token embeddings\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    # recuperate train and test set\n",
    "    train_dataset, test_dataset = recuperate_datasets(config['char_p'],\n",
    "                                                        config['word_p'], config['max_len'],\n",
    "                                                        config['end_mark'], tokenizer, config['corpus_1'],\n",
    "                                                        config['corpus_2'],\n",
    "                                                        config['train_file'], config['test_file'])\n",
    "    \n",
    "    # initialize the evaluation object\n",
    "    evaluation = TranslationEvaluation(tokenizer, train_dataset.decode)\n",
    "\n",
    "    # let us initialize the trainer\n",
    "    trainer = ModelRunner(model = model, version=config['version'], seed = 0, evaluation = evaluation, optimizer = Adafactor)\n",
    "\n",
    "    #-------------------------------------\n",
    "    # in the case when the linear learning rate scheduler with warmup is used\n",
    "    \n",
    "    # let us calculate the appropriate warmup steps (let us take a max epoch of 100)\n",
    "    # length = len(train_dataset)\n",
    "\n",
    "    # n_steps = length // config['batch_size']\n",
    "\n",
    "    # num_steps = config['max_epoch'] * n_steps\n",
    "\n",
    "    # warmup_steps = (config['max_epoch'] * n_steps) * config['warmup_ratio']\n",
    "\n",
    "    # Initialize the scheduler parameters\n",
    "    # scheduler_args = {'num_warmup_steps': warmup_steps, 'num_training_steps': num_steps}\n",
    "    #-------------------------------------\n",
    "\n",
    "    # Initialize the optimizer parameters\n",
    "    optimizer_args = {\n",
    "        'lr': config['learning_rate'],\n",
    "        'weight_decay': config['weight_decay'],\n",
    "        # 'betas': (0.9, 0.98),\n",
    "        'warmup_init': config['warmup_init'],\n",
    "        'relative_step': config['relative_step']\n",
    "    }\n",
    "\n",
    "    # ----------------------------\n",
    "    # initialize the bucket samplers for distributed environment\n",
    "    boundaries = config['boundaries']\n",
    "    batch_sizes = config['batch_sizes']\n",
    "\n",
    "    train_sampler = SequenceLengthBatchSampler(train_dataset,\n",
    "                                                boundaries = boundaries,\n",
    "                                                batch_sizes = batch_sizes)\n",
    "\n",
    "    test_sampler = SequenceLengthBatchSampler(test_dataset,\n",
    "                                                boundaries = boundaries,\n",
    "                                                batch_sizes = batch_sizes)\n",
    "\n",
    "    # ------------------------------\n",
    "    # initialize a bucket sampler with fixed batch size in the case of single machine\n",
    "    # with parallelization on multiple gpus\n",
    "    # train_sampler = BucketSampler(train_dataset, config['batch_size'])\n",
    "\n",
    "    # test_sampler = BucketSampler(test_dataset, config['batch_size'])\n",
    "    \n",
    "    # ------------------------------\n",
    "\n",
    "    # Initialize the loaders parameters\n",
    "    train_loader_args = {'batch_sampler': train_sampler, 'collate_fn': collate_fn,\n",
    "                        'num_workers': config['num_workers'], 'pin_memory': config['pin_memory']}\n",
    "\n",
    "    test_loader_args = {'batch_sampler': test_sampler, 'collate_fn': collate_fn,\n",
    "                        'num_workers': config['num_workers'], 'pin_memory': config['pin_memory']}\n",
    "\n",
    "    # Add the datasets and hyperparameters to trainer\n",
    "    trainer.compile(train_dataset, test_dataset, tokenizer, train_loader_args,\n",
    "                    test_loader_args, optimizer_kwargs = optimizer_args,\n",
    "                    # lr_scheduler=get_linear_schedule_with_warmup,\n",
    "                    # lr_scheduler_kwargs=scheduler_args,\n",
    "                    predict_with_generate = True,\n",
    "                    hugging_face = True,\n",
    "                    is_distributed=is_distributed,\n",
    "                    logging_dir=config['logging_dir'],\n",
    "                    dist=dist\n",
    "                    )\n",
    "\n",
    "    # load the model\n",
    "    trainer.load(config['model_dir'], load_best = not config['continue'])\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(config['epochs'] - trainer.current_epoch, auto_save = True, log_step = config['log_step'], saving_directory=config['new_model_dir'], save_best = config['save_best'],\n",
    "                  metric_for_best_model = config['metric_for_best_model'], metric_objective = config['metric_objective'])\n",
    "    \n",
    "    if config['return_trainer']:\n",
    "        \n",
    "        return trainer\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below train and save if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wolof_translate.utils.hg_training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.64batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.75batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 3.025106288450267, 'test_loss': 3.0578086183528708, 'bleu': 1.330838383838384, 'gen_len': 19.964669191919192}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:09<03:43,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.60batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.96batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.888327236344436, 'test_loss': 2.932071378736785, 'bleu': 1.3087666666666669, 'gen_len': 16.136386363636365}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:19<03:49,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.56batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.95batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.7692004121759877, 'test_loss': 2.849424434430672, 'bleu': 1.4679595959595961, 'gen_len': 16.43939494949495}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:30<03:44, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.53batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.77batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.663334673526241, 'test_loss': 2.788634987792584, 'bleu': 1.5415909090909092, 'gen_len': 16.055548484848487}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:41<03:39, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 10: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.53batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:04<00:00,  1.74batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.5818608457117724, 'test_loss': 2.7095980692391444, 'bleu': 1.8785469696969699, 'gen_len': 13.808072222222222}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:51<03:32, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 11: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.60batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:04<00:00,  1.73batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.4917865036259266, 'test_loss': 2.6703582159196495, 'bleu': 2.21769898989899, 'gen_len': 15.121238383838381}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [01:02<03:23, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 12: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.59batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.82batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.4179942812970907, 'test_loss': 2.6327337351712314, 'bleu': 2.2543474747474748, 'gen_len': 16.212137373737374}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [01:13<03:12, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 13: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.58batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:02<00:00,  2.44batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.362779219643667, 'test_loss': 2.6032126094355728, 'bleu': 2.085411616161616, 'gen_len': 12.797957575757577}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [01:23<02:56, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 14: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.43batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.75batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.292300087677235, 'test_loss': 2.561257794649914, 'bleu': 2.3605954545454546, 'gen_len': 15.70708686868687}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [01:34<02:49, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 15: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.51batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.86batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.2410037018391695, 'test_loss': 2.5626361875823047, 'bleu': 2.6147292929292933, 'gen_len': 15.65151666666667}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [01:43<02:33, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 16: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.47batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.07batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.1965482313372076, 'test_loss': 2.527354256071226, 'bleu': 2.484096969696969, 'gen_len': 13.2525}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [01:54<02:23, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 17: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.45batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.93batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.1407281559226945, 'test_loss': 2.497628905556419, 'bleu': 2.9381095959595958, 'gen_len': 14.272710606060606}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [02:04<02:14, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 18: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.53batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.76batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.0784834201844107, 'test_loss': 2.497836967911384, 'bleu': 2.899290404040405, 'gen_len': 15.631311111111112}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [02:14<02:01, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 19: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.49batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.89batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.05341728807325, 'test_loss': 2.481565406828216, 'bleu': 2.6675671717171716, 'gen_len': 16.57071616161616}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [02:24<01:53, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 20: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.41batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:04<00:00,  1.68batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 2.002027263300544, 'test_loss': 2.461949396615077, 'bleu': 3.311483333333334, 'gen_len': 15.63637171717172}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [02:36<01:45, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 21: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.41batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.78batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.9573933808280268, 'test_loss': 2.440742301218437, 'bleu': 3.6045080808080816, 'gen_len': 16.005034343434343}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [02:47<01:36, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 22: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.43batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.82batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.9155979083354977, 'test_loss': 2.457561742175709, 'bleu': 4.930958080808081, 'gen_len': 16.479829292929296}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [02:56<01:23, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 23: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:05<00:00,  6.38batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.87batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.8723649379952205, 'test_loss': 2.454600731531779, 'bleu': 4.282234343434344, 'gen_len': 15.005060101010102}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [03:06<01:11, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 24: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.52batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.75batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.8316938165318433, 'test_loss': 2.439377421080464, 'bleu': 4.814183333333334, 'gen_len': 16.166674242424243}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [03:17<01:02, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 25: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.48batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:04<00:00,  1.73batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.7985615124814047, 'test_loss': 2.456443261618566, 'bleu': 4.883823232323234, 'gen_len': 16.010118686868687}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [03:27<00:51, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 26: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.44batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.79batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.7628219490334776, 'test_loss': 2.4467217958334717, 'bleu': 4.541628787878789, 'gen_len': 16.626272222222223}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [03:36<00:40, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 27: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.44batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.14batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.7351601044638563, 'test_loss': 2.4418391073592987, 'bleu': 4.809811616161616, 'gen_len': 13.74244191919192}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [03:45<00:29,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 28: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.43batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.84batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.6943547316249008, 'test_loss': 2.4684393875526665, 'bleu': 4.866994444444445, 'gen_len': 15.510115151515153}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [03:55<00:19,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 29: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.45batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.76batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.6575911842065094, 'test_loss': 2.433619892958439, 'bleu': 5.274884848484849, 'gen_len': 15.570673232323234}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [04:06<00:10, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 30: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/32 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 33: 100%|██████████| 32/32 [00:04<00:00,  6.44batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.98batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.6241250370666247, 'test_loss': 2.4374969884602713, 'bleu': 4.865085353535354, 'gen_len': 15.782837878787882}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [04:15<00:00, 10.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# with warnings.catch_warnings():\n",
    "    # warnings.simplefilter(\"ignore\")\n",
    "trainer = train(config)\n",
    "\n",
    "# save if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 31: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.74batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.99batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.6031698549495028, 'test_loss': 2.48018310286782, 'bleu': 5.082866161616162, 'gen_len': 14.929275757575759}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:09<02:54,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 32: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.66batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.83batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.56718063592006, 'test_loss': 2.4559369737451733, 'bleu': 5.706334848484849, 'gen_len': 15.72220505050505}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:18<02:50,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 33: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.62batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.79batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.5363509753774343, 'test_loss': 2.462271097934608, 'bleu': 4.999496464646464, 'gen_len': 16.78284292929293}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:28<02:42,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 34: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.68batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.76batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.4993085373171824, 'test_loss': 2.4647206417237872, 'bleu': 5.2097772727272735, 'gen_len': 16.76260101010101}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:38<02:33,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 35: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.65batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.18batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.4714344369505565, 'test_loss': 2.52563930039454, 'bleu': 5.206471717171718, 'gen_len': 13.84849494949495}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:47<02:20,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 36: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.63batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.97batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.4317455306828286, 'test_loss': 2.4958050130593654, 'bleu': 4.841671717171717, 'gen_len': 14.994919191919193}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:56<02:11,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 37: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.71batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:04<00:00,  1.71batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.4115574834544322, 'test_loss': 2.4901456832885747, 'bleu': 5.709369696969697, 'gen_len': 16.217164646464646}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:06<02:04,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 38: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.58batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.84batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.3803954382134265, 'test_loss': 2.5174373015008786, 'bleu': 5.082258080808081, 'gen_len': 14.899022222222225}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:16<01:55,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 39: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.64batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.33batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.3583325295603628, 'test_loss': 2.531702978442414, 'bleu': 5.318264646464646, 'gen_len': 12.757601515151515}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:24<01:42,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 40: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.52batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.91batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.3195869691721784, 'test_loss': 2.5422805367094097, 'bleu': 5.3666823232323235, 'gen_len': 15.166634848484849}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:34<01:34,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 41: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.67batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.86batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.297868958158934, 'test_loss': 2.5708903038140503, 'bleu': 4.87779494949495, 'gen_len': 15.833323232323233}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:44<01:25,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 42: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.62batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.88batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.2691234390449861, 'test_loss': 2.5951932126825508, 'bleu': 5.3977151515151505, 'gen_len': 15.232341414141414}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:53<01:15,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 43: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.54batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.87batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.2421140144853033, 'test_loss': 2.590024545939282, 'bleu': 6.711281818181818, 'gen_len': 13.772703535353537}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [02:03<01:06,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 44: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:04<00:00,  6.61batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.78batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.2233287424018762, 'test_loss': 2.5700962663900975, 'bleu': 5.34880303030303, 'gen_len': 16.36870303030303}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [02:12<00:57,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 45: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.53batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.81batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.2071754128061318, 'test_loss': 2.6190930038991604, 'bleu': 5.325007070707071, 'gen_len': 15.06563181818182}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [02:22<00:48,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 46: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.56batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.79batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.167711973529613, 'test_loss': 2.5440620123737996, 'bleu': 6.071860606060607, 'gen_len': 15.292952525252526}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [02:32<00:38,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 47: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.55batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.83batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.151745243541128, 'test_loss': 2.610427420548719, 'bleu': 6.87779696969697, 'gen_len': 14.500006060606061}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [02:42<00:28,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 48: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.51batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.76batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.1192170883152472, 'test_loss': 2.5948631040977714, 'bleu': 5.628589393939393, 'gen_len': 16.36867777777778}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:51<00:19,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 49: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.54batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  2.09batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.0961309396564627, 'test_loss': 2.650956584949686, 'bleu': 7.354377777777779, 'gen_len': 14.343432323232324}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [03:01<00:09,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 50: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 2:   0%|          | 0/33 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batch number 34: 100%|██████████| 33/33 [00:05<00:00,  6.53batches/s]\n",
      "Test batch number 2:   0%|          | 0/7 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test batch number 8: 100%|██████████| 7/7 [00:03<00:00,  1.94batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics: {'train_loss': 1.0732805997670491, 'test_loss': 2.6258159791580358, 'bleu': 6.835085353535354, 'gen_len': 14.914118686868687}\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:10<00:00,  9.53s/it]\n"
     ]
    }
   ],
   "source": [
    "# with warnings.catch_warnings():\n",
    "    # warnings.simplefilter(\"ignore\")\n",
    "trainer = train(config)\n",
    "\n",
    "# save if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation batch number 2:   0%|          | 0/6 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation batch number 7: 100%|██████████| 6/6 [00:02<00:00,  2.03batches/s]\n"
     ]
    }
   ],
   "source": [
    "if not trainer is None:\n",
    "    \n",
    "    # recuperate the tokenizer\n",
    "    tokenizer = T5TokenizerFast(config['tokenizer_path'])\n",
    "    \n",
    "    # recuperate the test dataset\n",
    "    # initialize the transformation sequence\n",
    "    end_mark_fn = partial(add_end_mark)\n",
    "    augmentation = TransformerSequences(remove_mark_space, delete_guillemet_space, add_mark_space, end_mark_fn)\n",
    "\n",
    "\n",
    "    # let us get the test set\n",
    "    test_dataset = SentenceDataset(f\"{config['data_directory']}test_set.csv\",\n",
    "                                            tokenizer = tokenizer,\n",
    "                                            cp1_transformer = augmentation,\n",
    "                                            cp2_transformer = augmentation,\n",
    "                                            corpus_1=config['corpus_1'],\n",
    "                                            corpus_2=config['corpus_2'],\n",
    "                                            truncation = False)\n",
    "\n",
    "    # initialize the bucket samplers for distributed environment\n",
    "    boundaries = config['boundaries']\n",
    "    batch_sizes = config['batch_sizes']\n",
    "\n",
    "    test_sampler = SequenceLengthBatchSampler(test_dataset,\n",
    "                                                boundaries = boundaries,\n",
    "                                                batch_sizes = batch_sizes)\n",
    "\n",
    "    test_loader_args = {'batch_sampler': test_sampler, 'collate_fn': collate_fn,\n",
    "                            'num_workers': config['num_workers'], 'pin_memory': config['pin_memory']}\n",
    "\n",
    "    metrics, prediction = trainer.evaluate(test_dataset, test_loader_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 2.876970546414154,\n",
       " 'bleu': 8.537555050505052,\n",
       " 'gen_len': 7.237385353535354}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentences</th>\n",
       "      <th>translations</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L'homme est parti je crois!</td>\n",
       "      <td>Ma defe góor gi dem na!</td>\n",
       "      <td>Góor gi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu as vu l'homme?</td>\n",
       "      <td>Gis ŋga nit ki?</td>\n",
       "      <td>Gis ŋga nit ki woon?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tu vois ces femmes-là?</td>\n",
       "      <td>Gis ŋga jigéen ñooñii?</td>\n",
       "      <td>Gis ŋga xale bii?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sois un être de raison!</td>\n",
       "      <td>Dil nit!</td>\n",
       "      <td>Saal!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je veux que l'homme vienne.</td>\n",
       "      <td>Bëgg naa góor gi ñëw.</td>\n",
       "      <td>Degguma.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Ceux-là, cependant, sont des cases. Celle qui ...</td>\n",
       "      <td>Waaw lii nag ay néegi ñax la, néegi ñax bi ci ...</td>\n",
       "      <td>Lii, ag kër la, kër gu yàqu. Boo ko gisee xam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>On voit sur la photo beaucoup de personnes sor...</td>\n",
       "      <td>Ñu gis ci nataal bi ay nit ñu bari ñu génn ci ...</td>\n",
       "      <td>Waxu ñu ngi ci ag kër la, kër gu yàqu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Ceux-là, aussi, sont des gendarmes. Ils siègen...</td>\n",
       "      <td>Ñii moom tamit ay takk-der nañ. Ñi ñi ngi bàyy...</td>\n",
       "      <td>Lii nag ëe kaas la ak palaat. Nu ciy xelli ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Ceci, cependant, on a l'habitude de faire les ...</td>\n",
       "      <td>Lii nag dañ ciy faral di def ndugg maanaam jig...</td>\n",
       "      <td>nii nag mu mel ni benn bërëb jullikaay wala.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>À l'intérieur de cette photo je vois beaucoup ...</td>\n",
       "      <td>Ci biir nataal bii maa ngi ciy gis ay batã, ba...</td>\n",
       "      <td>Juróom-ñetteelu nataal bi seetlu naa ci cere ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    original_sentences  \\\n",
       "0                          L'homme est parti je crois!   \n",
       "1                                    Tu as vu l'homme?   \n",
       "2                               Tu vois ces femmes-là?   \n",
       "3                              Sois un être de raison!   \n",
       "4                          Je veux que l'homme vienne.   \n",
       "..                                                 ...   \n",
       "193  Ceux-là, cependant, sont des cases. Celle qui ...   \n",
       "194  On voit sur la photo beaucoup de personnes sor...   \n",
       "195  Ceux-là, aussi, sont des gendarmes. Ils siègen...   \n",
       "196  Ceci, cependant, on a l'habitude de faire les ...   \n",
       "197  À l'intérieur de cette photo je vois beaucoup ...   \n",
       "\n",
       "                                          translations  \\\n",
       "0                              Ma defe góor gi dem na!   \n",
       "1                                      Gis ŋga nit ki?   \n",
       "2                               Gis ŋga jigéen ñooñii?   \n",
       "3                                             Dil nit!   \n",
       "4                                Bëgg naa góor gi ñëw.   \n",
       "..                                                 ...   \n",
       "193  Waaw lii nag ay néegi ñax la, néegi ñax bi ci ...   \n",
       "194  Ñu gis ci nataal bi ay nit ñu bari ñu génn ci ...   \n",
       "195  Ñii moom tamit ay takk-der nañ. Ñi ñi ngi bàyy...   \n",
       "196  Lii nag dañ ciy faral di def ndugg maanaam jig...   \n",
       "197  Ci biir nataal bii maa ngi ciy gis ay batã, ba...   \n",
       "\n",
       "                                           predictions  \n",
       "0                                             Góor gi!  \n",
       "1                                 Gis ŋga nit ki woon?  \n",
       "2                                    Gis ŋga xale bii?  \n",
       "3                                                Saal!  \n",
       "4                                             Degguma.  \n",
       "..                                                 ...  \n",
       "193   Lii, ag kër la, kër gu yàqu. Boo ko gisee xam...  \n",
       "194             Waxu ñu ngi ci ag kër la, kër gu yàqu.  \n",
       "195   Lii nag ëe kaas la ak palaat. Nu ciy xelli ka...  \n",
       "196   nii nag mu mel ni benn bërëb jullikaay wala.....  \n",
       "197   Juróom-ñetteelu nataal bi seetlu naa ci cere ...  \n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
