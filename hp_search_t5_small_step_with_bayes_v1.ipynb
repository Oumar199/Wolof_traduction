{"cells":[{"cell_type":"markdown","metadata":{"id":"YTsVWwCgLAJl"},"source":["Hyper-parameter search with the Text-To-Text Transformer 🤖 (Bayes)\n","-----------------------------------\n","\n","In this project, we will make transfer learning with the Text-To-Text Transformer (T5) model to translate French sentences into Wolof sentences and vice-versa. The method we will use for the hyperparameter search is Bayesian Hyperparameter Optimization. We will use the `wandb` library to evaluate the model more efficiently with `Parallel coordinate` and `Parameter Importance` charts. After finding the best model, we will take the checkpoints and continue the training in another notebook. Let us dive into the process."]},{"cell_type":"markdown","source":["We want to know the best combination of values of the following hyperparameters:\n","\n","- **learning rate** $\\sim Log U(1e-3, 1e-5)$\n","- **weight decay** $\\in \\{0.0, 0.1, 0.2, 0.3, 0.4, 0.5\\}$\n","- **random state** (seed of the data splitting generator) $\\in range(1, 100)$ \n","\n","1. For the translation from French to Wolof\n","\n","  - **fr_char_p** (probability of modifying a character from a French word) $\\sim U(0.0, 0.9)$\n","  - **fr_word_p** (probability of modifying a word from a French sentence) $\\sim U(0.0, 0.9)$\n","\n","2. For the translation from Wolof to French\n","\n","  - **wf_char_p** (probability of modifying a character from a Wolof word) $\\sim U(0.0, 0.9)$\n","  - **fr_word_p** (probability of modifying a word from a Wolof sentence) $\\sim U(0.0, 0.9)$\n","\n","\n","The Bayes method requires to define a metric. We will evaluate the model on the test set, so the metric that we will add in the hyperparameter setting can be either the `cross entropy loss` calculated on the test set or `BLEU` score. Since it is a machine translation task, a BLEU score will be more useful as evaluation metric. \n","\n","**Objective**: We will try to `maximize the metric.` For the moment, we want to obtain a `BLEU` score greater than `50`."],"metadata":{"id":"ibHZ3hipw20S"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0NmODpFxX2Ik"},"outputs":[],"source":["# let us extend the paths of the system\n","import sys\n","\n","path = \"/content/drive/MyDrive/Memoire/subject2/T5/\"\n","\n","sys.path.extend([path, f\"{path}new_data\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqaQuyv3XvHl","outputId":"44cee857-5393-4848-f113-34d858bce73b","executionInfo":{"status":"ok","timestamp":1683116583334,"user_tz":0,"elapsed":4,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["env: WANDB_LOG_MODEL=true\n","env: WANDB_NOTEBOOK_NAME=training_gpt2_2.ipynb\n","env: WANDB_API_KEY=237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\n"]}],"source":["# define wandb environment\n","%env WANDB_LOG_MODEL=true\n","%env WANDB_NOTEBOOK_NAME=training_gpt2_2.ipynb\n","%env WANDB_API_KEY=237a8450cd2568ea1c8e1f8e0400708e79b6b4ee "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOALYu0I1th2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683116592727,"user_tz":0,"elapsed":9396,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}},"outputId":"d688dc59-5ba3-453c-f53c-195d22d11e1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -qq wandb --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqElKFkPLAJq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683116689589,"user_tz":0,"elapsed":96869,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}},"outputId":"d8758bff-6acc-436c-92c2-e28fa860486b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h2023-05-03 12:24:15.297231: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-03 12:24:16.304879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-05-03 12:24:17.603282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 12:24:17.603753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-03 12:24:17.603990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fr-core-news-lg==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.5.0/fr_core_news_lg-3.5.0-py3-none-any.whl (571.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-lg==3.5.0) (3.5.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.22.4)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.0.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.0.12)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.0.9)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.3.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (8.1.9)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.1.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (4.65.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.4.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (67.7.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.8)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.10.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.10.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.0.8)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (6.3.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.27.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.1.2)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.7.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (23.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.1.2)\n","Installing collected packages: fr-core-news-lg\n","Successfully installed fr-core-news-lg-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_lg')\n"]}],"source":["!pip install evaluate -qq\n","!pip install sacrebleu -qq\n","# !pip install optuna -qq\n","!pip install transformers -qq \n","!pip install tokenizers -qq\n","!pip install nlpaug -qq\n","!pip install ray[tune] -qq\n","!python -m spacy download fr_core_news_lg "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dF37F8_nLAJr"},"outputs":[],"source":["# let us import all necessary libraries\n","from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, T5TokenizerFast, set_seed\n","from wolof_translate.utils.sent_transformers import TransformerSequences\n","from wolof_translate.data.dataset_v2 import T5SentenceDataset\n","from wolof_translate.utils.sent_corrections import *\n","from sklearn.model_selection import train_test_split\n","from nlpaug.augmenter import char as nac\n","from torch.utils.data import DataLoader\n","# from datasets  import load_metric # make pip install evaluate instead\n","# and pip install sacrebleu for instance\n","from functools import partial\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import evaluate\n","import wandb\n","import torch\n"]},{"cell_type":"markdown","metadata":{"id":"ypAj4KXBLAJs"},"source":["We will create two models: \n","\n","- One translating the french corpus to a wolof corpus [french_to_wolof](#french-to-wolof)\n","- One translating the wolof corpus to a french corpus [wolof_to_french](#wolof-to-french)"]},{"cell_type":"markdown","metadata":{"id":"mtgeyZoxLAJs"},"source":["--------------"]},{"cell_type":"markdown","metadata":{"id":"19MVywzSLAJt"},"source":["## French to wolof"]},{"cell_type":"markdown","metadata":{"id":"n4tP0YGyLAJt"},"source":["### Configure dataset 🔠"]},{"cell_type":"markdown","metadata":{"id":"e6dLQ3poLAJu"},"source":["We will split the sentences between train (for the model's training), validation (to find the best performance) and test (to make final predictions) sets. The samples added as train, validation and test sets are identified according to `the random state.` We will tune the random state to the groups that guarantee the model's best fitting. In other words, we want the model to identify many training sentences and generalize that learning on the validation sentences. It is not sometimes the case, mainly when using a small dataset like ours. \n","\n","Notice that when continuing to train the model from the checkpoints we will use the train_set plus the validation set. Then we need to save the dataset part which doesn't contain the test set for latter. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GyCZiVSvLAJu"},"outputs":[],"source":["def split_data(random_state: int = 50):\n","  \"\"\"Split data between train, validation and test sets\n","\n","  Args:\n","    random_state (int): the seed of the splitting generator. Defaults to 50\n","  \"\"\"\n","  # load the corpora and split into train and test sets\n","  corpora = pd.read_csv(f\"{path}new_data/corpora_v3.csv\")\n","\n","  train_set, test_set = train_test_split(corpora, test_size=0.1, random_state=random_state)\n","\n","  # let us save the final training set when performing\n","\n","  train_set, valid_set = train_test_split(train_set, test_size=0.1, random_state=random_state)\n","\n","  train_set.to_csv(f\"{path}new_data/final_train_set.csv\", index=False)\n","\n","  # let us save the sets\n","  train_set.to_csv(f\"{path}new_data/train_set.csv\", index=False)\n","\n","  valid_set.to_csv(f\"{path}new_data/valid_set.csv\", index=False)\n","\n","  test_set.to_csv(f\"{path}new_data/test_set.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"WahLNKJ0LAJv"},"source":["Let us load the French and Wolof corpora's common tokenizer."]},{"cell_type":"code","source":["# recuperate the tokenizer from a json file\n","tokenizer = T5TokenizerFast(tokenizer_file=f\"{path}wolof_translate/tokenizers/t5_tokenizers/tokenizer_v1.json\")\n"],"metadata":{"id":"QyrikXX6eBPd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The following function will make recuperate the datasets."],"metadata":{"id":"d1UTpkFTlXr5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BIjksuH9LAJv"},"outputs":[],"source":["def recuperate_datasets(fr_char_p: float, fr_word_p: float):\n","\n","  # Create augmentation to add on French sentences\n","  fr_augmentation = TransformerSequences(nac.KeyboardAug(aug_char_p=fr_char_p, aug_word_p=fr_word_p),\n","                                        remove_mark_space, delete_guillemet_space)\n","\n","  # Recuperate the train dataset\n","  train_dataset_aug = T5SentenceDataset(f\"{path}new_data/train_set.csv\",\n","                                        tokenizer,\n","                                        truncation = True,\n","                                        cp1_transformer = fr_augmentation)\n","\n","  # Recuperate the test dataset\n","  valid_dataset = T5SentenceDataset(f\"{path}new_data/valid_set.csv\",\n","                                        tokenizer,\n","                                        truncation = True)\n","  \n","  # Return the datasets\n","  return train_dataset_aug, valid_dataset"]},{"cell_type":"markdown","metadata":{"id":"eLlcsICXpOmj"},"source":["### Configure hyperparameter search ⚙️"]},{"cell_type":"markdown","metadata":{"id":"JR9MwAFQppk0"},"source":["We have to configure the search space, the search method and the metric. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSNJ1s_ypZWg","outputId":"aa5d6a50-1133-439f-93a9-5ebbdef294c9","executionInfo":{"status":"ok","timestamp":1683116730475,"user_tz":0,"elapsed":1717,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moumar-kane\u001b[0m (\u001b[33moumar-kane-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["Create sweep with ID: 6sh11rwz\n","Sweep URL: https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz\n"]}],"source":["wandb.login(key=\"237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\")\n","\n","# hyperparameters\n","sweep_config = {\n","    'method': 'bayes',\n","    'metric':{\n","          'goal': 'maximize',\n","          'name': 'bleu'\n","      },\n","    'parameters':\n","    {\n","      'epochs': {\n","          'value': 1\n","      },\n","      'batch_size': {\n","          'values': [5, 16, 32]\n","      },\n","      'learning_rate': {\n","          'distribution': 'log_uniform_values',\n","          'min': 1e-5,\n","          'max': 1e-3\n","      },\n","      'weight_decay': {\n","          'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n","      },\n","     'fr_char_p': {\n","         'min': 0.0,\n","         'max': 0.9\n","     },\n","     'fr_word_p': {\n","          'min': 0.0,\n","          'max': 0.9\n","     },\n","     'random_state': {\n","         'values': list(range(1, 101))\n","     }\n","    }\n","}\n","\n","# Initialize the hyperparameter search\n","sweep_id = wandb.sweep(sweep_config, project = \"small-t5-fw-translation-bayes-hpsearch-v1\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0vhzP3IaLAJv"},"source":["### Configure the model and the evaluation function ⚙️"]},{"cell_type":"markdown","metadata":{"id":"Ts_cesDLLAJw"},"source":["Let us recuperate the model and resize the token embeddings.\n","\n","**Note**: In the first training we want to use the t5-small. If we don't obtain good results we will take the t5-base which contains more parameters. See bellow the configuration of the t5-small and the t5-base models, respectively."]},{"cell_type":"code","source":["small_model_name = 't5-small'\n","base_model_name = 't5-base'\n","\n","# import the small model with its pre-trained weights\n","small_model = AutoModelForSeq2SeqLM.from_pretrained(small_model_name)\n","\n","# import the base model with its pre-trained weights\n","base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n"],"metadata":{"id":"6cFW4alLpcb8","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["25ba4187ab414a32bc8cc7e6b3bcec36","7703984450514848962f292a2f98175d","3838dfe4ca5c4a039a988f4a51a0a649","b336daea2494491d8f67d665a9f33feb","7cbcf9b2af694cda8439268d0de5830d","e3046341e9b544dfa0fa991f848e0653","7bb70d123d114a8999298a4fa7e026ed","65bcbecabe6d4b1f89687f98434844a4","f32c78f1a67e4713aef1bc310984548b","b02b552a40934f9ebf80311493578a9a","7903729d3cb44d0ab3e487e3b7e86641","f47d648c89b8440da88cb4706bb8cb0b","4d75baac7f5e426c91c245c9b120e073","b30d3a9bcf044b858bb7c1a2e37bf2ab","5c5e44fd528f4c4599da35e93fcdfa41","1cd4fca6977143de9dabb02ae1d84aee","b48bc669b3d14854a1dbc542c78278b6","a6da1c422b7142a885dc25b85ce9b2e4","3f71cdb4b40846f5a6945cb20ac305d3","8f9b88804a3e49dea9cfb828c79e7471","a6d30d7c28a24fbf8a386fd89219a066","d50a068f5fad4a1fb3b31e4d902af7fc","6e551484691146a1a4ffc691b3e31b3a","cac472aa50f743fd807746f52d8297be","d8fa36133073423ca21b85fcc4bbc73a","690489ab48064ecc9928725f0fc757b0","443ee13f9e74424385dba88872acccc7","709bf3e0057348f999728b7f2ae7a24d","55246c37fa6f4d9b9e9b5bfecff7b524","88105371ff6d4ce6ba31a8f1f93c9a9f","122cc67ba2154264aef5a1064415a8a4","e5055dbbaa5b4baa8e26f4acb9154509","90f89f13e03e443c9f5d2c94d847e1cb","f7409ed29b654d7a867512710207c1f2","38f3257e9c724169bbaa66841ac5e156","1598deaf97204dbead6563c70a1d6ed3","145e9f9ef1b44794825596e82f752a24","9b846fbb443b429e8f6234f49e67802c","32cb2b67a1384512b073aafab1ab75ed","2fe7f282361c421a97fdb024cd37acef","8266651e18e54bc2ae0925c41064597f","f2310bae595941e8b84efba8f7160654","b59555a6d9cb4ba2bdca1a2510ae8c39","0ca000477e874feaa155af878e55d16e","2f53a0c11c36481e9762de60cdb35658","540fed32ad2048ae9c5b0a165a882175","48b418359cb940bb8766003e944aa666","8c3415dc54c249beb2649c0b327db858","c6aaeb90053d48cb8d024ae2ac3ea0b4","6ae8c304dc9a4567a3d44662a2292edf","609c88cee4d64dd89045b2cd9d6b49cd","f533177f7e9f453495e50e88692f2fe5","d8f2ad480b384fa5aef0d87a0369d7ae","b10c0a7129914a9fbcc192b864b3e52a","b441fdcf927246ceba830abd8458dd5c","35269e3136ac4235b9db25b994e46462","957a89c5d0fc414fa0c5e13e8c9bcdc1","a7e436b7d338419196ee7fe3b3bca2a7","fb9363a0864947e483b48f7ec94439c4","a68753999b2448998a87442528432944","20910b55c2d14131804e1f74794f26e4","3fe317d2e0c54629a6c31800f32e90e4","2bd161d8995240adb21babbef3723450","16084242755e4663b3688ce4fd41c98d","88f17b318c604bb1bc660deb24a77055","01b746ac6dad49d1b30af3f086b0e4a4"]},"executionInfo":{"status":"ok","timestamp":1683116761953,"user_tz":0,"elapsed":31494,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}},"outputId":"cbd758ed-950b-4855-9271-ced54268e955"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25ba4187ab414a32bc8cc7e6b3bcec36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f47d648c89b8440da88cb4706bb8cb0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e551484691146a1a4ffc691b3e31b3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7409ed29b654d7a867512710207c1f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f53a0c11c36481e9762de60cdb35658"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35269e3136ac4235b9db25b994e46462"}},"metadata":{}}]},{"cell_type":"code","source":["# print the small configuration\n","small_model.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTGhq0I3q1qU","executionInfo":{"status":"ok","timestamp":1683116761956,"user_tz":0,"elapsed":47,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}},"outputId":"5d95d3a3-e39f-468a-bbbc-0e5e6955b27a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5Config {\n","  \"_name_or_path\": \"t5-small\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 6,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# print the base configuration\n","base_model.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5jH56DMrLd3","executionInfo":{"status":"ok","timestamp":1683116761960,"user_tz":0,"elapsed":47,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}},"outputId":"136e50ab-7567-405b-cc7b-e26b60be2a0f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5Config {\n","  \"_name_or_path\": \"t5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["The small model have the same architecture than the original transformer of Ashish Vaswani, Noam Shazeer, and all. in the article [Attention_is_all_you_need](https://arxiv.org/pdf/1706.03762).\n","\n","The base model contains more parameters since it use 12 heads in place of 8 and, 12 stack decoder layers in place of 6, the number of feed forward features is of 3072 so 1024 more features than the small one and the embedding dimension is of 768 in place of 512. The base model contains exactly 220 millions of parameters which is a huge number. But since it is pre-trained, we can directly make transfer learning with already trained weights. The base model was firstly explained in the article [Text_To_Text_Transformer](https://arxiv.org/pdf/1910.10683). "],"metadata":{"id":"ehutM-8GrSld"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CO1jx85eLAJw"},"outputs":[],"source":["def gpt2_model_init(tokenizer):\n","\n","  # Initialize the model name\n","  model_name = 't5-small'\n","\n","  # import the model with its pre-trained weights\n","  model = AutoModelForSeq2SeqLM.from_pretrained(small_model_name)\n","\n","  # resize the token embeddings\n","  model.resize_token_embeddings(len(tokenizer))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"R8I3tm4WLAJx"},"source":["Let us evaluate the predictions with the `bleu` metric. The metric computation that we will use, we got it from the following `HugginFace` tutorial [translation](https://huggingface.co/docs/transformers/tasks/translation). We will use a class to add more parameters if we want."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IerZolDNLAJx","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["608ebf4a67ac45e0bfd3cab84d3de321","6c26590307574cb99d48756fd2bfb069","09002a94f7424804a3126729c84370b1","753b741a9d71465bb2d7d0e97c205ede","2c7681a6529141a686665edcc5631e3b","2316d73857ed4c9abb97bef21ef03af6","47cd33eeb5e742788f827ec77e3184b5","012cc5119cc74c7c9aaa75eefddabe88","ef27cbed736045cca5b84abfd0f34bed","bcf11d04edc24770a51379b334c6b304","1ba0d9c454e243568248c904b769ae17"]},"executionInfo":{"status":"ok","timestamp":1683116761963,"user_tz":0,"elapsed":48,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}},"outputId":"c2de3b6d-c872-4155-fcb6-3927b4113d21"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"608ebf4a67ac45e0bfd3cab84d3de321"}},"metadata":{}}],"source":["# %%writefile wolof-translate/wolof_translate/utils/evaluation.py\n","from tokenizers import Tokenizer\n","from typing import *\n","import numpy as np\n","import evaluate\n","\n","class TranslationEvaluation:\n","    \n","    def __init__(self, \n","                 tokenizer: Tokenizer,\n","                 decoder: Union[Callable, None] = None,\n","                 metric = evaluate.load('sacrebleu'),\n","                 ):\n","        \n","        self.tokenizer = tokenizer\n","        \n","        self.decoder = decoder\n","        \n","        self.metric = metric\n","    \n","    def postprocess_text(self, preds, labels):\n","        \n","        preds = [pred.strip() for pred in preds]\n","        \n","        labels = [[label.strip()] for label in labels]\n","        \n","        return preds, labels\n","\n","    def compute_metrics(self, eval_preds):\n","\n","        preds, labels = eval_preds\n","\n","        if isinstance(preds, tuple):\n","        \n","            preds = preds[0]\n","        \n","        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","        \n","        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","        decoded_preds, decoded_labels = self.postprocess_text(decoded_preds, decoded_labels)\n","\n","        result = self.metric.compute(predictions=decoded_preds, references=decoded_labels)\n","        \n","        result = {\"bleu\": result[\"score\"]}\n","\n","        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","        \n","        result[\"gen_len\"] = np.mean(prediction_lens)\n","        \n","        result = {k: round(v, 4) for k, v in result.items()}\n","        \n","        return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEvlO5mtLAJx"},"outputs":[],"source":["# %run wolof-translate/wolof_translate/utils/evaluation.py"]},{"cell_type":"markdown","source":["Let us initialize the evaluation object."],"metadata":{"id":"YtmCXLk29eJu"}},{"cell_type":"code","source":["evaluation = TranslationEvaluation(tokenizer)"],"metadata":{"id":"67e2stQk9g-C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xT17hB19LAJy"},"source":["### Searching for the best parameters 🕖"]},{"cell_type":"markdown","metadata":{"id":"XQ5evOG5LAJw"},"source":["Let us define the data collator."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgVN115tLAJw"},"outputs":[],"source":["def data_collator(batch):\n","    \"\"\"Generate a batch of data to provide to trainer\n","\n","    Args:\n","        batch (_type_): The batch\n","\n","    Returns:\n","        dict: A dictionary containing the ids, the attention mask and the labels\n","    \"\"\"\n","    input_ids = torch.stack([b[0].squeeze(0) for b in batch])\n","    \n","    attention_mask = torch.stack([b[1].squeeze(0) for b in batch])\n","    \n","    labels = torch.stack([b[2].squeeze(0) for b in batch])\n","    \n","    return {'input_ids': input_ids, 'attention_mask': attention_mask,\n","            'labels': labels}"]},{"cell_type":"markdown","metadata":{"id":"Ry3DmkBuLAJy"},"source":["Let us initialize the training arguments and search for the best model. The latter will be saved as an artefact inside our `wandb` project."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["9bcc87ca7cab45e2b3ed5df6690a3bc6","6c065ae652364dc7b3ce274aa03879dd","f2e1f38455f7429fb94d8f882ab0dd91","b7acb877f8d140e4afdb9280c679f715","8497dc2a290e4ccb9953e0c62417077d","02b214a69b314a049af7efc732bac64d","72cbe39203594c9c8da77cc0f1f2ca6e","86fa209c456a4b0b99e40d523cbb1acf"]},"id":"D_yP2Ny6LAJy","outputId":"a568ca34-0670-4a39-e2db-39fec33549a9","executionInfo":{"status":"ok","timestamp":1683118596146,"user_tz":0,"elapsed":1833759,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wltbvc5x with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.5610117724717548\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.12342420562500794\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.0431038733614627e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_122603-wltbvc5x</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/wltbvc5x' target=\"_blank\">soft-sweep-1</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/wltbvc5x' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/wltbvc5x</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:39, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.662300</td>\n","      <td>1.433833</td>\n","      <td>0.003900</td>\n","      <td>7.625000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0039</td></tr><tr><td>eval/gen_len</td><td>7.625</td></tr><tr><td>eval/loss</td><td>1.43383</td></tr><tr><td>eval/runtime</td><td>3.5668</td></tr><tr><td>eval/samples_per_second</td><td>26.915</td></tr><tr><td>eval/steps_per_second</td><td>1.682</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6623</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.66234</td></tr><tr><td>train/train_runtime</td><td>40.1064</td></tr><tr><td>train/train_samples_per_second</td><td>21.393</td></tr><tr><td>train/train_steps_per_second</td><td>4.289</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">soft-sweep-1</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/wltbvc5x' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/wltbvc5x</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_122603-wltbvc5x/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gkmqnvbd with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.8538971073103738\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.5232831372715491\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.228389805763303e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_122710-gkmqnvbd</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gkmqnvbd' target=\"_blank\">worldly-sweep-2</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gkmqnvbd' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gkmqnvbd</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.010500</td>\n","      <td>1.665153</td>\n","      <td>0.012100</td>\n","      <td>11.072900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0121</td></tr><tr><td>eval/gen_len</td><td>11.0729</td></tr><tr><td>eval/loss</td><td>1.66515</td></tr><tr><td>eval/runtime</td><td>3.6952</td></tr><tr><td>eval/samples_per_second</td><td>25.98</td></tr><tr><td>eval/steps_per_second</td><td>1.624</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>2.0105</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.01048</td></tr><tr><td>train/train_runtime</td><td>31.8097</td></tr><tr><td>train/train_samples_per_second</td><td>26.973</td></tr><tr><td>train/train_steps_per_second</td><td>1.698</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">worldly-sweep-2</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gkmqnvbd' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gkmqnvbd</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_122710-gkmqnvbd/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vk6fwkk6 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.15590715281340134\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.7092879701301565\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00020053145545767287\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_122802-vk6fwkk6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/vk6fwkk6' target=\"_blank\">gallant-sweep-3</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/vk6fwkk6' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/vk6fwkk6</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.509800</td>\n","      <td>1.353554</td>\n","      <td>0.000000</td>\n","      <td>4.166700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0</td></tr><tr><td>eval/gen_len</td><td>4.1667</td></tr><tr><td>eval/loss</td><td>1.35355</td></tr><tr><td>eval/runtime</td><td>2.4253</td></tr><tr><td>eval/samples_per_second</td><td>39.583</td></tr><tr><td>eval/steps_per_second</td><td>2.474</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.5098</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.5098</td></tr><tr><td>train/train_runtime</td><td>25.1419</td></tr><tr><td>train/train_samples_per_second</td><td>34.126</td></tr><tr><td>train/train_steps_per_second</td><td>2.148</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">gallant-sweep-3</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/vk6fwkk6' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/vk6fwkk6</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_122802-vk6fwkk6/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e5pxdvom with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.7587565400869124\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6327287294437675\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.742187785854545e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_122848-e5pxdvom</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e5pxdvom' target=\"_blank\">dry-sweep-4</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e5pxdvom' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e5pxdvom</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:32, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.145700</td>\n","      <td>1.127707</td>\n","      <td>0.000000</td>\n","      <td>4.333300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0</td></tr><tr><td>eval/gen_len</td><td>4.3333</td></tr><tr><td>eval/loss</td><td>1.12771</td></tr><tr><td>eval/runtime</td><td>2.4588</td></tr><tr><td>eval/samples_per_second</td><td>39.043</td></tr><tr><td>eval/steps_per_second</td><td>2.44</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1457</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.14571</td></tr><tr><td>train/train_runtime</td><td>29.5702</td></tr><tr><td>train/train_samples_per_second</td><td>29.016</td></tr><tr><td>train/train_steps_per_second</td><td>5.817</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">dry-sweep-4</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e5pxdvom' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e5pxdvom</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_122848-e5pxdvom/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8n7277tq with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.48846262862636913\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.16150612020472957\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.838933595295595e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_122939-8n7277tq</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/8n7277tq' target=\"_blank\">true-sweep-5</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/8n7277tq' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/8n7277tq</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.706400</td>\n","      <td>2.282822</td>\n","      <td>0.071800</td>\n","      <td>16.250000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0718</td></tr><tr><td>eval/gen_len</td><td>16.25</td></tr><tr><td>eval/loss</td><td>2.28282</td></tr><tr><td>eval/runtime</td><td>2.2885</td></tr><tr><td>eval/samples_per_second</td><td>41.949</td></tr><tr><td>eval/steps_per_second</td><td>2.622</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.7064</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.7064</td></tr><tr><td>train/train_runtime</td><td>24.3625</td></tr><tr><td>train/train_samples_per_second</td><td>35.218</td></tr><tr><td>train/train_steps_per_second</td><td>2.217</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">true-sweep-5</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/8n7277tq' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/8n7277tq</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_122939-8n7277tq/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e43ltml7 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.8142547858484664\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.3472530033110374\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00011493660993613652\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123025-e43ltml7</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e43ltml7' target=\"_blank\">vague-sweep-6</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e43ltml7' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e43ltml7</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.689600</td>\n","      <td>1.480706</td>\n","      <td>0.002800</td>\n","      <td>7.322900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0028</td></tr><tr><td>eval/gen_len</td><td>7.3229</td></tr><tr><td>eval/loss</td><td>1.48071</td></tr><tr><td>eval/runtime</td><td>2.9347</td></tr><tr><td>eval/samples_per_second</td><td>32.712</td></tr><tr><td>eval/steps_per_second</td><td>2.045</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.6896</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.68958</td></tr><tr><td>train/train_runtime</td><td>25.7272</td></tr><tr><td>train/train_samples_per_second</td><td>33.35</td></tr><tr><td>train/train_steps_per_second</td><td>2.099</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">vague-sweep-6</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e43ltml7' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/e43ltml7</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123025-e43ltml7/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ouf1yfsg with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.4279669231306425\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.4721639721254076\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.585546848288992e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123112-ouf1yfsg</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ouf1yfsg' target=\"_blank\">generous-sweep-7</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ouf1yfsg' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ouf1yfsg</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:31, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.875100</td>\n","      <td>1.686484</td>\n","      <td>0.022900</td>\n","      <td>14.760400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0229</td></tr><tr><td>eval/gen_len</td><td>14.7604</td></tr><tr><td>eval/loss</td><td>1.68648</td></tr><tr><td>eval/runtime</td><td>2.2756</td></tr><tr><td>eval/samples_per_second</td><td>42.186</td></tr><tr><td>eval/steps_per_second</td><td>2.637</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>2.8751</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.87512</td></tr><tr><td>train/train_runtime</td><td>29.5802</td></tr><tr><td>train/train_samples_per_second</td><td>29.006</td></tr><tr><td>train/train_steps_per_second</td><td>0.913</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">generous-sweep-7</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ouf1yfsg' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ouf1yfsg</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123112-ouf1yfsg/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3xbhrwkw with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.4158215457591863\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.8450154877237073\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.173544889360225e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123220-3xbhrwkw</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3xbhrwkw' target=\"_blank\">vocal-sweep-8</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3xbhrwkw' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3xbhrwkw</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:32, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.545300</td>\n","      <td>2.572609</td>\n","      <td>0.034200</td>\n","      <td>17.302100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0342</td></tr><tr><td>eval/gen_len</td><td>17.3021</td></tr><tr><td>eval/loss</td><td>2.57261</td></tr><tr><td>eval/runtime</td><td>2.9689</td></tr><tr><td>eval/samples_per_second</td><td>32.336</td></tr><tr><td>eval/steps_per_second</td><td>2.021</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.5453</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.54533</td></tr><tr><td>train/train_runtime</td><td>30.3368</td></tr><tr><td>train/train_samples_per_second</td><td>28.282</td></tr><tr><td>train/train_steps_per_second</td><td>5.67</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">vocal-sweep-8</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3xbhrwkw' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3xbhrwkw</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123220-3xbhrwkw/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l9q9opu6 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.5301181688250258\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.3820331478361061\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00018447976921647297\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669155633333807, max=1.0…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bcc87ca7cab45e2b3ed5df6690a3bc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123311-l9q9opu6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/l9q9opu6' target=\"_blank\">magic-sweep-9</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/l9q9opu6' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/l9q9opu6</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.025800</td>\n","      <td>1.307575</td>\n","      <td>0.000200</td>\n","      <td>5.437500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0002</td></tr><tr><td>eval/gen_len</td><td>5.4375</td></tr><tr><td>eval/loss</td><td>1.30758</td></tr><tr><td>eval/runtime</td><td>2.9708</td></tr><tr><td>eval/samples_per_second</td><td>32.314</td></tr><tr><td>eval/steps_per_second</td><td>2.02</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>2.0258</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.02584</td></tr><tr><td>train/train_runtime</td><td>23.9591</td></tr><tr><td>train/train_samples_per_second</td><td>35.811</td></tr><tr><td>train/train_steps_per_second</td><td>1.127</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">magic-sweep-9</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/l9q9opu6' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/l9q9opu6</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123311-l9q9opu6/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yi4hag2r with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.4483870797238989\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.504264814626644\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007294170638522566\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123405-yi4hag2r</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/yi4hag2r' target=\"_blank\">lilac-sweep-10</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/yi4hag2r' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/yi4hag2r</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:33, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.873200</td>\n","      <td>0.769955</td>\n","      <td>0.041600</td>\n","      <td>18.437500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0416</td></tr><tr><td>eval/gen_len</td><td>18.4375</td></tr><tr><td>eval/loss</td><td>0.76995</td></tr><tr><td>eval/runtime</td><td>2.7853</td></tr><tr><td>eval/samples_per_second</td><td>34.467</td></tr><tr><td>eval/steps_per_second</td><td>2.154</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8732</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>0.87319</td></tr><tr><td>train/train_runtime</td><td>30.8051</td></tr><tr><td>train/train_samples_per_second</td><td>27.853</td></tr><tr><td>train/train_steps_per_second</td><td>5.583</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">lilac-sweep-10</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/yi4hag2r' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/yi4hag2r</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123405-yi4hag2r/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6208rltr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.3948613426128461\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.4976669424803505\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.0745304549698e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123456-6208rltr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/6208rltr' target=\"_blank\">glowing-sweep-11</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/6208rltr' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/6208rltr</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:33, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.184800</td>\n","      <td>1.438949</td>\n","      <td>0.000500</td>\n","      <td>5.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0005</td></tr><tr><td>eval/gen_len</td><td>5.5</td></tr><tr><td>eval/loss</td><td>1.43895</td></tr><tr><td>eval/runtime</td><td>2.5725</td></tr><tr><td>eval/samples_per_second</td><td>37.318</td></tr><tr><td>eval/steps_per_second</td><td>2.332</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1848</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.1848</td></tr><tr><td>train/train_runtime</td><td>30.3147</td></tr><tr><td>train/train_samples_per_second</td><td>28.303</td></tr><tr><td>train/train_steps_per_second</td><td>5.674</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">glowing-sweep-11</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/6208rltr' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/6208rltr</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123456-6208rltr/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u0tgmz1p with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.48997148073449787\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.26053974584137846\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00014084150706406842\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123549-u0tgmz1p</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/u0tgmz1p' target=\"_blank\">polar-sweep-12</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/u0tgmz1p' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/u0tgmz1p</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:25, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.394200</td>\n","      <td>1.489333</td>\n","      <td>0.007600</td>\n","      <td>9.572900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0076</td></tr><tr><td>eval/gen_len</td><td>9.5729</td></tr><tr><td>eval/loss</td><td>1.48933</td></tr><tr><td>eval/runtime</td><td>2.2947</td></tr><tr><td>eval/samples_per_second</td><td>41.835</td></tr><tr><td>eval/steps_per_second</td><td>2.615</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>2.3942</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.39417</td></tr><tr><td>train/train_runtime</td><td>23.4306</td></tr><tr><td>train/train_samples_per_second</td><td>36.619</td></tr><tr><td>train/train_steps_per_second</td><td>1.152</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">polar-sweep-12</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/u0tgmz1p' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/u0tgmz1p</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123549-u0tgmz1p/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oqm62nrl with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.5326296118112752\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.10392841182281104\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.974552739945833e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 100\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123635-oqm62nrl</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/oqm62nrl' target=\"_blank\">sage-sweep-13</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/oqm62nrl' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/oqm62nrl</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.507100</td>\n","      <td>2.772197</td>\n","      <td>0.033800</td>\n","      <td>18.072900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0338</td></tr><tr><td>eval/gen_len</td><td>18.0729</td></tr><tr><td>eval/loss</td><td>2.7722</td></tr><tr><td>eval/runtime</td><td>2.8263</td></tr><tr><td>eval/samples_per_second</td><td>33.966</td></tr><tr><td>eval/steps_per_second</td><td>2.123</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>3.5071</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>3.50715</td></tr><tr><td>train/train_runtime</td><td>24.5393</td></tr><tr><td>train/train_samples_per_second</td><td>34.964</td></tr><tr><td>train/train_steps_per_second</td><td>1.1</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">sage-sweep-13</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/oqm62nrl' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/oqm62nrl</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123635-oqm62nrl/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 56u4ajcg with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.3269481527825772\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.28669982187999987\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.6723740867752515e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123723-56u4ajcg</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/56u4ajcg' target=\"_blank\">young-sweep-14</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/56u4ajcg' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/56u4ajcg</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:25, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>4.829700</td>\n","      <td>4.064007</td>\n","      <td>0.230100</td>\n","      <td>17.677100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.2301</td></tr><tr><td>eval/gen_len</td><td>17.6771</td></tr><tr><td>eval/loss</td><td>4.06401</td></tr><tr><td>eval/runtime</td><td>2.3548</td></tr><tr><td>eval/samples_per_second</td><td>40.768</td></tr><tr><td>eval/steps_per_second</td><td>2.548</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>4.8297</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>4.82971</td></tr><tr><td>train/train_runtime</td><td>23.4356</td></tr><tr><td>train/train_samples_per_second</td><td>36.611</td></tr><tr><td>train/train_steps_per_second</td><td>1.152</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">young-sweep-14</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/56u4ajcg' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/56u4ajcg</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123723-56u4ajcg/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o0aog224 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.2129528577129459\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.09869105718650648\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.865327761476859e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123819-o0aog224</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/o0aog224' target=\"_blank\">likely-sweep-15</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/o0aog224' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/o0aog224</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:25, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.799000</td>\n","      <td>2.900218</td>\n","      <td>0.033500</td>\n","      <td>17.625000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0335</td></tr><tr><td>eval/gen_len</td><td>17.625</td></tr><tr><td>eval/loss</td><td>2.90022</td></tr><tr><td>eval/runtime</td><td>2.3587</td></tr><tr><td>eval/samples_per_second</td><td>40.7</td></tr><tr><td>eval/steps_per_second</td><td>2.544</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>3.799</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>3.79896</td></tr><tr><td>train/train_runtime</td><td>23.8381</td></tr><tr><td>train/train_samples_per_second</td><td>35.993</td></tr><tr><td>train/train_steps_per_second</td><td>1.133</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">likely-sweep-15</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/o0aog224' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/o0aog224</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123819-o0aog224/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hvaq5j35 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.6303432251767113\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6597579272621471\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.045367768675292e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_123905-hvaq5j35</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/hvaq5j35' target=\"_blank\">fresh-sweep-16</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/hvaq5j35' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/hvaq5j35</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:33, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.182400</td>\n","      <td>1.186207</td>\n","      <td>0.000000</td>\n","      <td>4.197900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0</td></tr><tr><td>eval/gen_len</td><td>4.1979</td></tr><tr><td>eval/loss</td><td>1.18621</td></tr><tr><td>eval/runtime</td><td>2.5177</td></tr><tr><td>eval/samples_per_second</td><td>38.131</td></tr><tr><td>eval/steps_per_second</td><td>2.383</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1824</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.1824</td></tr><tr><td>train/train_runtime</td><td>30.6657</td></tr><tr><td>train/train_samples_per_second</td><td>27.979</td></tr><tr><td>train/train_steps_per_second</td><td>5.609</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">fresh-sweep-16</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/hvaq5j35' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/hvaq5j35</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_123905-hvaq5j35/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7r4xzmjh with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.32218719047344535\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6517656923123819\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002159040840810998\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124007-7r4xzmjh</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/7r4xzmjh' target=\"_blank\">vocal-sweep-17</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/7r4xzmjh' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/7r4xzmjh</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:25, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.905700</td>\n","      <td>1.151660</td>\n","      <td>0.003200</td>\n","      <td>6.822900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0032</td></tr><tr><td>eval/gen_len</td><td>6.8229</td></tr><tr><td>eval/loss</td><td>1.15166</td></tr><tr><td>eval/runtime</td><td>2.3243</td></tr><tr><td>eval/samples_per_second</td><td>41.303</td></tr><tr><td>eval/steps_per_second</td><td>2.581</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.9057</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.90569</td></tr><tr><td>train/train_runtime</td><td>23.7702</td></tr><tr><td>train/train_samples_per_second</td><td>36.096</td></tr><tr><td>train/train_steps_per_second</td><td>1.136</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">vocal-sweep-17</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/7r4xzmjh' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/7r4xzmjh</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124007-7r4xzmjh/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: smdszw2j with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.47640241984882614\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.21132462882448333\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004446832087150979\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124053-smdszw2j</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/smdszw2j' target=\"_blank\">rich-sweep-18</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/smdszw2j' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/smdszw2j</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.856600</td>\n","      <td>1.020045</td>\n","      <td>0.000000</td>\n","      <td>2.260400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0</td></tr><tr><td>eval/gen_len</td><td>2.2604</td></tr><tr><td>eval/loss</td><td>1.02004</td></tr><tr><td>eval/runtime</td><td>2.4322</td></tr><tr><td>eval/samples_per_second</td><td>39.471</td></tr><tr><td>eval/steps_per_second</td><td>2.467</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>train/loss</td><td>1.8566</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.8566</td></tr><tr><td>train/train_runtime</td><td>24.3805</td></tr><tr><td>train/train_samples_per_second</td><td>35.192</td></tr><tr><td>train/train_steps_per_second</td><td>1.107</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">rich-sweep-18</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/smdszw2j' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/smdszw2j</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124053-smdszw2j/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9p8qbyt3 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.06505758614236899\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.28154550803853956\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.3343838200441186e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 100\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124149-9p8qbyt3</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9p8qbyt3' target=\"_blank\">deft-sweep-19</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9p8qbyt3' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9p8qbyt3</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.527400</td>\n","      <td>1.389754</td>\n","      <td>0.001100</td>\n","      <td>5.843800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0011</td></tr><tr><td>eval/gen_len</td><td>5.8438</td></tr><tr><td>eval/loss</td><td>1.38975</td></tr><tr><td>eval/runtime</td><td>3.0814</td></tr><tr><td>eval/samples_per_second</td><td>31.155</td></tr><tr><td>eval/steps_per_second</td><td>1.947</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5274</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.52744</td></tr><tr><td>train/train_runtime</td><td>31.5617</td></tr><tr><td>train/train_samples_per_second</td><td>27.185</td></tr><tr><td>train/train_steps_per_second</td><td>5.45</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">deft-sweep-19</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9p8qbyt3' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9p8qbyt3</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124149-9p8qbyt3/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q7bv54d2 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.291129663032987\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.17656891172624997\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.547429254371896e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124250-q7bv54d2</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7bv54d2' target=\"_blank\">swept-sweep-20</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7bv54d2' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7bv54d2</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.501200</td>\n","      <td>1.717234</td>\n","      <td>0.124300</td>\n","      <td>14.406200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.1243</td></tr><tr><td>eval/gen_len</td><td>14.4062</td></tr><tr><td>eval/loss</td><td>1.71723</td></tr><tr><td>eval/runtime</td><td>2.5686</td></tr><tr><td>eval/samples_per_second</td><td>37.374</td></tr><tr><td>eval/steps_per_second</td><td>2.336</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.5012</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.50119</td></tr><tr><td>train/train_runtime</td><td>25.4897</td></tr><tr><td>train/train_samples_per_second</td><td>33.661</td></tr><tr><td>train/train_steps_per_second</td><td>2.119</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">swept-sweep-20</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7bv54d2' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7bv54d2</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124250-q7bv54d2/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gddev7hl with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.2905138736360415\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.3826292800027291\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007676268591274725\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124341-gddev7hl</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gddev7hl' target=\"_blank\">treasured-sweep-21</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gddev7hl' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gddev7hl</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.166100</td>\n","      <td>0.830785</td>\n","      <td>0.000200</td>\n","      <td>4.958300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0002</td></tr><tr><td>eval/gen_len</td><td>4.9583</td></tr><tr><td>eval/loss</td><td>0.83079</td></tr><tr><td>eval/runtime</td><td>2.8134</td></tr><tr><td>eval/samples_per_second</td><td>34.122</td></tr><tr><td>eval/steps_per_second</td><td>2.133</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.1661</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.16613</td></tr><tr><td>train/train_runtime</td><td>26.0958</td></tr><tr><td>train/train_samples_per_second</td><td>32.879</td></tr><tr><td>train/train_steps_per_second</td><td>2.069</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">treasured-sweep-21</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gddev7hl' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gddev7hl</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124341-gddev7hl/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xsk92mbh with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.5144986395869243\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.5802526750170622\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.233584616725848e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124432-xsk92mbh</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/xsk92mbh' target=\"_blank\">glorious-sweep-22</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/xsk92mbh' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/xsk92mbh</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.395200</td>\n","      <td>2.470595</td>\n","      <td>0.175100</td>\n","      <td>16.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.1751</td></tr><tr><td>eval/gen_len</td><td>16.5</td></tr><tr><td>eval/loss</td><td>2.47059</td></tr><tr><td>eval/runtime</td><td>2.3528</td></tr><tr><td>eval/samples_per_second</td><td>40.803</td></tr><tr><td>eval/steps_per_second</td><td>2.55</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>3.3952</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>3.3952</td></tr><tr><td>train/train_runtime</td><td>23.87</td></tr><tr><td>train/train_samples_per_second</td><td>35.945</td></tr><tr><td>train/train_steps_per_second</td><td>1.131</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">glorious-sweep-22</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/xsk92mbh' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/xsk92mbh</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124432-xsk92mbh/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q7l41rqy with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.20564244803896173\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.4963901120562853\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005301414416182666\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124518-q7l41rqy</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7l41rqy' target=\"_blank\">fragrant-sweep-23</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7l41rqy' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7l41rqy</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.828900</td>\n","      <td>1.156023</td>\n","      <td>0.000000</td>\n","      <td>3.687500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0</td></tr><tr><td>eval/gen_len</td><td>3.6875</td></tr><tr><td>eval/loss</td><td>1.15602</td></tr><tr><td>eval/runtime</td><td>2.8014</td></tr><tr><td>eval/samples_per_second</td><td>34.268</td></tr><tr><td>eval/steps_per_second</td><td>2.142</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>6e-05</td></tr><tr><td>train/loss</td><td>1.8289</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.82892</td></tr><tr><td>train/train_runtime</td><td>24.7256</td></tr><tr><td>train/train_samples_per_second</td><td>34.701</td></tr><tr><td>train/train_steps_per_second</td><td>1.092</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">fragrant-sweep-23</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7l41rqy' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/q7l41rqy</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124518-q7l41rqy/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 43pzir5h with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.46149044413734097\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6424055199241102\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00029086872247771926\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124605-43pzir5h</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/43pzir5h' target=\"_blank\">playful-sweep-24</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/43pzir5h' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/43pzir5h</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.551800</td>\n","      <td>1.011343</td>\n","      <td>0.000000</td>\n","      <td>3.343800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0</td></tr><tr><td>eval/gen_len</td><td>3.3438</td></tr><tr><td>eval/loss</td><td>1.01134</td></tr><tr><td>eval/runtime</td><td>2.3881</td></tr><tr><td>eval/samples_per_second</td><td>40.2</td></tr><tr><td>eval/steps_per_second</td><td>2.512</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.5518</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.55183</td></tr><tr><td>train/train_runtime</td><td>25.225</td></tr><tr><td>train/train_samples_per_second</td><td>34.014</td></tr><tr><td>train/train_steps_per_second</td><td>2.141</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">playful-sweep-24</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/43pzir5h' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/43pzir5h</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124605-43pzir5h/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1krdpu44 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.6134605225455577\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.7998895939001074\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.590147172658666e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124655-1krdpu44</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/1krdpu44' target=\"_blank\">genial-sweep-25</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/1krdpu44' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/1krdpu44</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.285500</td>\n","      <td>1.941440</td>\n","      <td>0.045000</td>\n","      <td>15.541700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.045</td></tr><tr><td>eval/gen_len</td><td>15.5417</td></tr><tr><td>eval/loss</td><td>1.94144</td></tr><tr><td>eval/runtime</td><td>3.0573</td></tr><tr><td>eval/samples_per_second</td><td>31.4</td></tr><tr><td>eval/steps_per_second</td><td>1.963</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.2855</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.28552</td></tr><tr><td>train/train_runtime</td><td>26.1045</td></tr><tr><td>train/train_samples_per_second</td><td>32.868</td></tr><tr><td>train/train_steps_per_second</td><td>2.069</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">genial-sweep-25</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/1krdpu44' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/1krdpu44</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124655-1krdpu44/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 79og7n7j with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.6573931730727202\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.527697557518109\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.320774990813549e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 50\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124747-79og7n7j</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/79og7n7j' target=\"_blank\">amber-sweep-26</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/79og7n7j' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/79og7n7j</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.439700</td>\n","      <td>2.526425</td>\n","      <td>0.113900</td>\n","      <td>17.104200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.1139</td></tr><tr><td>eval/gen_len</td><td>17.1042</td></tr><tr><td>eval/loss</td><td>2.52643</td></tr><tr><td>eval/runtime</td><td>2.7266</td></tr><tr><td>eval/samples_per_second</td><td>35.209</td></tr><tr><td>eval/steps_per_second</td><td>2.201</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>3.4397</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>3.43971</td></tr><tr><td>train/train_runtime</td><td>25.0365</td></tr><tr><td>train/train_samples_per_second</td><td>34.27</td></tr><tr><td>train/train_steps_per_second</td><td>1.078</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">amber-sweep-26</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/79og7n7j' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/79og7n7j</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124747-79og7n7j/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3gwoqm2o with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.13391120466972786\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.0458305364440084\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005377241318871253\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124833-3gwoqm2o</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3gwoqm2o' target=\"_blank\">divine-sweep-27</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3gwoqm2o' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3gwoqm2o</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:37, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.941400</td>\n","      <td>0.830009</td>\n","      <td>0.000000</td>\n","      <td>3.979200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0</td></tr><tr><td>eval/gen_len</td><td>3.9792</td></tr><tr><td>eval/loss</td><td>0.83001</td></tr><tr><td>eval/runtime</td><td>2.4626</td></tr><tr><td>eval/samples_per_second</td><td>38.983</td></tr><tr><td>eval/steps_per_second</td><td>2.436</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.9414</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>0.94139</td></tr><tr><td>train/train_runtime</td><td>30.7093</td></tr><tr><td>train/train_samples_per_second</td><td>27.939</td></tr><tr><td>train/train_steps_per_second</td><td>5.601</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">divine-sweep-27</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3gwoqm2o' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/3gwoqm2o</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124833-3gwoqm2o/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ru3tn3az with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.6164205011394965\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6369304960537903\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.9626261599729228e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_124934-ru3tn3az</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ru3tn3az' target=\"_blank\">glowing-sweep-28</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ru3tn3az' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ru3tn3az</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.848800</td>\n","      <td>2.087959</td>\n","      <td>0.023600</td>\n","      <td>16.812500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0236</td></tr><tr><td>eval/gen_len</td><td>16.8125</td></tr><tr><td>eval/loss</td><td>2.08796</td></tr><tr><td>eval/runtime</td><td>2.4431</td></tr><tr><td>eval/samples_per_second</td><td>39.294</td></tr><tr><td>eval/steps_per_second</td><td>2.456</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.8488</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.84884</td></tr><tr><td>train/train_runtime</td><td>25.7817</td></tr><tr><td>train/train_samples_per_second</td><td>33.279</td></tr><tr><td>train/train_steps_per_second</td><td>2.095</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">glowing-sweep-28</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ru3tn3az' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/ru3tn3az</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_124934-ru3tn3az/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gpen0l78 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.372939956140982\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6960487840985721\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.9093667318336974e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 50\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_125030-gpen0l78</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gpen0l78' target=\"_blank\">solar-sweep-29</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gpen0l78' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gpen0l78</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.275800</td>\n","      <td>1.931993</td>\n","      <td>0.082000</td>\n","      <td>14.583300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.082</td></tr><tr><td>eval/gen_len</td><td>14.5833</td></tr><tr><td>eval/loss</td><td>1.93199</td></tr><tr><td>eval/runtime</td><td>2.4379</td></tr><tr><td>eval/samples_per_second</td><td>39.378</td></tr><tr><td>eval/steps_per_second</td><td>2.461</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.2758</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.27581</td></tr><tr><td>train/train_runtime</td><td>26.6682</td></tr><tr><td>train/train_samples_per_second</td><td>32.173</td></tr><tr><td>train/train_steps_per_second</td><td>2.025</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">solar-sweep-29</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gpen0l78' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/gpen0l78</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_125030-gpen0l78/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9sr5omon with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.04944991411414499\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.4678093229542011\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.109384939089684e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_125121-9sr5omon</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9sr5omon' target=\"_blank\">stoic-sweep-30</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9sr5omon' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9sr5omon</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/172 00:33, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.002100</td>\n","      <td>1.458804</td>\n","      <td>0.108500</td>\n","      <td>13.458300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.1085</td></tr><tr><td>eval/gen_len</td><td>13.4583</td></tr><tr><td>eval/loss</td><td>1.4588</td></tr><tr><td>eval/runtime</td><td>2.7757</td></tr><tr><td>eval/samples_per_second</td><td>34.586</td></tr><tr><td>eval/steps_per_second</td><td>2.162</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>172</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.0021</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.00206</td></tr><tr><td>train/train_runtime</td><td>31.769</td></tr><tr><td>train/train_samples_per_second</td><td>27.007</td></tr><tr><td>train/train_steps_per_second</td><td>5.414</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">stoic-sweep-30</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9sr5omon' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/9sr5omon</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_125121-9sr5omon/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: elvzqqz6 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.6918098321857\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.3227187899436356\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.666829121749361e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_125222-elvzqqz6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/elvzqqz6' target=\"_blank\">dainty-sweep-31</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/elvzqqz6' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/elvzqqz6</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.685900</td>\n","      <td>3.583575</td>\n","      <td>0.058700</td>\n","      <td>18.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0587</td></tr><tr><td>eval/gen_len</td><td>18.0</td></tr><tr><td>eval/loss</td><td>3.58358</td></tr><tr><td>eval/runtime</td><td>2.8676</td></tr><tr><td>eval/samples_per_second</td><td>33.478</td></tr><tr><td>eval/steps_per_second</td><td>2.092</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.6859</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>3.68588</td></tr><tr><td>train/train_runtime</td><td>26.4933</td></tr><tr><td>train/train_samples_per_second</td><td>32.386</td></tr><tr><td>train/train_steps_per_second</td><td>2.038</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">dainty-sweep-31</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/elvzqqz6' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/elvzqqz6</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_125222-elvzqqz6/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g44lzge4 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.060706599783709715\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.021074262487238416\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.2875944874111391e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_125315-g44lzge4</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/g44lzge4' target=\"_blank\">giddy-sweep-32</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/g44lzge4' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/g44lzge4</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>5.240900</td>\n","      <td>5.260365</td>\n","      <td>0.063100</td>\n","      <td>18.614600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0631</td></tr><tr><td>eval/gen_len</td><td>18.6146</td></tr><tr><td>eval/loss</td><td>5.26037</td></tr><tr><td>eval/runtime</td><td>2.8143</td></tr><tr><td>eval/samples_per_second</td><td>34.111</td></tr><tr><td>eval/steps_per_second</td><td>2.132</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>5.2409</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>5.24089</td></tr><tr><td>train/train_runtime</td><td>24.933</td></tr><tr><td>train/train_samples_per_second</td><td>34.412</td></tr><tr><td>train/train_steps_per_second</td><td>1.083</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">giddy-sweep-32</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/g44lzge4' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/g44lzge4</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_125315-g44lzge4/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f16mz1ny with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.11158189568283718\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.4773998330386453\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00018043561063886616\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_125407-f16mz1ny</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/f16mz1ny' target=\"_blank\">distinctive-sweep-33</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/f16mz1ny' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/f16mz1ny</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.109200</td>\n","      <td>1.221382</td>\n","      <td>0.000100</td>\n","      <td>5.750000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0001</td></tr><tr><td>eval/gen_len</td><td>5.75</td></tr><tr><td>eval/loss</td><td>1.22138</td></tr><tr><td>eval/runtime</td><td>2.4402</td></tr><tr><td>eval/samples_per_second</td><td>39.341</td></tr><tr><td>eval/steps_per_second</td><td>2.459</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>2.1092</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>2.10915</td></tr><tr><td>train/train_runtime</td><td>24.1756</td></tr><tr><td>train/train_samples_per_second</td><td>35.49</td></tr><tr><td>train/train_steps_per_second</td><td>1.117</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">distinctive-sweep-33</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/f16mz1ny' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/f16mz1ny</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_125407-f16mz1ny/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 90khoq08 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.30652115286328085\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.5318096437023665\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.960817752437873e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_125458-90khoq08</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/90khoq08' target=\"_blank\">divine-sweep-34</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/90khoq08' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/90khoq08</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.759600</td>\n","      <td>1.472680</td>\n","      <td>0.005100</td>\n","      <td>10.187500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0051</td></tr><tr><td>eval/gen_len</td><td>10.1875</td></tr><tr><td>eval/loss</td><td>1.47268</td></tr><tr><td>eval/runtime</td><td>2.9582</td></tr><tr><td>eval/samples_per_second</td><td>32.452</td></tr><tr><td>eval/steps_per_second</td><td>2.028</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7596</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.75955</td></tr><tr><td>train/train_runtime</td><td>25.8533</td></tr><tr><td>train/train_samples_per_second</td><td>33.187</td></tr><tr><td>train/train_steps_per_second</td><td>2.089</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">divine-sweep-34</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/90khoq08' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/90khoq08</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_125458-90khoq08/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d0h32xvr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.18542772028359752\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.5446007725215211\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00030916309332457256\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230503_125550-d0h32xvr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/d0h32xvr' target=\"_blank\">lively-sweep-35</a></strong> to <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/sweeps/6sh11rwz</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/d0h32xvr' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/d0h32xvr</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 00:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.301600</td>\n","      <td>1.240728</td>\n","      <td>0.000000</td>\n","      <td>4.333300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0</td></tr><tr><td>eval/gen_len</td><td>4.3333</td></tr><tr><td>eval/loss</td><td>1.24073</td></tr><tr><td>eval/runtime</td><td>2.8357</td></tr><tr><td>eval/samples_per_second</td><td>33.854</td></tr><tr><td>eval/steps_per_second</td><td>2.116</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.3016</td></tr><tr><td>train/total_flos</td><td>75752286584832.0</td></tr><tr><td>train/train_loss</td><td>1.30158</td></tr><tr><td>train/train_runtime</td><td>26.2867</td></tr><tr><td>train/train_samples_per_second</td><td>32.64</td></tr><tr><td>train/train_steps_per_second</td><td>2.054</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">lively-sweep-35</strong> at: <a href='https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/d0h32xvr' target=\"_blank\">https://wandb.ai/oumar-kane-team/small-t5-translation-bayes-hpsearch/runs/d0h32xvr</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230503_125550-d0h32xvr/logs</code>"]},"metadata":{}}],"source":["# %%wandb\n","\n","def train(config = None):\n","\n","  with wandb.init(config = config):\n","\n","    # seed\n","    set_seed(0)\n","\n","    # set sweep configuration\n","    config = wandb.config\n","\n","    # split the data\n","    split_data(config.random_state)\n","\n","    # let us recuperate the datasets\n","    train_dataset, valid_dataset = recuperate_datasets(config.fr_char_p, config.fr_word_p)\n","\n","    # set training arguments\n","    training_args = Seq2SeqTrainingArguments(f\"{path}/training//training/bayes_search_results_fw_v1\",\n","                                      report_to = f\"wandb\",\n","                                      num_train_epochs=config.epochs,\n","                                      load_best_model_at_end=True,\n","                                      save_strategy=\"epoch\",\n","                                      evaluation_strategy=\"epoch\",\n","                                      logging_strategy = 'epoch',\n","                                      per_device_train_batch_size=config.batch_size, \n","                                      per_device_eval_batch_size=16,\n","                                      learning_rate=config.learning_rate,\n","                                      weight_decay=config.weight_decay,\n","                                      predict_with_generate=True, # we will use predict with generate in order to obtain more valuable test results\n","                                      fp16 = True,\n","                                      )   \n","\n","    # define training loop\n","    trainer = Seq2SeqTrainer(model_init=partial(gpt2_model_init, tokenizer = train_dataset.tokenizer),\n","                      args=training_args,\n","                      train_dataset=train_dataset, \n","                      eval_dataset=valid_dataset,\n","                      data_collator=data_collator,\n","                      compute_metrics=evaluation.compute_metrics\n","                      )\n","\n","    # start training loop\n","    trainer.train()\n","\n","agent = wandb.agent(sweep_id, train, count = 45)\n"]},{"cell_type":"markdown","metadata":{"id":"u7NPlNlPgRz9"},"source":["------------------"]},{"cell_type":"markdown","metadata":{"id":"DO_49vgmTu8B"},"source":["## Wolof to french"]},{"cell_type":"markdown","metadata":{"id":"8BehHF09W3AK"},"source":["The only thing that we will change is the order of sentences. The wolof sentence is the first one to write."]},{"cell_type":"markdown","metadata":{"id":"nYjqfwjzW3AK"},"source":["### Configure dataset 🔠"]},{"cell_type":"markdown","source":["We can use the same custom dataset that we created in [text_augmentation](text_augmentation.ipynb). But we need to split the data between train and test sets and save them."],"metadata":{"id":"1Oul_eIAY2dz"}},{"cell_type":"code","source":["def split_data(random_state: int = 50):\n","\n","  # load the corpora and split into train and test sets\n","  corpora = pd.read_csv(f\"{path}new_data/sent_extraction.csv\")\n","\n","  train_set, test_set = train_test_split(corpora, test_size=0.1, random_state=random_state)\n","\n","  # let us save the sets\n","  train_set.to_csv(f\"{path}new_data/train_set.csv\", index=False)\n","\n","  test_set.to_csv(f\"{path}new_data/test_set.csv\", index=False)"],"metadata":{"id":"LPjxkXryY15-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hbNfFuKpW3AK"},"source":["Let us recuperate the datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nt7rn_dW3AK"},"outputs":[],"source":["def recuperate_datasets(wf_char_p: float, wf_word_p):\n","\n","  # with augmentation\n","  wf_augmentation = TransformerSequences(nac.KeyboardAug(aug_char_p=wf_char_p, aug_word_p=wf_word_p),\n","                                        remove_mark_space, delete_guillemet_space)\n","\n","  train_dataset_aug = SentenceDataset(f\"{path}new_data/train_set.csv\", \n","                                  tokenizer_path = f\"{path}wolof-translate/wolof_translate/tokenizers/tokenizer_v1.json\",\n","                                  corpus_1=\"wolof_corpus\",\n","                                  corpus_2=\"french_corpus\",\n","                                  cp1_transformer=wf_augmentation, truncation=True,\n","                                  max_len=579)\n","\n","  test_dataset = SentenceDataset(f\"{path}new_data/test_set.csv\",\n","                                tokenizer_path = f\"{path}wolof-translate/wolof_translate/tokenizers/tokenizer_v1.json\",\n","                                corpus_1=\"wolof_corpus\",\n","                                corpus_2=\"french_corpus\",\n","                                truncation=True, max_len=579)\n","  \n","  return train_dataset_aug, test_dataset"]},{"cell_type":"markdown","metadata":{"id":"sUt9UGWuW3AL"},"source":["### Configure hyperparameter search ⚙️"]},{"cell_type":"markdown","metadata":{"id":"L64gK2UgW3AL"},"source":["We have to configure the search space and the search method (\"random\" in our case). ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0UqeLmDW3AL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682856760036,"user_tz":0,"elapsed":2743,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"}},"outputId":"96d11bcf-37a7-49a6-9225-5c6db35911db"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moumar-kane\u001b[0m (\u001b[33moumar-kane-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["Create sweep with ID: alygo14y\n","Sweep URL: https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y\n"]}],"source":["import wandb\n","wandb.login(key=\"237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\")\n","\n","# hyperparameters\n","sweep_config = {\n","    'method': 'bayes',\n","    'metric':{\n","          'goal': 'minimize',\n","          'name': 'eval_loss'\n","      },\n","    'parameters':\n","    {\n","      'epochs': {\n","          'value': 1\n","      },\n","      'batch_size': {\n","          'values': [2, 3, 5]\n","      },\n","      'learning_rate': {\n","          'distribution': 'log_uniform_values',\n","          'min': 1e-5,\n","          'max': 1e-3\n","      },\n","      'weight_decay': {\n","          'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n","      },\n","     'wf_char_p': {\n","          'min': 0.0,\n","          'max': 0.7\n","     },\n","     'wf_word_p': {\n","          'min': 0.0,\n","          'max': 0.7\n","     },\n","     'random_state': {\n","         'values': [0, 10, 20, 30, 40, 50, 60, 70, 80, 100]\n","     }\n","    }\n","}\n","\n","# Initialize the hyperparameter search\n","sweep_id = wandb.sweep(sweep_config, project = \"gpt2-wolof-french-translation_bayes1_1\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JM7hEUdsW3AM"},"source":["### Configure the model and the evaluation function ⚙️"]},{"cell_type":"markdown","metadata":{"id":"h0-iQcATW3AM"},"source":["Let us recuperate the model and resize the token embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBaPD_qRW3AM"},"outputs":[],"source":["def gpt2_model_init(tokenizer):\n","  # set the mode name\n","  model_name = \"gpt2\"\n","\n","  # recuperate the tokenizer from the dataset\n","  tokenizer = tokenizer\n","\n","  # configure the model\n","  model = GPT2LMHeadModel.from_pretrained(model_name).cuda()\n","\n","  # resize the token embeddings\n","  model.resize_token_embeddings(len(tokenizer))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"U1xTTv_PW3AN"},"source":["Let us evaluate the predictions with the `bleu` metric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnPoI-vdW3AN","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["db7b4297d2f54e23b6c1a67cfc44411d","b4e89c244bf544d2b6c03c987aea33cf","4abd1a2e0e584a9f8b1d84f74a4f23bd","8ff179976b294d78a55c05512de3117f","c03b053582484d708d8150ca3d575244","be2c259b7fcd4e309c2e9bd63551e7c7","2b8b8c0820cf4f7fa226961d85129d6b","7952368ec6084469a27c61bfa43c5342","1dbcf8f3699a495bb0643eab17cea27b","ebd5507dbcb2490985432977aba34797","48a68082c7c144f38c143ab915169a7b"]},"executionInfo":{"status":"ok","timestamp":1682856761583,"user_tz":0,"elapsed":1550,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"}},"outputId":"8517895c-ecf5-4d6c-c5a2-29572fdcd47f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db7b4297d2f54e23b6c1a67cfc44411d"}},"metadata":{}}],"source":["# %%writefile wolof-translate/wolof_translate/utils/evaluation.py\n","from tokenizers import Tokenizer\n","from typing import *\n","import numpy as np\n","import evaluate\n","\n","class TranslationEvaluation:\n","    \n","    def __init__(self, \n","                 tokenizer: Tokenizer,\n","                 decoder: Union[Callable, None] = None,\n","                 metric = evaluate.load('sacrebleu'),\n","                 ):\n","        \n","        self.tokenizer = tokenizer\n","        \n","        self.decoder = decoder\n","        \n","        self.metric = metric\n","    \n","    def postprocess_text(self, preds, labels):\n","        \n","        preds = [pred.strip() for pred in preds]\n","        \n","        labels = [[label.strip()] for label in labels]\n","        \n","        return preds, labels\n","\n","    def compute_metrics(self, eval_preds):\n","        \n","        preds, labels = eval_preds.preds.detach().cpu(), labels.detach().cpu()\n","        \n","        if isinstance(preds, tuple):\n","            \n","            preds = preds[0]\n","        \n","        if self.decoder is None:\n","            \n","            decoded_preds = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n","            \n","            decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n","            \n","            decoded_preds, decoded_labels = self.postprocess_text(decoded_preds, decoded_labels)\n","            \n","            result = self.metric.compute(predictions=decoded_preds, references=decoded_labels)\n","            \n","            result = {\"bleu\": result[\"score\"]}\n","            \n","            prediction_lens = [np.count_nonzero(pred != self.tokenizer.pad_token_id) for pred in preds]\n","            \n","            result[\"gen_len\"] = np.mean(prediction_lens)\n","        \n","        else:\n","            \n","            predictions = list(self.decoder(preds))\n","            \n","            labels = list(self.decoder(labels))\n","      \n","            decoded_preds, decoded_labels = self.postprocess_text(predictions, labels)\n","            \n","            result = self.metric.compute(predictions=predictions, references=labels)\n","            \n","            result = {\"bleu\": result[\"score\"]}\n","        \n","        result = {k:round(v, 4) for k, v in result.items()}\n","\n","        wandb.log(\"bleu\", result[\"bleu\"])\n","            \n","        return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75UKFiPtW3AN"},"outputs":[],"source":["# %run wolof-translate/wolof_translate/utils/evaluation.py"]},{"cell_type":"markdown","metadata":{"id":"ovar55kYW3AO"},"source":["Let us initialize the evaluation object."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEjuC9_2W3AO"},"outputs":[],"source":["# translation_eval = TranslationEvaluation(test_dataset.tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"qwsA3gtGW3AO"},"source":["### Searching for the best parameters 🕖"]},{"cell_type":"markdown","metadata":{"id":"YAiR1MvmW3AO"},"source":["Let us define the data collator."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DR6XzHQW3AO"},"outputs":[],"source":["def data_collator(batch):\n","    \"\"\"Generate a batch of data to provide to trainer\n","\n","    Args:\n","        batch (_type_): The batch\n","\n","    Returns:\n","        dict: A dictionary containing the ids, the attention mask and the labels\n","    \"\"\"\n","    input_ids = torch.stack([b[0] for b in batch])\n","    \n","    attention_mask = torch.stack([b[1] for b in batch])\n","    \n","    labels = torch.stack([b[0] for b in batch])\n","    \n","    return {'input_ids': input_ids, 'attention_mask': attention_mask,\n","            'labels': labels}"]},{"cell_type":"markdown","metadata":{"id":"2P1qVBmlW3AP"},"source":["Let us initialize the training arguments and make random search."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8dXJjfhW3AP","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f73b2f84da9a4928ab0465094e5ec9cb","8b59e277cd98427fa5fc58808a2de6e3","ae1fc5bcdfa840efaf51bf505c6fa933","7880628963764d81b7f02350a1c2f04a","c7537d902cf343d5bed2616b021b88de","d2dc59c7fa5e44a6864591df27888586","0fd9d3313f6c43c9ba23e5ab70cd0213","727a7c008d89405d825bd24ad290b125","1d1088b3661e4ea397d7aa0bddd30649","e775795965144e938535b0a6fb54d880","db3eaa3328144b1fb2531df2864c7430","01613034172e4b00bee7c1dbc37404ed","27da5478ae3943a3877bd11559c5c82b","05bb4d42d5634732b02ecdad88eb6113","5a0a004f54454161bc0a72fc40bd5311","7eaf2ba083d84df8ac4ad32ce4ed10e7","ad927445b97942b7a3e6e2c26c607a94","3a02f284c2244d4aa8759d7c8caa7dd5","a0f3f82056bc4dbf9fc36aa07444704a","c8b8fdb2947c45edb6c11cf4f9115979","81a80a3ef5b74876bfe4d4342fb9a5b4","2fd1230d14fb48f1bfab3237610ff2d5","e341e084df494c2db150abf75a57894b","99d11e532b7c4bcda7e3d9c19c1b3bd7","8aa672fbbe6c40c697d9faa687ac2e20","d524cd529a654786a7659e5d6f10eb48","2b488c71e9ce434e9af5c2fc4b68355d","46a2d31366b546fbb7aef8e9dcdadb2c","a654ca3a23b243edb5b8e0a3e7a5c488","6eb5c08b7d594f36aa1900739151e663","3bed3e0675bf4961adbad59fe5559276","fd2377aeab634cbc83441e11e2c8a6c5","d0532ce3e6dd4409b8a1471ecb421e6b","440615e853584cf29c16e9393772b1e3","e51d668e16b14ee68792b76c651425b1","2672f8670b704e1584624c4c3307d651","410cfe6ea2494c149bcaa299547162e3","706408202679485481da12cc439c65a6","4308d419d5b4460eb6cbed09ad28f00d","efe22bb7e28c4c46af2a7f82dddf0bef","9d6c16f00283434db57d86feea4e2eb2"]},"executionInfo":{"status":"ok","timestamp":1682860429233,"user_tz":0,"elapsed":3667664,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"}},"outputId":"7173bdb4-63f5-44d2-a990-2f13ca3a418c"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0u0t6k2 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.702369179262155e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2819068695463206\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.3271474379445852\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121244-a0u0t6k2</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">usual-sweep-1</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f73b2f84da9a4928ab0465094e5ec9cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01613034172e4b00bee7c1dbc37404ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e341e084df494c2db150abf75a57894b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.331400</td>\n","      <td>0.972646</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.97265</td></tr><tr><td>eval/runtime</td><td>2.7358</td></tr><tr><td>eval/samples_per_second</td><td>29.973</td></tr><tr><td>eval/steps_per_second</td><td>6.214</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3314</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.33135</td></tr><tr><td>train/train_runtime</td><td>98.9652</td></tr><tr><td>train/train_samples_per_second</td><td>7.407</td></tr><tr><td>train/train_steps_per_second</td><td>3.708</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">usual-sweep-1</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_121244-a0u0t6k2/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8p97mqyj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000687378518112751\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.10242928904824668\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.3761238934195836\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121602-8p97mqyj</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">honest-sweep-2</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:40, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.211800</td>\n","      <td>0.902809</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.90281</td></tr><tr><td>eval/runtime</td><td>2.7187</td></tr><tr><td>eval/samples_per_second</td><td>30.162</td></tr><tr><td>eval/steps_per_second</td><td>6.253</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2118</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.21175</td></tr><tr><td>train/train_runtime</td><td>95.0089</td></tr><tr><td>train/train_samples_per_second</td><td>7.715</td></tr><tr><td>train/train_steps_per_second</td><td>3.863</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">honest-sweep-2</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_121602-8p97mqyj/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cufx9n8t with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.226951404890168e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.23759176734591644\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.13227163155096622\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121831-cufx9n8t</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">grateful-sweep-3</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.571300</td>\n","      <td>0.956762</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95676</td></tr><tr><td>eval/runtime</td><td>2.7129</td></tr><tr><td>eval/samples_per_second</td><td>30.226</td></tr><tr><td>eval/steps_per_second</td><td>6.266</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5713</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.57131</td></tr><tr><td>train/train_runtime</td><td>89.3504</td></tr><tr><td>train/train_samples_per_second</td><td>8.204</td></tr><tr><td>train/train_steps_per_second</td><td>2.742</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">grateful-sweep-3</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_121831-cufx9n8t/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y2zo0avu with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007890211017920526\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2153084724244564\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.03750263309251056\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122053-y2zo0avu</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">misty-sweep-4</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.394700</td>\n","      <td>0.852979</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85298</td></tr><tr><td>eval/runtime</td><td>2.7128</td></tr><tr><td>eval/samples_per_second</td><td>30.227</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>1.3947</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.39468</td></tr><tr><td>train/train_runtime</td><td>81.7228</td></tr><tr><td>train/train_samples_per_second</td><td>8.969</td></tr><tr><td>train/train_steps_per_second</td><td>1.799</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">misty-sweep-4</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_122053-y2zo0avu/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6zl4nshz with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00013060682353049685\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6581358201308465\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.010288732393246668\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122304-6zl4nshz</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">noble-sweep-5</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.125200</td>\n","      <td>0.843749</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.84375</td></tr><tr><td>eval/runtime</td><td>2.7146</td></tr><tr><td>eval/samples_per_second</td><td>30.207</td></tr><tr><td>eval/steps_per_second</td><td>6.262</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1252</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.12516</td></tr><tr><td>train/train_runtime</td><td>96.13</td></tr><tr><td>train/train_samples_per_second</td><td>7.625</td></tr><tr><td>train/train_steps_per_second</td><td>3.818</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">noble-sweep-5</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_122304-6zl4nshz/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lmlh43bi with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.6544061486102166e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.601761705072325\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5485382582443594\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122548-lmlh43bi</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">spring-sweep-6</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.511200</td>\n","      <td>0.959907</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95991</td></tr><tr><td>eval/runtime</td><td>2.7127</td></tr><tr><td>eval/samples_per_second</td><td>30.228</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5112</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5112</td></tr><tr><td>train/train_runtime</td><td>89.39</td></tr><tr><td>train/train_samples_per_second</td><td>8.2</td></tr><tr><td>train/train_steps_per_second</td><td>2.741</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">spring-sweep-6</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_122548-lmlh43bi/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b3709lrr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.01812368676995e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.3414514505517595\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.06590909422021479\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122808-b3709lrr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">worldly-sweep-7</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.298400</td>\n","      <td>0.943387</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.94339</td></tr><tr><td>eval/runtime</td><td>2.7141</td></tr><tr><td>eval/samples_per_second</td><td>30.212</td></tr><tr><td>eval/steps_per_second</td><td>6.264</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2984</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.2984</td></tr><tr><td>train/train_runtime</td><td>88.4049</td></tr><tr><td>train/train_samples_per_second</td><td>8.291</td></tr><tr><td>train/train_steps_per_second</td><td>2.771</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">worldly-sweep-7</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_122808-b3709lrr/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ixh1wkga with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.665404061522188e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2025899023149373\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.30403171896970477\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123025-ixh1wkga</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">giddy-sweep-8</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.600400</td>\n","      <td>0.898786</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89879</td></tr><tr><td>eval/runtime</td><td>2.7076</td></tr><tr><td>eval/samples_per_second</td><td>30.285</td></tr><tr><td>eval/steps_per_second</td><td>6.279</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6004</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.60037</td></tr><tr><td>train/train_runtime</td><td>83.0477</td></tr><tr><td>train/train_samples_per_second</td><td>8.826</td></tr><tr><td>train/train_steps_per_second</td><td>1.77</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">giddy-sweep-8</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_123025-ixh1wkga/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yqxwql6m with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009940796140095907\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.5740543904824967\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.2462419315938406\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123241-yqxwql6m</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">rosy-sweep-9</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.284500</td>\n","      <td>0.848199</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.8482</td></tr><tr><td>eval/runtime</td><td>2.7189</td></tr><tr><td>eval/samples_per_second</td><td>30.159</td></tr><tr><td>eval/steps_per_second</td><td>6.253</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.2845</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.28448</td></tr><tr><td>train/train_runtime</td><td>96.6069</td></tr><tr><td>train/train_samples_per_second</td><td>7.587</td></tr><tr><td>train/train_steps_per_second</td><td>3.799</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">rosy-sweep-9</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_123241-yqxwql6m/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6z8kvttx with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.136396657280805e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.496992386293468\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.09128048050662484\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668863250000263, max=1.0…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"440615e853584cf29c16e9393772b1e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123510-6z8kvttx</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">lemon-sweep-10</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.633700</td>\n","      <td>0.925104</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9251</td></tr><tr><td>eval/runtime</td><td>2.7135</td></tr><tr><td>eval/samples_per_second</td><td>30.22</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6337</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.63375</td></tr><tr><td>train/train_runtime</td><td>82.7991</td></tr><tr><td>train/train_samples_per_second</td><td>8.853</td></tr><tr><td>train/train_steps_per_second</td><td>1.775</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">lemon-sweep-10</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_123510-6z8kvttx/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m9sb4aqc with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.292925960874299e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.1392332134258406\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.33276367556881936\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123730-m9sb4aqc</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">resilient-sweep-11</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.377200</td>\n","      <td>0.921299</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9213</td></tr><tr><td>eval/runtime</td><td>2.7224</td></tr><tr><td>eval/samples_per_second</td><td>30.12</td></tr><tr><td>eval/steps_per_second</td><td>6.244</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3772</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.37722</td></tr><tr><td>train/train_runtime</td><td>97.2966</td></tr><tr><td>train/train_samples_per_second</td><td>7.534</td></tr><tr><td>train/train_steps_per_second</td><td>3.772</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">resilient-sweep-11</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_123730-m9sb4aqc/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jbput8ui with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.444484556126347e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.29893712569494857\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.26117783521919574\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123958-jbput8ui</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">snowy-sweep-12</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.432100</td>\n","      <td>0.896062</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89606</td></tr><tr><td>eval/runtime</td><td>2.708</td></tr><tr><td>eval/samples_per_second</td><td>30.281</td></tr><tr><td>eval/steps_per_second</td><td>6.278</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4321</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.43209</td></tr><tr><td>train/train_runtime</td><td>88.9488</td></tr><tr><td>train/train_samples_per_second</td><td>8.241</td></tr><tr><td>train/train_steps_per_second</td><td>2.754</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">snowy-sweep-12</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_123958-jbput8ui/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4fwhdrrr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.5593238990374552e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2943749543935819\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.12398175089457102\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124220-4fwhdrrr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">daily-sweep-13</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:30, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.699900</td>\n","      <td>0.852140</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85214</td></tr><tr><td>eval/runtime</td><td>2.7191</td></tr><tr><td>eval/samples_per_second</td><td>30.157</td></tr><tr><td>eval/steps_per_second</td><td>6.252</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6999</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.69991</td></tr><tr><td>train/train_runtime</td><td>85.2131</td></tr><tr><td>train/train_samples_per_second</td><td>8.602</td></tr><tr><td>train/train_steps_per_second</td><td>1.725</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">daily-sweep-13</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_124220-4fwhdrrr/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1bz3dbic with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.890480473611398e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2378445346533837\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.4209643755950993\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124438-1bz3dbic</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">eternal-sweep-14</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.483200</td>\n","      <td>0.875917</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.87592</td></tr><tr><td>eval/runtime</td><td>2.7525</td></tr><tr><td>eval/samples_per_second</td><td>29.792</td></tr><tr><td>eval/steps_per_second</td><td>6.176</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4832</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.48315</td></tr><tr><td>train/train_runtime</td><td>90.2171</td></tr><tr><td>train/train_samples_per_second</td><td>8.125</td></tr><tr><td>train/train_steps_per_second</td><td>2.716</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">eternal-sweep-14</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_124438-1bz3dbic/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ho6ta14m with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002774553527447285\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6714497099264989\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.03656663081592687\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124701-ho6ta14m</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">kind-sweep-15</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.124700</td>\n","      <td>0.822917</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.82292</td></tr><tr><td>eval/runtime</td><td>2.7172</td></tr><tr><td>eval/samples_per_second</td><td>30.178</td></tr><tr><td>eval/steps_per_second</td><td>6.256</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.1247</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.12474</td></tr><tr><td>train/train_runtime</td><td>96.7926</td></tr><tr><td>train/train_samples_per_second</td><td>7.573</td></tr><tr><td>train/train_steps_per_second</td><td>3.792</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">kind-sweep-15</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_124701-ho6ta14m/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wmlfiw0r with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003923791647223955\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.06807537344840917\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5604330614348828\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124934-wmlfiw0r</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">radiant-sweep-16</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.500600</td>\n","      <td>0.949637</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.94964</td></tr><tr><td>eval/runtime</td><td>2.7103</td></tr><tr><td>eval/samples_per_second</td><td>30.255</td></tr><tr><td>eval/steps_per_second</td><td>6.272</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.5006</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5006</td></tr><tr><td>train/train_runtime</td><td>83.6072</td></tr><tr><td>train/train_samples_per_second</td><td>8.767</td></tr><tr><td>train/train_steps_per_second</td><td>1.758</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">radiant-sweep-16</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_124934-wmlfiw0r/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r8gcrole with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.821341363881095e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 50\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.4377052667800509\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.28337028938356845\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125204-r8gcrole</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">dainty-sweep-17</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:31, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.846200</td>\n","      <td>0.981831</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.98183</td></tr><tr><td>eval/runtime</td><td>2.7136</td></tr><tr><td>eval/samples_per_second</td><td>30.218</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8462</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.8462</td></tr><tr><td>train/train_runtime</td><td>84.9129</td></tr><tr><td>train/train_samples_per_second</td><td>8.632</td></tr><tr><td>train/train_steps_per_second</td><td>1.731</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">dainty-sweep-17</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_125204-r8gcrole/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: phwfj18n with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.811279212646426e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2317434997460037\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.4361895012572056\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125428-phwfj18n</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">apricot-sweep-18</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.639600</td>\n","      <td>0.980084</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.98008</td></tr><tr><td>eval/runtime</td><td>2.767</td></tr><tr><td>eval/samples_per_second</td><td>29.635</td></tr><tr><td>eval/steps_per_second</td><td>6.144</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6396</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.63955</td></tr><tr><td>train/train_runtime</td><td>83.6783</td></tr><tr><td>train/train_samples_per_second</td><td>8.76</td></tr><tr><td>train/train_steps_per_second</td><td>1.757</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">apricot-sweep-18</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_125428-phwfj18n/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jlqkadbj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010056956001033137\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6390337876205812\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.23792329132405943\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125655-jlqkadbj</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">good-sweep-19</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.611900</td>\n","      <td>0.873367</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.87337</td></tr><tr><td>eval/runtime</td><td>2.7126</td></tr><tr><td>eval/samples_per_second</td><td>30.23</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.6119</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.61191</td></tr><tr><td>train/train_runtime</td><td>83.1352</td></tr><tr><td>train/train_samples_per_second</td><td>8.817</td></tr><tr><td>train/train_steps_per_second</td><td>1.768</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">good-sweep-19</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_125655-jlqkadbj/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6p270685 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.129742665577746e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.39725467091195105\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5004309074101329\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125915-6p270685</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">pious-sweep-20</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.459300</td>\n","      <td>0.955068</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95507</td></tr><tr><td>eval/runtime</td><td>2.7243</td></tr><tr><td>eval/samples_per_second</td><td>30.099</td></tr><tr><td>eval/steps_per_second</td><td>6.24</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4593</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.45931</td></tr><tr><td>train/train_runtime</td><td>89.8845</td></tr><tr><td>train/train_samples_per_second</td><td>8.155</td></tr><tr><td>train/train_steps_per_second</td><td>2.726</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">pious-sweep-20</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_125915-6p270685/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gcv6axp9 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.252438217932992e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.29046645972247725\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.2600785813543463\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130144-gcv6axp9</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">dutiful-sweep-21</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.316900</td>\n","      <td>0.971379</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.97138</td></tr><tr><td>eval/runtime</td><td>2.7496</td></tr><tr><td>eval/samples_per_second</td><td>29.823</td></tr><tr><td>eval/steps_per_second</td><td>6.183</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3169</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.31693</td></tr><tr><td>train/train_runtime</td><td>97.0731</td></tr><tr><td>train/train_samples_per_second</td><td>7.551</td></tr><tr><td>train/train_steps_per_second</td><td>3.781</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">dutiful-sweep-21</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_130144-gcv6axp9/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yhyy9e23 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.647196100197014e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.1717366963251063\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.1316624948710261\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130418-yhyy9e23</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">glowing-sweep-22</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:38, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.396900</td>\n","      <td>0.856822</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85682</td></tr><tr><td>eval/runtime</td><td>2.7137</td></tr><tr><td>eval/samples_per_second</td><td>30.217</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3969</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.3969</td></tr><tr><td>train/train_runtime</td><td>91.6977</td></tr><tr><td>train/train_samples_per_second</td><td>7.994</td></tr><tr><td>train/train_steps_per_second</td><td>2.672</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">glowing-sweep-22</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_130418-yhyy9e23/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xup68ew4 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.637652455538814e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.677355252029728\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.16163588455481578\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130645-xup68ew4</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">devoted-sweep-23</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.687100</td>\n","      <td>0.952795</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9528</td></tr><tr><td>eval/runtime</td><td>2.7376</td></tr><tr><td>eval/samples_per_second</td><td>29.953</td></tr><tr><td>eval/steps_per_second</td><td>6.21</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6871</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.68711</td></tr><tr><td>train/train_runtime</td><td>83.5213</td></tr><tr><td>train/train_samples_per_second</td><td>8.776</td></tr><tr><td>train/train_steps_per_second</td><td>1.76</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">devoted-sweep-23</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_130645-xup68ew4/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wa2re6yd with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00015372099844614283\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.4593404124892092\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5384324544438147\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130904-wa2re6yd</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">deft-sweep-24</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.402800</td>\n","      <td>0.823874</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.82387</td></tr><tr><td>eval/runtime</td><td>2.7275</td></tr><tr><td>eval/samples_per_second</td><td>30.064</td></tr><tr><td>eval/steps_per_second</td><td>6.233</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4028</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.40277</td></tr><tr><td>train/train_runtime</td><td>89.583</td></tr><tr><td>train/train_samples_per_second</td><td>8.182</td></tr><tr><td>train/train_steps_per_second</td><td>2.735</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">deft-sweep-24</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_130904-wa2re6yd/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i305ffth with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.284698923411304e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6295786463189464\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.6968639258681786\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_131131-i305ffth</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">sunny-sweep-25</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:36, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.509300</td>\n","      <td>0.986804</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9868</td></tr><tr><td>eval/runtime</td><td>2.7162</td></tr><tr><td>eval/samples_per_second</td><td>30.189</td></tr><tr><td>eval/steps_per_second</td><td>6.259</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5093</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5093</td></tr><tr><td>train/train_runtime</td><td>90.604</td></tr><tr><td>train/train_samples_per_second</td><td>8.09</td></tr><tr><td>train/train_steps_per_second</td><td>2.704</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">sunny-sweep-25</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230430_131131-i305ffth/logs</code>"]},"metadata":{}}],"source":["# %%wandb\n","\n","def train(config = None):\n","\n","  with wandb.init(config = config):\n","\n","    # seed\n","    torch.manual_seed(50)\n","\n","    # set sweep configuration\n","    config = wandb.config\n","\n","    # split the data\n","    split_data(config.random_state)\n","\n","    # let us recuperate the datasets\n","    train_dataset, test_dataset = recuperate_datasets(config.wf_char_p, config.wf_word_p)\n","\n","    # get train and test datasets according to the config\n","\n","    # train_dataset = datasets[config.dataset_aug]['train_dataset']\n","\n","    # test_dataset = datasets[config.dataset_aug]['test_dataset']\n","\n","    # set training arguments\n","    training_args = TrainingArguments(f\"{path}training2/Results1\",\n","                                      report_to = f\"wandb\",\n","                                      num_train_epochs=config.epochs,\n","                                      # logging_steps=100,\n","                                      load_best_model_at_end=True,\n","                                      save_strategy=\"epoch\",\n","                                      evaluation_strategy=\"epoch\",\n","                                      logging_strategy = 'epoch',\n","                                      per_device_train_batch_size=config.batch_size, \n","                                      per_device_eval_batch_size=5,\n","                                      learning_rate=config.learning_rate,\n","                                      weight_decay=config.weight_decay,\n","                                      remove_unused_columns = False,\n","                                      fp16 = True,\n","                                      )   \n","\n","    # define training loop\n","    trainer = Trainer(model_init=partial(gpt2_model_init, tokenizer = train_dataset.tokenizer),\n","                      args=training_args,\n","                      train_dataset=train_dataset, \n","                      eval_dataset=test_dataset,\n","                      data_collator=data_collator,\n","                      # compute_metrics=translation_eval.compute_metrics\n","                      )\n","\n","    # start training loop\n","    trainer.train()\n","\n","agent = wandb.agent(sweep_id, train, count = 25)\n"]},{"cell_type":"markdown","metadata":{"id":"3DIrLmGrW3AP"},"source":["-----------"]},{"cell_type":"markdown","metadata":{"id":"WLu_sR9yW3AQ"},"source":["## Colab download and remove step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvqj0ijnW3AQ"},"outputs":[],"source":["import shutil\n","\n","# shutil.rmtree('/content/drive/MyDrive/Memoire/subject2/T5/training/bayes_search_results')\n","shutil.rmtree('wandb')\n","# shutil.make_archive('wandb', 'zip', 'wanbd')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"pytorch1-HleOW5am-py3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"db7b4297d2f54e23b6c1a67cfc44411d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4e89c244bf544d2b6c03c987aea33cf","IPY_MODEL_4abd1a2e0e584a9f8b1d84f74a4f23bd","IPY_MODEL_8ff179976b294d78a55c05512de3117f"],"layout":"IPY_MODEL_c03b053582484d708d8150ca3d575244"}},"b4e89c244bf544d2b6c03c987aea33cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be2c259b7fcd4e309c2e9bd63551e7c7","placeholder":"​","style":"IPY_MODEL_2b8b8c0820cf4f7fa226961d85129d6b","value":"Downloading builder script: 100%"}},"4abd1a2e0e584a9f8b1d84f74a4f23bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7952368ec6084469a27c61bfa43c5342","max":8146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dbcf8f3699a495bb0643eab17cea27b","value":8146}},"8ff179976b294d78a55c05512de3117f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebd5507dbcb2490985432977aba34797","placeholder":"​","style":"IPY_MODEL_48a68082c7c144f38c143ab915169a7b","value":" 8.15k/8.15k [00:00&lt;00:00, 330kB/s]"}},"c03b053582484d708d8150ca3d575244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be2c259b7fcd4e309c2e9bd63551e7c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b8b8c0820cf4f7fa226961d85129d6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7952368ec6084469a27c61bfa43c5342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dbcf8f3699a495bb0643eab17cea27b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebd5507dbcb2490985432977aba34797":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48a68082c7c144f38c143ab915169a7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f73b2f84da9a4928ab0465094e5ec9cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b59e277cd98427fa5fc58808a2de6e3","IPY_MODEL_ae1fc5bcdfa840efaf51bf505c6fa933","IPY_MODEL_7880628963764d81b7f02350a1c2f04a"],"layout":"IPY_MODEL_c7537d902cf343d5bed2616b021b88de"}},"8b59e277cd98427fa5fc58808a2de6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2dc59c7fa5e44a6864591df27888586","placeholder":"​","style":"IPY_MODEL_0fd9d3313f6c43c9ba23e5ab70cd0213","value":"Downloading (…)lve/main/config.json: 100%"}},"ae1fc5bcdfa840efaf51bf505c6fa933":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_727a7c008d89405d825bd24ad290b125","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d1088b3661e4ea397d7aa0bddd30649","value":665}},"7880628963764d81b7f02350a1c2f04a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e775795965144e938535b0a6fb54d880","placeholder":"​","style":"IPY_MODEL_db3eaa3328144b1fb2531df2864c7430","value":" 665/665 [00:00&lt;00:00, 15.7kB/s]"}},"c7537d902cf343d5bed2616b021b88de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2dc59c7fa5e44a6864591df27888586":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fd9d3313f6c43c9ba23e5ab70cd0213":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"727a7c008d89405d825bd24ad290b125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d1088b3661e4ea397d7aa0bddd30649":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e775795965144e938535b0a6fb54d880":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db3eaa3328144b1fb2531df2864c7430":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01613034172e4b00bee7c1dbc37404ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27da5478ae3943a3877bd11559c5c82b","IPY_MODEL_05bb4d42d5634732b02ecdad88eb6113","IPY_MODEL_5a0a004f54454161bc0a72fc40bd5311"],"layout":"IPY_MODEL_7eaf2ba083d84df8ac4ad32ce4ed10e7"}},"27da5478ae3943a3877bd11559c5c82b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad927445b97942b7a3e6e2c26c607a94","placeholder":"​","style":"IPY_MODEL_3a02f284c2244d4aa8759d7c8caa7dd5","value":"Downloading pytorch_model.bin: 100%"}},"05bb4d42d5634732b02ecdad88eb6113":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0f3f82056bc4dbf9fc36aa07444704a","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8b8fdb2947c45edb6c11cf4f9115979","value":548118077}},"5a0a004f54454161bc0a72fc40bd5311":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81a80a3ef5b74876bfe4d4342fb9a5b4","placeholder":"​","style":"IPY_MODEL_2fd1230d14fb48f1bfab3237610ff2d5","value":" 548M/548M [00:26&lt;00:00, 23.8MB/s]"}},"7eaf2ba083d84df8ac4ad32ce4ed10e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad927445b97942b7a3e6e2c26c607a94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a02f284c2244d4aa8759d7c8caa7dd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0f3f82056bc4dbf9fc36aa07444704a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8b8fdb2947c45edb6c11cf4f9115979":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81a80a3ef5b74876bfe4d4342fb9a5b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fd1230d14fb48f1bfab3237610ff2d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e341e084df494c2db150abf75a57894b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99d11e532b7c4bcda7e3d9c19c1b3bd7","IPY_MODEL_8aa672fbbe6c40c697d9faa687ac2e20","IPY_MODEL_d524cd529a654786a7659e5d6f10eb48"],"layout":"IPY_MODEL_2b488c71e9ce434e9af5c2fc4b68355d"}},"99d11e532b7c4bcda7e3d9c19c1b3bd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46a2d31366b546fbb7aef8e9dcdadb2c","placeholder":"​","style":"IPY_MODEL_a654ca3a23b243edb5b8e0a3e7a5c488","value":"Downloading (…)neration_config.json: 100%"}},"8aa672fbbe6c40c697d9faa687ac2e20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eb5c08b7d594f36aa1900739151e663","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bed3e0675bf4961adbad59fe5559276","value":124}},"d524cd529a654786a7659e5d6f10eb48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd2377aeab634cbc83441e11e2c8a6c5","placeholder":"​","style":"IPY_MODEL_d0532ce3e6dd4409b8a1471ecb421e6b","value":" 124/124 [00:00&lt;00:00, 6.71kB/s]"}},"2b488c71e9ce434e9af5c2fc4b68355d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a2d31366b546fbb7aef8e9dcdadb2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a654ca3a23b243edb5b8e0a3e7a5c488":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6eb5c08b7d594f36aa1900739151e663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bed3e0675bf4961adbad59fe5559276":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd2377aeab634cbc83441e11e2c8a6c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0532ce3e6dd4409b8a1471ecb421e6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"440615e853584cf29c16e9393772b1e3":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e51d668e16b14ee68792b76c651425b1","IPY_MODEL_2672f8670b704e1584624c4c3307d651"],"layout":"IPY_MODEL_410cfe6ea2494c149bcaa299547162e3"}},"e51d668e16b14ee68792b76c651425b1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_706408202679485481da12cc439c65a6","placeholder":"​","style":"IPY_MODEL_4308d419d5b4460eb6cbed09ad28f00d","value":"Waiting for wandb.init()...\r"}},"2672f8670b704e1584624c4c3307d651":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_efe22bb7e28c4c46af2a7f82dddf0bef","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d6c16f00283434db57d86feea4e2eb2","value":1}},"410cfe6ea2494c149bcaa299547162e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706408202679485481da12cc439c65a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4308d419d5b4460eb6cbed09ad28f00d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efe22bb7e28c4c46af2a7f82dddf0bef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d6c16f00283434db57d86feea4e2eb2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25ba4187ab414a32bc8cc7e6b3bcec36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7703984450514848962f292a2f98175d","IPY_MODEL_3838dfe4ca5c4a039a988f4a51a0a649","IPY_MODEL_b336daea2494491d8f67d665a9f33feb"],"layout":"IPY_MODEL_7cbcf9b2af694cda8439268d0de5830d"}},"7703984450514848962f292a2f98175d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3046341e9b544dfa0fa991f848e0653","placeholder":"​","style":"IPY_MODEL_7bb70d123d114a8999298a4fa7e026ed","value":"Downloading (…)lve/main/config.json: 100%"}},"3838dfe4ca5c4a039a988f4a51a0a649":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65bcbecabe6d4b1f89687f98434844a4","max":1206,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f32c78f1a67e4713aef1bc310984548b","value":1206}},"b336daea2494491d8f67d665a9f33feb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b02b552a40934f9ebf80311493578a9a","placeholder":"​","style":"IPY_MODEL_7903729d3cb44d0ab3e487e3b7e86641","value":" 1.21k/1.21k [00:00&lt;00:00, 66.7kB/s]"}},"7cbcf9b2af694cda8439268d0de5830d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3046341e9b544dfa0fa991f848e0653":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bb70d123d114a8999298a4fa7e026ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65bcbecabe6d4b1f89687f98434844a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32c78f1a67e4713aef1bc310984548b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b02b552a40934f9ebf80311493578a9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7903729d3cb44d0ab3e487e3b7e86641":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f47d648c89b8440da88cb4706bb8cb0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d75baac7f5e426c91c245c9b120e073","IPY_MODEL_b30d3a9bcf044b858bb7c1a2e37bf2ab","IPY_MODEL_5c5e44fd528f4c4599da35e93fcdfa41"],"layout":"IPY_MODEL_1cd4fca6977143de9dabb02ae1d84aee"}},"4d75baac7f5e426c91c245c9b120e073":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b48bc669b3d14854a1dbc542c78278b6","placeholder":"​","style":"IPY_MODEL_a6da1c422b7142a885dc25b85ce9b2e4","value":"Downloading pytorch_model.bin: 100%"}},"b30d3a9bcf044b858bb7c1a2e37bf2ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f71cdb4b40846f5a6945cb20ac305d3","max":242065649,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f9b88804a3e49dea9cfb828c79e7471","value":242065649}},"5c5e44fd528f4c4599da35e93fcdfa41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6d30d7c28a24fbf8a386fd89219a066","placeholder":"​","style":"IPY_MODEL_d50a068f5fad4a1fb3b31e4d902af7fc","value":" 242M/242M [00:00&lt;00:00, 326MB/s]"}},"1cd4fca6977143de9dabb02ae1d84aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b48bc669b3d14854a1dbc542c78278b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6da1c422b7142a885dc25b85ce9b2e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f71cdb4b40846f5a6945cb20ac305d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f9b88804a3e49dea9cfb828c79e7471":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6d30d7c28a24fbf8a386fd89219a066":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d50a068f5fad4a1fb3b31e4d902af7fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e551484691146a1a4ffc691b3e31b3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cac472aa50f743fd807746f52d8297be","IPY_MODEL_d8fa36133073423ca21b85fcc4bbc73a","IPY_MODEL_690489ab48064ecc9928725f0fc757b0"],"layout":"IPY_MODEL_443ee13f9e74424385dba88872acccc7"}},"cac472aa50f743fd807746f52d8297be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_709bf3e0057348f999728b7f2ae7a24d","placeholder":"​","style":"IPY_MODEL_55246c37fa6f4d9b9e9b5bfecff7b524","value":"Downloading (…)neration_config.json: 100%"}},"d8fa36133073423ca21b85fcc4bbc73a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88105371ff6d4ce6ba31a8f1f93c9a9f","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_122cc67ba2154264aef5a1064415a8a4","value":147}},"690489ab48064ecc9928725f0fc757b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5055dbbaa5b4baa8e26f4acb9154509","placeholder":"​","style":"IPY_MODEL_90f89f13e03e443c9f5d2c94d847e1cb","value":" 147/147 [00:00&lt;00:00, 10.3kB/s]"}},"443ee13f9e74424385dba88872acccc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"709bf3e0057348f999728b7f2ae7a24d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55246c37fa6f4d9b9e9b5bfecff7b524":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88105371ff6d4ce6ba31a8f1f93c9a9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"122cc67ba2154264aef5a1064415a8a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5055dbbaa5b4baa8e26f4acb9154509":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90f89f13e03e443c9f5d2c94d847e1cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7409ed29b654d7a867512710207c1f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38f3257e9c724169bbaa66841ac5e156","IPY_MODEL_1598deaf97204dbead6563c70a1d6ed3","IPY_MODEL_145e9f9ef1b44794825596e82f752a24"],"layout":"IPY_MODEL_9b846fbb443b429e8f6234f49e67802c"}},"38f3257e9c724169bbaa66841ac5e156":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32cb2b67a1384512b073aafab1ab75ed","placeholder":"​","style":"IPY_MODEL_2fe7f282361c421a97fdb024cd37acef","value":"Downloading (…)lve/main/config.json: 100%"}},"1598deaf97204dbead6563c70a1d6ed3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8266651e18e54bc2ae0925c41064597f","max":1208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2310bae595941e8b84efba8f7160654","value":1208}},"145e9f9ef1b44794825596e82f752a24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b59555a6d9cb4ba2bdca1a2510ae8c39","placeholder":"​","style":"IPY_MODEL_0ca000477e874feaa155af878e55d16e","value":" 1.21k/1.21k [00:00&lt;00:00, 52.1kB/s]"}},"9b846fbb443b429e8f6234f49e67802c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32cb2b67a1384512b073aafab1ab75ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fe7f282361c421a97fdb024cd37acef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8266651e18e54bc2ae0925c41064597f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2310bae595941e8b84efba8f7160654":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b59555a6d9cb4ba2bdca1a2510ae8c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ca000477e874feaa155af878e55d16e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f53a0c11c36481e9762de60cdb35658":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_540fed32ad2048ae9c5b0a165a882175","IPY_MODEL_48b418359cb940bb8766003e944aa666","IPY_MODEL_8c3415dc54c249beb2649c0b327db858"],"layout":"IPY_MODEL_c6aaeb90053d48cb8d024ae2ac3ea0b4"}},"540fed32ad2048ae9c5b0a165a882175":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ae8c304dc9a4567a3d44662a2292edf","placeholder":"​","style":"IPY_MODEL_609c88cee4d64dd89045b2cd9d6b49cd","value":"Downloading pytorch_model.bin: 100%"}},"48b418359cb940bb8766003e944aa666":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f533177f7e9f453495e50e88692f2fe5","max":891691430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8f2ad480b384fa5aef0d87a0369d7ae","value":891691430}},"8c3415dc54c249beb2649c0b327db858":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b10c0a7129914a9fbcc192b864b3e52a","placeholder":"​","style":"IPY_MODEL_b441fdcf927246ceba830abd8458dd5c","value":" 892M/892M [00:24&lt;00:00, 16.8MB/s]"}},"c6aaeb90053d48cb8d024ae2ac3ea0b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ae8c304dc9a4567a3d44662a2292edf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"609c88cee4d64dd89045b2cd9d6b49cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f533177f7e9f453495e50e88692f2fe5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8f2ad480b384fa5aef0d87a0369d7ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b10c0a7129914a9fbcc192b864b3e52a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b441fdcf927246ceba830abd8458dd5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35269e3136ac4235b9db25b994e46462":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_957a89c5d0fc414fa0c5e13e8c9bcdc1","IPY_MODEL_a7e436b7d338419196ee7fe3b3bca2a7","IPY_MODEL_fb9363a0864947e483b48f7ec94439c4"],"layout":"IPY_MODEL_a68753999b2448998a87442528432944"}},"957a89c5d0fc414fa0c5e13e8c9bcdc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20910b55c2d14131804e1f74794f26e4","placeholder":"​","style":"IPY_MODEL_3fe317d2e0c54629a6c31800f32e90e4","value":"Downloading (…)neration_config.json: 100%"}},"a7e436b7d338419196ee7fe3b3bca2a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bd161d8995240adb21babbef3723450","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16084242755e4663b3688ce4fd41c98d","value":147}},"fb9363a0864947e483b48f7ec94439c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88f17b318c604bb1bc660deb24a77055","placeholder":"​","style":"IPY_MODEL_01b746ac6dad49d1b30af3f086b0e4a4","value":" 147/147 [00:00&lt;00:00, 10.5kB/s]"}},"a68753999b2448998a87442528432944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20910b55c2d14131804e1f74794f26e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fe317d2e0c54629a6c31800f32e90e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bd161d8995240adb21babbef3723450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16084242755e4663b3688ce4fd41c98d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88f17b318c604bb1bc660deb24a77055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01b746ac6dad49d1b30af3f086b0e4a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"608ebf4a67ac45e0bfd3cab84d3de321":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c26590307574cb99d48756fd2bfb069","IPY_MODEL_09002a94f7424804a3126729c84370b1","IPY_MODEL_753b741a9d71465bb2d7d0e97c205ede"],"layout":"IPY_MODEL_2c7681a6529141a686665edcc5631e3b"}},"6c26590307574cb99d48756fd2bfb069":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2316d73857ed4c9abb97bef21ef03af6","placeholder":"​","style":"IPY_MODEL_47cd33eeb5e742788f827ec77e3184b5","value":"Downloading builder script: 100%"}},"09002a94f7424804a3126729c84370b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_012cc5119cc74c7c9aaa75eefddabe88","max":8146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef27cbed736045cca5b84abfd0f34bed","value":8146}},"753b741a9d71465bb2d7d0e97c205ede":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcf11d04edc24770a51379b334c6b304","placeholder":"​","style":"IPY_MODEL_1ba0d9c454e243568248c904b769ae17","value":" 8.15k/8.15k [00:00&lt;00:00, 498kB/s]"}},"2c7681a6529141a686665edcc5631e3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2316d73857ed4c9abb97bef21ef03af6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47cd33eeb5e742788f827ec77e3184b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"012cc5119cc74c7c9aaa75eefddabe88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef27cbed736045cca5b84abfd0f34bed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcf11d04edc24770a51379b334c6b304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ba0d9c454e243568248c904b769ae17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bcc87ca7cab45e2b3ed5df6690a3bc6":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_6c065ae652364dc7b3ce274aa03879dd","IPY_MODEL_f2e1f38455f7429fb94d8f882ab0dd91"],"layout":"IPY_MODEL_b7acb877f8d140e4afdb9280c679f715"}},"6c065ae652364dc7b3ce274aa03879dd":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8497dc2a290e4ccb9953e0c62417077d","placeholder":"​","style":"IPY_MODEL_02b214a69b314a049af7efc732bac64d","value":"Waiting for wandb.init()...\r"}},"f2e1f38455f7429fb94d8f882ab0dd91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_72cbe39203594c9c8da77cc0f1f2ca6e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86fa209c456a4b0b99e40d523cbb1acf","value":1}},"b7acb877f8d140e4afdb9280c679f715":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8497dc2a290e4ccb9953e0c62417077d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02b214a69b314a049af7efc732bac64d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72cbe39203594c9c8da77cc0f1f2ca6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86fa209c456a4b0b99e40d523cbb1acf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}