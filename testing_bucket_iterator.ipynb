{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch create buckets with same lengths\n",
    "---------------------------------------\n",
    "Let us use a class create by chat gpt to generate batches of sequences of same lengths."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data with a custom dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following custom dataset is very similar to that we created in [tokenizing_sentences](creating_tokenizer_for_all_sentences_3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wolof-translate/wolof_translate/utils/bucket_iterator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile wolof-translate/wolof_translate/utils/bucket_iterator.py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Sampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class SequenceLengthBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, boundaries, batch_sizes):\n",
    "        self.dataset = dataset\n",
    "        self.boundaries = boundaries\n",
    "        self.batch_sizes = batch_sizes\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = list(range(len(self.dataset)))  # Get indices of the dataset\n",
    "        sorted_indices = sorted(indices, key=lambda i: max(len(self.dataset[i][0]), len(self.dataset[i][1])))  # Sort indices based on sequence length\n",
    "        self.batches = []\n",
    "\n",
    "        # Group indices into batches of sequences with the same length\n",
    "        for boundary in self.boundaries:\n",
    "            batch = [i for i in sorted_indices if len(self.dataset[i][0]) <= boundary]  # Filter indices based on length boundary\n",
    "            self.batches.append(batch)\n",
    "            sorted_indices = [i for i in sorted_indices if i not in batch]  # Remove processed indices\n",
    "\n",
    "        # Add remaining indices to the last batch\n",
    "        self.batches.append(sorted_indices)\n",
    "\n",
    "        # Yield batches with the corresponding batch sizes\n",
    "        for batch_indices, batch_size in zip(self.batches, self.batch_sizes):\n",
    "            for i in range(0, len(batch_indices), batch_size):\n",
    "                yield batch_indices[i:i + batch_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(batch) // batch_size + 1 for batch, batch_size in zip(self.batches, self.batch_sizes))\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Separate the input sequences, target sequences, and attention masks\n",
    "    input_seqs, input_masks, target_seqs, target_masks = zip(*batch)\n",
    "\n",
    "    # Pad the input sequences to have the same length\n",
    "    padded_input_seqs = pad_sequence(input_seqs, batch_first=True)\n",
    "\n",
    "    # Pad the target sequences to have the same length\n",
    "    padded_target_seqs = pad_sequence(target_seqs, batch_first=True)\n",
    "\n",
    "    # Pad the input masks to have the same length\n",
    "    padded_input_masks = pad_sequence(input_masks, batch_first=True)\n",
    "\n",
    "    # Pad the labels masks to have the same length\n",
    "    padded_target_masks = pad_sequence(target_masks, batch_first=True)\n",
    "\n",
    "    return padded_input_seqs, padded_input_masks, padded_target_seqs, padded_target_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oumar Kane\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pytorch1-HleOW5am-py3.10\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%run wolof-translate/wolof_translate/data/dataset_v4.py\n",
    "%run wolof-translate/wolof_translate/utils/bucket_iterator.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create two datasets. One for the training and another for the validation. We need to upload and split the sentences before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wolof_translate.utils.split_with_valid import split_data\n",
    "from wolof_translate.data.dataset_v4 import SentenceDataset\n",
    "# from wolof_translate.utils.bucket_iterator import SameLengthBatchSampler, collate_fn\n",
    "from transformers import T5TokenizerFast\n",
    "\n",
    "# split the data\n",
    "split_data(random_state=0, csv_file='ad_sentences.csv')\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = T5TokenizerFast('wolof-translate/wolof_translate/tokenizers/t5_tokenizers/tokenizer_v4.model')\n",
    "\n",
    "# load the train data\n",
    "train_dataset = SentenceDataset('data/extractions/new_data/train_set.csv', tokenizer)\n",
    "\n",
    "sampler = SequenceLengthBatchSampler(train_dataset, [2, 23, 43, 64, 84, 104], [256, 128, 64, 32, 16, 8, 4])\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=sampler, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "torch.Size([128, 6])\n",
      "torch.Size([128, 7])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 9])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 11])\n",
      "torch.Size([128, 12])\n",
      "torch.Size([128, 13])\n",
      "torch.Size([128, 15])\n",
      "torch.Size([128, 20])\n",
      "torch.Size([27, 23])\n",
      "torch.Size([62, 43])\n",
      "torch.Size([32, 63])\n",
      "torch.Size([2, 64])\n",
      "torch.Size([16, 72])\n",
      "torch.Size([11, 84])\n",
      "torch.Size([8, 93])\n",
      "torch.Size([3, 99])\n",
      "torch.Size([4, 151])\n",
      "torch.Size([4, 206])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for input_, mask_, labels, _ in dataloader:\n",
    "    i+=1\n",
    "    print(input_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1-HleOW5am-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
