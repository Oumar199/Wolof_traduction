{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"YTsVWwCgLAJl"},"source":["First Training with the GPT-2 decoder ğŸ¤– (bayes search)\n","-----------------------------------\n","\n","In this notebook, we will train the pre-trained GPT-2 model provided by OPEN-AI. It only tests how the model can be accurate on the corpora we extracted. It is undoubtedly a partial model. We will add hyperparameter search with the `wandb` library.\n"]},{"cell_type":"markdown","metadata":{"id":"LpFGxo7ULAJp"},"source":["We will make this with and without augmentation and see where we obtain better results. "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":456,"status":"ok","timestamp":1682856578114,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"0NmODpFxX2Ik"},"outputs":[],"source":["# let us extend the paths of the system\n","import sys\n","\n","path = \"/content/drive/MyDrive/Memoire/subject2/\"\n","\n","sys.path.extend([f\"{path}new_data\", f\"{path}wolof-translate\"])"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682856578591,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"JqaQuyv3XvHl","outputId":"0624cc6a-413c-42c8-ca9d-c701d607cc27"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_LOG_MODEL=true\n","env: WANDB_NOTEBOOK_NAME=training_gpt2_2.ipynb\n","env: WANDB_API_KEY=237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\n"]}],"source":["# define environment\n","%env WANDB_LOG_MODEL=true\n","%env WANDB_NOTEBOOK_NAME=training_gpt2_2.ipynb\n","%env WANDB_API_KEY=237a8450cd2568ea1c8e1f8e0400708e79b6b4ee "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12544,"status":"ok","timestamp":1682856591133,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"rOALYu0I1th2","outputId":"d141da13-a23d-4db6-a717-f1699710f69c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -qq wandb --upgrade"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121009,"status":"ok","timestamp":1682856712137,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"YqElKFkPLAJq","outputId":"7cd65a9b-5193-4f72-9876-13c948e47023"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h2023-04-30 12:11:04.333008: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-30 12:11:05.364790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-04-30 12:11:06.652553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-04-30 12:11:06.653000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-04-30 12:11:06.653196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fr-core-news-lg==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.5.0/fr_core_news_lg-3.5.0-py3-none-any.whl (571.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-lg==3.5.0) (3.5.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (4.65.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.3.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.10.1)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (6.3.0)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.7.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (23.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.22.4)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.1.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (67.7.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.0.12)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.4.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.0.9)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.8)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.10.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.0.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.27.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.1.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (8.1.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.7)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.12)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.1.2)\n","Installing collected packages: fr-core-news-lg\n","Successfully installed fr-core-news-lg-3.5.0\n","\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_lg')\n"]}],"source":["!pip install evaluate -qq\n","!pip install sacrebleu -qq\n","# !pip install optuna -qq\n","!pip install transformers -qq \n","!pip install tokenizers -qq\n","!pip install nlpaug -qq\n","!pip install ray[tune] -qq\n","!python -m spacy download fr_core_news_lg "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":45175,"status":"ok","timestamp":1682856757309,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"dF37F8_nLAJr"},"outputs":[],"source":["# let us import all necessary libraries\n","from wolof_translate.utils.sent_transformers import TransformerSequences\n","from transformers import GPT2LMHeadModel, TrainingArguments, Trainer\n","from wolof_translate.data.dataset_v1 import SentenceDataset\n","from wolof_translate.utils.sent_corrections import *\n","from sklearn.model_selection import train_test_split\n","from nlpaug.augmenter import char as nac\n","from torch.utils.data import DataLoader\n","# from datasets  import load_metric # make pip install evaluate instead\n","# and pip install sacrebleu for instance\n","from functools import partial\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import evaluate\n","import torch\n"]},{"cell_type":"markdown","metadata":{"id":"ypAj4KXBLAJs"},"source":["We will create two models: \n","\n","- One translating the french corpus to a wolof corpus [french_to_wolof](#french-to-wolof)\n","- One translating the wolof corpus to a french corpus [wolof_to_french](#wolof-to-french)"]},{"cell_type":"markdown","metadata":{"id":"mtgeyZoxLAJs"},"source":["--------------"]},{"cell_type":"markdown","metadata":{"id":"19MVywzSLAJt"},"source":["## French to wolof"]},{"cell_type":"markdown","metadata":{"id":"n4tP0YGyLAJt"},"source":["### Configure dataset ğŸ” "]},{"cell_type":"markdown","metadata":{"id":"e6dLQ3poLAJu"},"source":["We can use the same custom dataset that we created in [text_augmentation](text_augmentation.ipynb). But we need to split the data between train and test sets and save them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GyCZiVSvLAJu"},"outputs":[],"source":["def split_data(random_state: int = 50):\n","\n","  # load the corpora and split into train and test sets\n","  corpora = pd.read_csv(f\"{path}new_data/sent_extraction.csv\")\n","\n","  train_set, test_set = train_test_split(corpora, test_size=0.1, random_state=random_state)\n","\n","  # let us save the sets\n","  train_set.to_csv(f\"{path}new_data/train_set.csv\", index=False)\n","\n","  test_set.to_csv(f\"{path}new_data/test_set.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"WahLNKJ0LAJv"},"source":["Let us recuperate the datasets with and without augmentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BIjksuH9LAJv"},"outputs":[],"source":["def recuperate_datasets(fr_char_p: float, fr_word_p: float):\n","\n","  # with augmentation\n","  fr_augmentation = TransformerSequences(nac.KeyboardAug(aug_char_p=fr_char_p, aug_word_p=fr_word_p),\n","                                        remove_mark_space, delete_guillemet_space)\n","\n","  train_dataset_aug = SentenceDataset(f\"{path}new_data/train_set.csv\", \n","                                  tokenizer_path = f\"{path}wolof-translate/wolof_translate/tokenizers/tokenizer_v1.json\",\n","                                  cp1_transformer=fr_augmentation, truncation=True,\n","                                  max_len=579)\n","\n","  test_dataset = SentenceDataset(f\"{path}new_data/test_set.csv\",\n","                                tokenizer_path = f\"{path}wolof-translate/wolof_translate/tokenizers/tokenizer_v1.json\",\n","                                truncation=True, max_len=579)\n","  \n","  return train_dataset_aug, test_dataset"]},{"cell_type":"markdown","metadata":{"id":"eLlcsICXpOmj"},"source":["### Configure hyperparameter search âš™ï¸"]},{"cell_type":"markdown","metadata":{"id":"JR9MwAFQppk0"},"source":["We have to configure the search space and the search method (\"random\" in our case). ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3083,"status":"ok","timestamp":1682791296605,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"},"user_tz":0},"id":"QSNJ1s_ypZWg","outputId":"21a28146-51dc-4b3a-867a-cef906282ec8"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moumar-kane\u001b[0m (\u001b[33moumar-kane-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"name":"stdout","output_type":"stream","text":["Create sweep with ID: uy1shq94\n","Sweep URL: https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94\n"]}],"source":["import wandb\n","wandb.login(key=\"237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\")\n","\n","# hyperparameters\n","sweep_config = {\n","    'method': 'bayes',\n","    'metric':{\n","          'goal': 'minimize',\n","          'name': 'eval_loss'\n","      },\n","    'parameters':\n","    {\n","      'epochs': {\n","          'value': 1\n","      },\n","      'batch_size': {\n","          'values': [2, 3, 5]\n","      },\n","      'learning_rate': {\n","          'distribution': 'log_uniform_values',\n","          'min': 1e-5,\n","          'max': 1e-3\n","      },\n","      'weight_decay': {\n","          'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n","      },\n","     'fr_char_p': {\n","         'min': 0.0,\n","         'max': 0.7\n","     },\n","     'fr_word_p': {\n","          'min': 0.0,\n","          'max': 0.7\n","     },\n","     'random_state': {\n","         'values': [0, 10, 20, 30, 40, 50, 60, 70, 80, 100]\n","     }\n","    }\n","}\n","\n","# Initialize the hyperparameter search\n","sweep_id = wandb.sweep(sweep_config, project = \"gpt2-wolof-french-translation_bayes1\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0vhzP3IaLAJv"},"source":["### Configure the model and the evaluation function âš™ï¸"]},{"cell_type":"markdown","metadata":{"id":"Ts_cesDLLAJw"},"source":["Let us recuperate the model and resize the token embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CO1jx85eLAJw"},"outputs":[],"source":["def gpt2_model_init(tokenizer):\n","  # set the mode name\n","  model_name = \"gpt2\"\n","\n","  # recuperate the tokenizer from the dataset\n","  tokenizer = tokenizer\n","\n","  # configure the model\n","  model = GPT2LMHeadModel.from_pretrained(model_name).cuda()\n","\n","  # resize the token embeddings\n","  model.resize_token_embeddings(len(tokenizer))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"R8I3tm4WLAJx"},"source":["Let us evaluate the predictions with the `bleu` metric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IerZolDNLAJx"},"outputs":[],"source":["# %%writefile wolof-translate/wolof_translate/utils/evaluation.py\n","from tokenizers import Tokenizer\n","from typing import *\n","import numpy as np\n","import evaluate\n","\n","class TranslationEvaluation:\n","    \n","    def __init__(self, \n","                 tokenizer: Tokenizer,\n","                 decoder: Union[Callable, None] = None,\n","                 metric = evaluate.load('sacrebleu'),\n","                 ):\n","        \n","        self.tokenizer = tokenizer\n","        \n","        self.decoder = decoder\n","        \n","        self.metric = metric\n","    \n","    def postprocess_text(self, preds, labels):\n","        \n","        preds = [pred.strip() for pred in preds]\n","        \n","        labels = [[label.strip()] for label in labels]\n","        \n","        return preds, labels\n","\n","    def compute_metrics(self, eval_preds):\n","        \n","        preds, labels = eval_preds.preds.detach().cpu(), labels.detach().cpu()\n","        \n","        if isinstance(preds, tuple):\n","            \n","            preds = preds[0]\n","        \n","        if self.decoder is None:\n","            \n","            decoded_preds = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n","            \n","            decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n","            \n","            decoded_preds, decoded_labels = self.postprocess_text(decoded_preds, decoded_labels)\n","            \n","            result = self.metric.compute(predictions=decoded_preds, references=decoded_labels)\n","            \n","            result = {\"bleu\": result[\"score\"]}\n","            \n","            prediction_lens = [np.count_nonzero(pred != self.tokenizer.pad_token_id) for pred in preds]\n","            \n","            result[\"gen_len\"] = np.mean(prediction_lens)\n","        \n","        else:\n","            \n","            predictions = list(self.decoder(preds))\n","            \n","            labels = list(self.decoder(labels))\n","      \n","            decoded_preds, decoded_labels = self.postprocess_text(predictions, labels)\n","            \n","            result = self.metric.compute(predictions=predictions, references=labels)\n","            \n","            result = {\"bleu\": result[\"score\"]}\n","        \n","        result = {k:round(v, 4) for k, v in result.items()}\n","\n","        wandb.log(\"bleu\", result[\"bleu\"])\n","            \n","        return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEvlO5mtLAJx"},"outputs":[],"source":["# %run wolof-translate/wolof_translate/utils/evaluation.py"]},{"cell_type":"markdown","metadata":{"id":"IuppKYiyLAJx"},"source":["Let us initialize the evaluation object."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7Bpd4UPLAJy"},"outputs":[],"source":["# translation_eval = TranslationEvaluation(test_dataset.tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"xT17hB19LAJy"},"source":["### Searching for the best parameters ğŸ•–"]},{"cell_type":"markdown","metadata":{"id":"XQ5evOG5LAJw"},"source":["Let us define the data collator."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgVN115tLAJw"},"outputs":[],"source":["def data_collator(batch):\n","    \"\"\"Generate a batch of data to provide to trainer\n","\n","    Args:\n","        batch (_type_): The batch\n","\n","    Returns:\n","        dict: A dictionary containing the ids, the attention mask and the labels\n","    \"\"\"\n","    input_ids = torch.stack([b[0] for b in batch])\n","    \n","    attention_mask = torch.stack([b[1] for b in batch])\n","    \n","    labels = torch.stack([b[0] for b in batch])\n","    \n","    return {'input_ids': input_ids, 'attention_mask': attention_mask,\n","            'labels': labels}"]},{"cell_type":"markdown","metadata":{"id":"Ry3DmkBuLAJy"},"source":["Let us initialize the training arguments and make random search."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2f4aec705bc840268c3113b08e088dbc","338e1d1e2d144fb5848840e008928c04","72bddef17ce7475b884e9b7ec4cf2d1d","2bd00e6995c2483199e6c667c40b79ef","eb2d1996cc3b4256832da78d8b21be03","15ecb66090e4439a9bd2b3dba056471b","2da5b9ec1b144375840702623eb01253","5ad758aeffe344a9bcbe49fa225671b1"]},"executionInfo":{"elapsed":1396006,"status":"ok","timestamp":1682794502972,"user":{"displayName":"Oumar Kane","userId":"07762555087280818881"},"user_tz":0},"id":"D_yP2Ny6LAJy","outputId":"0ad4e889-45f1-49df-c887-ee4d3ffa0c5f"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9e51e1u9 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.5581741048902115\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6578266163044363\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.805299002293826e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 100\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_180138-9e51e1u9</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9e51e1u9' target=\"_blank\">skilled-sweep-1</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9e51e1u9' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9e51e1u9</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:32, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.622000</td>\n","      <td>0.906943</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.90694</td></tr><tr><td>eval/runtime</td><td>2.6736</td></tr><tr><td>eval/samples_per_second</td><td>30.671</td></tr><tr><td>eval/steps_per_second</td><td>6.359</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.622</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.62203</td></tr><tr><td>train/train_runtime</td><td>88.3603</td></tr><tr><td>train/train_samples_per_second</td><td>8.296</td></tr><tr><td>train/train_steps_per_second</td><td>2.773</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">skilled-sweep-1</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9e51e1u9' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9e51e1u9</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_180138-9e51e1u9/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 77xbcu8n with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.04780608618206691\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.2934642666867476\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004265318428674258\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_180351-77xbcu8n</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/77xbcu8n' target=\"_blank\">fallen-sweep-2</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/77xbcu8n' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/77xbcu8n</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:40, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.250400</td>\n","      <td>0.778923</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.77892</td></tr><tr><td>eval/runtime</td><td>2.7289</td></tr><tr><td>eval/samples_per_second</td><td>30.049</td></tr><tr><td>eval/steps_per_second</td><td>6.23</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2504</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.25037</td></tr><tr><td>train/train_runtime</td><td>94.7322</td></tr><tr><td>train/train_samples_per_second</td><td>7.738</td></tr><tr><td>train/train_steps_per_second</td><td>3.874</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">fallen-sweep-2</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/77xbcu8n' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/77xbcu8n</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_180351-77xbcu8n/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1iwqpkgm with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.16737852032273567\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.28649966586939685\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00013263986254450776\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_180554-1iwqpkgm</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/1iwqpkgm' target=\"_blank\">sleek-sweep-3</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/1iwqpkgm' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/1iwqpkgm</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:26, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.662700</td>\n","      <td>0.840447</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.84045</td></tr><tr><td>eval/runtime</td><td>2.7528</td></tr><tr><td>eval/samples_per_second</td><td>29.787</td></tr><tr><td>eval/steps_per_second</td><td>6.175</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.6627</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.66269</td></tr><tr><td>train/train_runtime</td><td>81.0714</td></tr><tr><td>train/train_samples_per_second</td><td>9.041</td></tr><tr><td>train/train_steps_per_second</td><td>1.813</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">sleek-sweep-3</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/1iwqpkgm' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/1iwqpkgm</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_180554-1iwqpkgm/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 735lugar with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.526513857153737\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.49282705038844304\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002043984784509529\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_180746-735lugar</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/735lugar' target=\"_blank\">feasible-sweep-4</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/735lugar' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/735lugar</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.383500</td>\n","      <td>0.877133</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.87713</td></tr><tr><td>eval/runtime</td><td>2.7615</td></tr><tr><td>eval/samples_per_second</td><td>29.694</td></tr><tr><td>eval/steps_per_second</td><td>6.156</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3835</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.38353</td></tr><tr><td>train/train_runtime</td><td>97.2361</td></tr><tr><td>train/train_samples_per_second</td><td>7.538</td></tr><tr><td>train/train_steps_per_second</td><td>3.774</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">feasible-sweep-4</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/735lugar' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/735lugar</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_180746-735lugar/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7kglau67 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.6531041380804302\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.23760096478570283\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000718198892880793\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_180954-7kglau67</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/7kglau67' target=\"_blank\">serene-sweep-5</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/7kglau67' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/7kglau67</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:36, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.397100</td>\n","      <td>0.776812</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.77681</td></tr><tr><td>eval/runtime</td><td>2.7758</td></tr><tr><td>eval/samples_per_second</td><td>29.541</td></tr><tr><td>eval/steps_per_second</td><td>6.124</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.3971</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.39714</td></tr><tr><td>train/train_runtime</td><td>90.5301</td></tr><tr><td>train/train_samples_per_second</td><td>8.097</td></tr><tr><td>train/train_steps_per_second</td><td>2.706</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">serene-sweep-5</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/7kglau67' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/7kglau67</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_180954-7kglau67/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4m2eka1h with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.6167489331342644\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.24656203270287985\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000451149817879716\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_181202-4m2eka1h</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/4m2eka1h' target=\"_blank\">sleek-sweep-6</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/4m2eka1h' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/4m2eka1h</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.325800</td>\n","      <td>0.719152</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.71915</td></tr><tr><td>eval/runtime</td><td>2.7706</td></tr><tr><td>eval/samples_per_second</td><td>29.597</td></tr><tr><td>eval/steps_per_second</td><td>6.136</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.3258</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.32579</td></tr><tr><td>train/train_runtime</td><td>96.9362</td></tr><tr><td>train/train_samples_per_second</td><td>7.562</td></tr><tr><td>train/train_steps_per_second</td><td>3.786</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">sleek-sweep-6</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/4m2eka1h' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/4m2eka1h</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_181202-4m2eka1h/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9mvh0lnh with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.2264991217570484\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.5839893860446403\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00030585180789287445\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_181410-9mvh0lnh</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9mvh0lnh' target=\"_blank\">solar-sweep-7</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9mvh0lnh' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9mvh0lnh</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.634900</td>\n","      <td>0.898007</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89801</td></tr><tr><td>eval/runtime</td><td>2.7625</td></tr><tr><td>eval/samples_per_second</td><td>29.683</td></tr><tr><td>eval/steps_per_second</td><td>6.154</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.6349</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.63492</td></tr><tr><td>train/train_runtime</td><td>82.9317</td></tr><tr><td>train/train_samples_per_second</td><td>8.839</td></tr><tr><td>train/train_steps_per_second</td><td>1.773</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">solar-sweep-7</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9mvh0lnh' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9mvh0lnh</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_181410-9mvh0lnh/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o5wp33w1 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.2879121617388648\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.2953003698700635\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.077734501713909e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_181608-o5wp33w1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/o5wp33w1' target=\"_blank\">rural-sweep-8</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/o5wp33w1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/o5wp33w1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:36, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.522200</td>\n","      <td>0.813414</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.81341</td></tr><tr><td>eval/runtime</td><td>2.7541</td></tr><tr><td>eval/samples_per_second</td><td>29.774</td></tr><tr><td>eval/steps_per_second</td><td>6.173</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5222</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5222</td></tr><tr><td>train/train_runtime</td><td>90.2152</td></tr><tr><td>train/train_samples_per_second</td><td>8.125</td></tr><tr><td>train/train_steps_per_second</td><td>2.716</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">rural-sweep-8</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/o5wp33w1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/o5wp33w1</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_181608-o5wp33w1/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vlw3r86q with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.35615767375446367\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.5877794126953338\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.97269044032181e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_181816-vlw3r86q</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/vlw3r86q' target=\"_blank\">super-sweep-9</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/vlw3r86q' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/vlw3r86q</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.763600</td>\n","      <td>0.962839</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.96284</td></tr><tr><td>eval/runtime</td><td>2.7583</td></tr><tr><td>eval/samples_per_second</td><td>29.729</td></tr><tr><td>eval/steps_per_second</td><td>6.163</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7636</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.7636</td></tr><tr><td>train/train_runtime</td><td>83.5912</td></tr><tr><td>train/train_samples_per_second</td><td>8.769</td></tr><tr><td>train/train_steps_per_second</td><td>1.759</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">super-sweep-9</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/vlw3r86q' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/vlw3r86q</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_181816-vlw3r86q/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zwrcu8nw with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.20880201195327625\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.27812413200334757\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006676348627454577\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_182013-zwrcu8nw</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/zwrcu8nw' target=\"_blank\">polished-sweep-10</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/zwrcu8nw' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/zwrcu8nw</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.290900</td>\n","      <td>0.818876</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.81888</td></tr><tr><td>eval/runtime</td><td>2.7529</td></tr><tr><td>eval/samples_per_second</td><td>29.786</td></tr><tr><td>eval/steps_per_second</td><td>6.175</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2909</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.29091</td></tr><tr><td>train/train_runtime</td><td>97.6152</td></tr><tr><td>train/train_samples_per_second</td><td>7.509</td></tr><tr><td>train/train_steps_per_second</td><td>3.76</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">polished-sweep-10</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/zwrcu8nw' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/zwrcu8nw</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_182013-zwrcu8nw/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8tairrrb with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.15050441182036742\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6911094810657563\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.216059735391623e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_182225-8tairrrb</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/8tairrrb' target=\"_blank\">misty-sweep-11</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/8tairrrb' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/8tairrrb</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.753600</td>\n","      <td>0.924779</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.92478</td></tr><tr><td>eval/runtime</td><td>2.7592</td></tr><tr><td>eval/samples_per_second</td><td>29.719</td></tr><tr><td>eval/steps_per_second</td><td>6.161</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7536</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.75356</td></tr><tr><td>train/train_runtime</td><td>82.4997</td></tr><tr><td>train/train_samples_per_second</td><td>8.885</td></tr><tr><td>train/train_steps_per_second</td><td>1.782</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">misty-sweep-11</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/8tairrrb' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/8tairrrb</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_182225-8tairrrb/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0m1wbxrq with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.39337281602009766\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.2975121495884152\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025823365169873195\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_182422-0m1wbxrq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0m1wbxrq' target=\"_blank\">fancy-sweep-12</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0m1wbxrq' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0m1wbxrq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:36, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.445900</td>\n","      <td>0.830113</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.83011</td></tr><tr><td>eval/runtime</td><td>2.7731</td></tr><tr><td>eval/samples_per_second</td><td>29.57</td></tr><tr><td>eval/steps_per_second</td><td>6.13</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.4459</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.44591</td></tr><tr><td>train/train_runtime</td><td>90.7783</td></tr><tr><td>train/train_samples_per_second</td><td>8.075</td></tr><tr><td>train/train_steps_per_second</td><td>2.699</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">fancy-sweep-12</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0m1wbxrq' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0m1wbxrq</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_182422-0m1wbxrq/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: arpwebjc with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.3862316743502598\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.47220106624955194\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.925827727510921e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_182629-arpwebjc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/arpwebjc' target=\"_blank\">zesty-sweep-13</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/arpwebjc' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/arpwebjc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.740800</td>\n","      <td>0.915819</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.91582</td></tr><tr><td>eval/runtime</td><td>2.7545</td></tr><tr><td>eval/samples_per_second</td><td>29.77</td></tr><tr><td>eval/steps_per_second</td><td>6.172</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7408</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.74081</td></tr><tr><td>train/train_runtime</td><td>82.128</td></tr><tr><td>train/train_samples_per_second</td><td>8.925</td></tr><tr><td>train/train_steps_per_second</td><td>1.79</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">zesty-sweep-13</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/arpwebjc' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/arpwebjc</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_182629-arpwebjc/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wcpwhyq3 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.11800051372162204\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.4564208025649316\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00018349848970390976\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_182827-wcpwhyq3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/wcpwhyq3' target=\"_blank\">robust-sweep-14</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/wcpwhyq3' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/wcpwhyq3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.638100</td>\n","      <td>0.927052</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.92705</td></tr><tr><td>eval/runtime</td><td>2.7581</td></tr><tr><td>eval/samples_per_second</td><td>29.731</td></tr><tr><td>eval/steps_per_second</td><td>6.164</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.6381</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.63813</td></tr><tr><td>train/train_runtime</td><td>82.0591</td></tr><tr><td>train/train_samples_per_second</td><td>8.933</td></tr><tr><td>train/train_steps_per_second</td><td>1.791</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">robust-sweep-14</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/wcpwhyq3' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/wcpwhyq3</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_182827-wcpwhyq3/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ftqg9xyt with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.4681800871709539\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.40108962433453255\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00030905704557136456\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_183024-ftqg9xyt</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/ftqg9xyt' target=\"_blank\">laced-sweep-15</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/ftqg9xyt' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/ftqg9xyt</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='197' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [197/245 01:03 < 00:15, 3.09 it/s, Epoch 0.80/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.464800</td>\n","      <td>0.849067</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.84907</td></tr><tr><td>eval/runtime</td><td>2.7454</td></tr><tr><td>eval/samples_per_second</td><td>29.868</td></tr><tr><td>eval/steps_per_second</td><td>6.192</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.4648</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.46477</td></tr><tr><td>train/train_runtime</td><td>89.2305</td></tr><tr><td>train/train_samples_per_second</td><td>8.215</td></tr><tr><td>train/train_steps_per_second</td><td>2.746</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">laced-sweep-15</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/ftqg9xyt' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/ftqg9xyt</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_183024-ftqg9xyt/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qjf7ecgz with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.0942741739833867\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.11077105731033872\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.195377985553066e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_183242-qjf7ecgz</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/qjf7ecgz' target=\"_blank\">wise-sweep-16</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/qjf7ecgz' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/qjf7ecgz</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:41, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.251100</td>\n","      <td>0.763528</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.76353</td></tr><tr><td>eval/runtime</td><td>2.7505</td></tr><tr><td>eval/samples_per_second</td><td>29.813</td></tr><tr><td>eval/steps_per_second</td><td>6.181</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2511</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.25109</td></tr><tr><td>train/train_runtime</td><td>96.8803</td></tr><tr><td>train/train_samples_per_second</td><td>7.566</td></tr><tr><td>train/train_steps_per_second</td><td>3.788</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">wise-sweep-16</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/qjf7ecgz' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/qjf7ecgz</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_183242-qjf7ecgz/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f1cid8te with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.6729225034492003\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.5852055032457493\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.41693533259522e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_183455-f1cid8te</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/f1cid8te' target=\"_blank\">celestial-sweep-17</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/f1cid8te' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/f1cid8te</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.423000</td>\n","      <td>0.910818</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.91082</td></tr><tr><td>eval/runtime</td><td>2.7587</td></tr><tr><td>eval/samples_per_second</td><td>29.724</td></tr><tr><td>eval/steps_per_second</td><td>6.162</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.423</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.42299</td></tr><tr><td>train/train_runtime</td><td>97.7784</td></tr><tr><td>train/train_samples_per_second</td><td>7.497</td></tr><tr><td>train/train_steps_per_second</td><td>3.753</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">celestial-sweep-17</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/f1cid8te' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/f1cid8te</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_183455-f1cid8te/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kgcnthew with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.17242885520656936\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.3844696616235247\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.146643120298594e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_183716-kgcnthew</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/kgcnthew' target=\"_blank\">worthy-sweep-18</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/kgcnthew' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/kgcnthew</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.502400</td>\n","      <td>0.824268</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.82427</td></tr><tr><td>eval/runtime</td><td>2.7579</td></tr><tr><td>eval/samples_per_second</td><td>29.733</td></tr><tr><td>eval/steps_per_second</td><td>6.164</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5024</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5024</td></tr><tr><td>train/train_runtime</td><td>90.2345</td></tr><tr><td>train/train_samples_per_second</td><td>8.123</td></tr><tr><td>train/train_steps_per_second</td><td>2.715</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">worthy-sweep-18</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/kgcnthew' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/kgcnthew</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_183716-kgcnthew/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9hhnfdly with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.5524365189614215\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.1326794146861514\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.757229279228031e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_183922-9hhnfdly</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9hhnfdly' target=\"_blank\">cosmic-sweep-19</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9hhnfdly' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9hhnfdly</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:41, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.329200</td>\n","      <td>0.863907</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.86391</td></tr><tr><td>eval/runtime</td><td>2.7623</td></tr><tr><td>eval/samples_per_second</td><td>29.685</td></tr><tr><td>eval/steps_per_second</td><td>6.154</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3292</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.32921</td></tr><tr><td>train/train_runtime</td><td>96.8028</td></tr><tr><td>train/train_samples_per_second</td><td>7.572</td></tr><tr><td>train/train_steps_per_second</td><td>3.791</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">cosmic-sweep-19</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9hhnfdly' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/9hhnfdly</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_183922-9hhnfdly/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0iaeouhb with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.16205938534015293\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.6189463501369112\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.122207999993984e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_184139-0iaeouhb</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0iaeouhb' target=\"_blank\">eager-sweep-20</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0iaeouhb' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0iaeouhb</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.544400</td>\n","      <td>0.865255</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.86525</td></tr><tr><td>eval/runtime</td><td>2.7603</td></tr><tr><td>eval/samples_per_second</td><td>29.707</td></tr><tr><td>eval/steps_per_second</td><td>6.159</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5444</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.54436</td></tr><tr><td>train/train_runtime</td><td>89.9251</td></tr><tr><td>train/train_samples_per_second</td><td>8.151</td></tr><tr><td>train/train_steps_per_second</td><td>2.724</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">eager-sweep-20</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0iaeouhb' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/0iaeouhb</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_184139-0iaeouhb/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r0cxa419 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.4361037612688261\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.5717770674686344\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00016029380823855152\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 100\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_184349-r0cxa419</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/r0cxa419' target=\"_blank\">fearless-sweep-21</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/r0cxa419' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/r0cxa419</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:41, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.389000</td>\n","      <td>0.825492</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.82549</td></tr><tr><td>eval/runtime</td><td>2.8054</td></tr><tr><td>eval/samples_per_second</td><td>29.229</td></tr><tr><td>eval/steps_per_second</td><td>6.06</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.389</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.38902</td></tr><tr><td>train/train_runtime</td><td>96.8345</td></tr><tr><td>train/train_samples_per_second</td><td>7.57</td></tr><tr><td>train/train_steps_per_second</td><td>3.79</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">fearless-sweep-21</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/r0cxa419' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/r0cxa419</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_184349-r0cxa419/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i6yhiihu with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.16560673137459947\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.12730656857678593\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.1355786362382953e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f4aec705bc840268c3113b08e088dbc","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669043583321278, max=1.0â€¦"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_184603-i6yhiihu</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/i6yhiihu' target=\"_blank\">ruby-sweep-22</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/i6yhiihu' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/i6yhiihu</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.383500</td>\n","      <td>0.856237</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85624</td></tr><tr><td>eval/runtime</td><td>2.7556</td></tr><tr><td>eval/samples_per_second</td><td>29.758</td></tr><tr><td>eval/steps_per_second</td><td>6.169</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3835</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.38352</td></tr><tr><td>train/train_runtime</td><td>97.4503</td></tr><tr><td>train/train_samples_per_second</td><td>7.522</td></tr><tr><td>train/train_steps_per_second</td><td>3.766</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">ruby-sweep-22</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/i6yhiihu' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/i6yhiihu</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_184603-i6yhiihu/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 69peb7ro with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.019731407124009847\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.44993573909979334\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004290223514951012\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_184825-69peb7ro</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/69peb7ro' target=\"_blank\">ethereal-sweep-23</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/69peb7ro' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/69peb7ro</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.584400</td>\n","      <td>0.809303</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.8093</td></tr><tr><td>eval/runtime</td><td>2.744</td></tr><tr><td>eval/samples_per_second</td><td>29.883</td></tr><tr><td>eval/steps_per_second</td><td>6.195</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.5844</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.58441</td></tr><tr><td>train/train_runtime</td><td>83.552</td></tr><tr><td>train/train_samples_per_second</td><td>8.773</td></tr><tr><td>train/train_steps_per_second</td><td>1.759</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">ethereal-sweep-23</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/69peb7ro' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/69peb7ro</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_184825-69peb7ro/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sajbsm4i with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.3672702769661469\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.06541575658197718\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00021593199008898315\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_185032-sajbsm4i</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/sajbsm4i' target=\"_blank\">earnest-sweep-24</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/sajbsm4i' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/sajbsm4i</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.196100</td>\n","      <td>0.773625</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.77363</td></tr><tr><td>eval/runtime</td><td>2.7907</td></tr><tr><td>eval/samples_per_second</td><td>29.383</td></tr><tr><td>eval/steps_per_second</td><td>6.092</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1961</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.19612</td></tr><tr><td>train/train_runtime</td><td>97.2478</td></tr><tr><td>train/train_samples_per_second</td><td>7.537</td></tr><tr><td>train/train_steps_per_second</td><td>3.774</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">earnest-sweep-24</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/sajbsm4i' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/sajbsm4i</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_185032-sajbsm4i/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cwc9cly1 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.10116489699879488\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.2114979131069878\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000117418264348541\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230429_185256-cwc9cly1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/cwc9cly1' target=\"_blank\">astral-sweep-25</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/sweeps/uy1shq94</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/cwc9cly1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/cwc9cly1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.413600</td>\n","      <td>0.863103</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.8631</td></tr><tr><td>eval/runtime</td><td>2.7521</td></tr><tr><td>eval/samples_per_second</td><td>29.795</td></tr><tr><td>eval/steps_per_second</td><td>6.177</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4136</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.41359</td></tr><tr><td>train/train_runtime</td><td>88.7483</td></tr><tr><td>train/train_samples_per_second</td><td>8.259</td></tr><tr><td>train/train_steps_per_second</td><td>2.761</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">astral-sweep-25</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/cwc9cly1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1/runs/cwc9cly1</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230429_185256-cwc9cly1/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# %%wandb\n","\n","def train(config = None):\n","\n","  with wandb.init(config = config):\n","\n","    # seed\n","    torch.manual_seed(50)\n","\n","    # set sweep configuration\n","    config = wandb.config\n","\n","    # split the data\n","    split_data(config.random_state)\n","\n","    # let us recuperate the datasets\n","    train_dataset, test_dataset = recuperate_datasets(config.fr_char_p, config.fr_word_p)\n","\n","    # get train and test datasets according to the config\n","\n","    # train_dataset = datasets[config.dataset_aug]['train_dataset']\n","\n","    # test_dataset = datasets[config.dataset_aug]['test_dataset']\n","\n","    # set training arguments\n","    training_args = TrainingArguments(f\"{path}training2/results1\",\n","                                      report_to = f\"wandb\",\n","                                      num_train_epochs=config.epochs,\n","                                      # logging_steps=100,\n","                                      load_best_model_at_end=True,\n","                                      save_strategy=\"epoch\",\n","                                      evaluation_strategy=\"epoch\",\n","                                      logging_strategy = 'epoch',\n","                                      per_device_train_batch_size=config.batch_size, \n","                                      per_device_eval_batch_size=5,\n","                                      learning_rate=config.learning_rate,\n","                                      weight_decay=config.weight_decay,\n","                                      logging_dir=f'{path}gpt2_training_logs2',\n","                                      remove_unused_columns = False,\n","                                      fp16 = True,\n","                                      )   \n","\n","    # define training loop\n","    trainer = Trainer(model_init=partial(gpt2_model_init, tokenizer = train_dataset.tokenizer),\n","                      args=training_args,\n","                      train_dataset=train_dataset, \n","                      eval_dataset=test_dataset,\n","                      data_collator=data_collator,\n","                      # compute_metrics=translation_eval.compute_metrics\n","                      )\n","\n","    # start training loop\n","    trainer.train()\n","\n","agent = wandb.agent(sweep_id, train, count = 25)\n"]},{"cell_type":"markdown","metadata":{"id":"u7NPlNlPgRz9"},"source":["------------------"]},{"cell_type":"markdown","metadata":{"id":"DO_49vgmTu8B"},"source":["## Wolof to french"]},{"cell_type":"markdown","metadata":{"id":"8BehHF09W3AK"},"source":["The only thing that we will change is the order of sentences. The wolof sentence is the first one to write."]},{"cell_type":"markdown","metadata":{"id":"nYjqfwjzW3AK"},"source":["### Configure dataset ğŸ” "]},{"cell_type":"markdown","metadata":{"id":"1Oul_eIAY2dz"},"source":["We can use the same custom dataset that we created in [text_augmentation](text_augmentation.ipynb). But we need to split the data between train and test sets and save them."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1682856757310,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"LPjxkXryY15-"},"outputs":[],"source":["def split_data(random_state: int = 50):\n","\n","  # load the corpora and split into train and test sets\n","  corpora = pd.read_csv(f\"{path}new_data/sent_extraction.csv\")\n","\n","  train_set, test_set = train_test_split(corpora, test_size=0.1, random_state=random_state)\n","\n","  # let us save the sets\n","  train_set.to_csv(f\"{path}new_data/train_set.csv\", index=False)\n","\n","  test_set.to_csv(f\"{path}new_data/test_set.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"hbNfFuKpW3AK"},"source":["Let us recuperate the datasets."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1682856757311,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"9nt7rn_dW3AK"},"outputs":[],"source":["def recuperate_datasets(wf_char_p: float, wf_word_p):\n","\n","  # with augmentation\n","  wf_augmentation = TransformerSequences(nac.KeyboardAug(aug_char_p=wf_char_p, aug_word_p=wf_word_p),\n","                                        remove_mark_space, delete_guillemet_space)\n","\n","  train_dataset_aug = SentenceDataset(f\"{path}new_data/train_set.csv\", \n","                                  tokenizer_path = f\"{path}wolof-translate/wolof_translate/tokenizers/tokenizer_v1.json\",\n","                                  corpus_1=\"wolof_corpus\",\n","                                  corpus_2=\"french_corpus\",\n","                                  cp1_transformer=wf_augmentation, truncation=True,\n","                                  max_len=579)\n","\n","  test_dataset = SentenceDataset(f\"{path}new_data/test_set.csv\",\n","                                tokenizer_path = f\"{path}wolof-translate/wolof_translate/tokenizers/tokenizer_v1.json\",\n","                                corpus_1=\"wolof_corpus\",\n","                                corpus_2=\"french_corpus\",\n","                                truncation=True, max_len=579)\n","  \n","  return train_dataset_aug, test_dataset"]},{"cell_type":"markdown","metadata":{"id":"sUt9UGWuW3AL"},"source":["### Configure hyperparameter search âš™ï¸"]},{"cell_type":"markdown","metadata":{"id":"L64gK2UgW3AL"},"source":["We have to configure the search space and the search method (\"random\" in our case). ."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2743,"status":"ok","timestamp":1682856760036,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"m0UqeLmDW3AL","outputId":"96d11bcf-37a7-49a6-9225-5c6db35911db"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moumar-kane\u001b[0m (\u001b[33moumar-kane-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"name":"stdout","output_type":"stream","text":["Create sweep with ID: alygo14y\n","Sweep URL: https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y\n"]}],"source":["import wandb\n","wandb.login(key=\"237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\")\n","\n","# hyperparameters\n","sweep_config = {\n","    'method': 'bayes',\n","    'metric':{\n","          'goal': 'minimize',\n","          'name': 'eval_loss'\n","      },\n","    'parameters':\n","    {\n","      'epochs': {\n","          'value': 1\n","      },\n","      'batch_size': {\n","          'values': [2, 3, 5]\n","      },\n","      'learning_rate': {\n","          'distribution': 'log_uniform_values',\n","          'min': 1e-5,\n","          'max': 1e-3\n","      },\n","      'weight_decay': {\n","          'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n","      },\n","     'wf_char_p': {\n","          'min': 0.0,\n","          'max': 0.7\n","     },\n","     'wf_word_p': {\n","          'min': 0.0,\n","          'max': 0.7\n","     },\n","     'random_state': {\n","         'values': [0, 10, 20, 30, 40, 50, 60, 70, 80, 100]\n","     }\n","    }\n","}\n","\n","# Initialize the hyperparameter search\n","sweep_id = wandb.sweep(sweep_config, project = \"gpt2-wolof-french-translation_bayes1_1\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JM7hEUdsW3AM"},"source":["### Configure the model and the evaluation function âš™ï¸"]},{"cell_type":"markdown","metadata":{"id":"h0-iQcATW3AM"},"source":["Let us recuperate the model and resize the token embeddings."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682856760036,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"QBaPD_qRW3AM"},"outputs":[],"source":["def gpt2_model_init(tokenizer):\n","  # set the mode name\n","  model_name = \"gpt2\"\n","\n","  # recuperate the tokenizer from the dataset\n","  tokenizer = tokenizer\n","\n","  # configure the model\n","  model = GPT2LMHeadModel.from_pretrained(model_name).cuda()\n","\n","  # resize the token embeddings\n","  model.resize_token_embeddings(len(tokenizer))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"U1xTTv_PW3AN"},"source":["Let us evaluate the predictions with the `bleu` metric."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["db7b4297d2f54e23b6c1a67cfc44411d","b4e89c244bf544d2b6c03c987aea33cf","4abd1a2e0e584a9f8b1d84f74a4f23bd","8ff179976b294d78a55c05512de3117f","c03b053582484d708d8150ca3d575244","be2c259b7fcd4e309c2e9bd63551e7c7","2b8b8c0820cf4f7fa226961d85129d6b","7952368ec6084469a27c61bfa43c5342","1dbcf8f3699a495bb0643eab17cea27b","ebd5507dbcb2490985432977aba34797","48a68082c7c144f38c143ab915169a7b"]},"executionInfo":{"elapsed":1550,"status":"ok","timestamp":1682856761583,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"cnPoI-vdW3AN","outputId":"8517895c-ecf5-4d6c-c5a2-29572fdcd47f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db7b4297d2f54e23b6c1a67cfc44411d","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# %%writefile wolof-translate/wolof_translate/utils/evaluation.py\n","from tokenizers import Tokenizer\n","from typing import *\n","import numpy as np\n","import evaluate\n","\n","class TranslationEvaluation:\n","    \n","    def __init__(self, \n","                 tokenizer: Tokenizer,\n","                 decoder: Union[Callable, None] = None,\n","                 metric = evaluate.load('sacrebleu'),\n","                 ):\n","        \n","        self.tokenizer = tokenizer\n","        \n","        self.decoder = decoder\n","        \n","        self.metric = metric\n","    \n","    def postprocess_text(self, preds, labels):\n","        \n","        preds = [pred.strip() for pred in preds]\n","        \n","        labels = [[label.strip()] for label in labels]\n","        \n","        return preds, labels\n","\n","    def compute_metrics(self, eval_preds):\n","        \n","        preds, labels = eval_preds.preds.detach().cpu(), labels.detach().cpu()\n","        \n","        if isinstance(preds, tuple):\n","            \n","            preds = preds[0]\n","        \n","        if self.decoder is None:\n","            \n","            decoded_preds = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n","            \n","            decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n","            \n","            decoded_preds, decoded_labels = self.postprocess_text(decoded_preds, decoded_labels)\n","            \n","            result = self.metric.compute(predictions=decoded_preds, references=decoded_labels)\n","            \n","            result = {\"bleu\": result[\"score\"]}\n","            \n","            prediction_lens = [np.count_nonzero(pred != self.tokenizer.pad_token_id) for pred in preds]\n","            \n","            result[\"gen_len\"] = np.mean(prediction_lens)\n","        \n","        else:\n","            \n","            predictions = list(self.decoder(preds))\n","            \n","            labels = list(self.decoder(labels))\n","      \n","            decoded_preds, decoded_labels = self.postprocess_text(predictions, labels)\n","            \n","            result = self.metric.compute(predictions=predictions, references=labels)\n","            \n","            result = {\"bleu\": result[\"score\"]}\n","        \n","        result = {k:round(v, 4) for k, v in result.items()}\n","\n","        wandb.log(\"bleu\", result[\"bleu\"])\n","            \n","        return result"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1682856761584,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"75UKFiPtW3AN"},"outputs":[],"source":["# %run wolof-translate/wolof_translate/utils/evaluation.py"]},{"cell_type":"markdown","metadata":{"id":"ovar55kYW3AO"},"source":["Let us initialize the evaluation object."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1682856761585,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"NEjuC9_2W3AO"},"outputs":[],"source":["# translation_eval = TranslationEvaluation(test_dataset.tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"qwsA3gtGW3AO"},"source":["### Searching for the best parameters ğŸ•–"]},{"cell_type":"markdown","metadata":{"id":"YAiR1MvmW3AO"},"source":["Let us define the data collator."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1682856761585,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"4DR6XzHQW3AO"},"outputs":[],"source":["def data_collator(batch):\n","    \"\"\"Generate a batch of data to provide to trainer\n","\n","    Args:\n","        batch (_type_): The batch\n","\n","    Returns:\n","        dict: A dictionary containing the ids, the attention mask and the labels\n","    \"\"\"\n","    input_ids = torch.stack([b[0] for b in batch])\n","    \n","    attention_mask = torch.stack([b[1] for b in batch])\n","    \n","    labels = torch.stack([b[0] for b in batch])\n","    \n","    return {'input_ids': input_ids, 'attention_mask': attention_mask,\n","            'labels': labels}"]},{"cell_type":"markdown","metadata":{"id":"2P1qVBmlW3AP"},"source":["Let us initialize the training arguments and make random search."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f73b2f84da9a4928ab0465094e5ec9cb","8b59e277cd98427fa5fc58808a2de6e3","ae1fc5bcdfa840efaf51bf505c6fa933","7880628963764d81b7f02350a1c2f04a","c7537d902cf343d5bed2616b021b88de","d2dc59c7fa5e44a6864591df27888586","0fd9d3313f6c43c9ba23e5ab70cd0213","727a7c008d89405d825bd24ad290b125","1d1088b3661e4ea397d7aa0bddd30649","e775795965144e938535b0a6fb54d880","db3eaa3328144b1fb2531df2864c7430","01613034172e4b00bee7c1dbc37404ed","27da5478ae3943a3877bd11559c5c82b","05bb4d42d5634732b02ecdad88eb6113","5a0a004f54454161bc0a72fc40bd5311","7eaf2ba083d84df8ac4ad32ce4ed10e7","ad927445b97942b7a3e6e2c26c607a94","3a02f284c2244d4aa8759d7c8caa7dd5","a0f3f82056bc4dbf9fc36aa07444704a","c8b8fdb2947c45edb6c11cf4f9115979","81a80a3ef5b74876bfe4d4342fb9a5b4","2fd1230d14fb48f1bfab3237610ff2d5","e341e084df494c2db150abf75a57894b","99d11e532b7c4bcda7e3d9c19c1b3bd7","8aa672fbbe6c40c697d9faa687ac2e20","d524cd529a654786a7659e5d6f10eb48","2b488c71e9ce434e9af5c2fc4b68355d","46a2d31366b546fbb7aef8e9dcdadb2c","a654ca3a23b243edb5b8e0a3e7a5c488","6eb5c08b7d594f36aa1900739151e663","3bed3e0675bf4961adbad59fe5559276","fd2377aeab634cbc83441e11e2c8a6c5","d0532ce3e6dd4409b8a1471ecb421e6b","440615e853584cf29c16e9393772b1e3","e51d668e16b14ee68792b76c651425b1","2672f8670b704e1584624c4c3307d651","410cfe6ea2494c149bcaa299547162e3","706408202679485481da12cc439c65a6","4308d419d5b4460eb6cbed09ad28f00d","efe22bb7e28c4c46af2a7f82dddf0bef","9d6c16f00283434db57d86feea4e2eb2"]},"executionInfo":{"elapsed":3667664,"status":"ok","timestamp":1682860429233,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"o8dXJjfhW3AP","outputId":"7173bdb4-63f5-44d2-a990-2f13ca3a418c"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0u0t6k2 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.702369179262155e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2819068695463206\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.3271474379445852\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121244-a0u0t6k2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">usual-sweep-1</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f73b2f84da9a4928ab0465094e5ec9cb","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01613034172e4b00bee7c1dbc37404ed","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e341e084df494c2db150abf75a57894b","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.331400</td>\n","      <td>0.972646</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.97265</td></tr><tr><td>eval/runtime</td><td>2.7358</td></tr><tr><td>eval/samples_per_second</td><td>29.973</td></tr><tr><td>eval/steps_per_second</td><td>6.214</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3314</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.33135</td></tr><tr><td>train/train_runtime</td><td>98.9652</td></tr><tr><td>train/train_samples_per_second</td><td>7.407</td></tr><tr><td>train/train_steps_per_second</td><td>3.708</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">usual-sweep-1</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_121244-a0u0t6k2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8p97mqyj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000687378518112751\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.10242928904824668\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.3761238934195836\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121602-8p97mqyj</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">honest-sweep-2</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:40, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.211800</td>\n","      <td>0.902809</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.90281</td></tr><tr><td>eval/runtime</td><td>2.7187</td></tr><tr><td>eval/samples_per_second</td><td>30.162</td></tr><tr><td>eval/steps_per_second</td><td>6.253</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2118</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.21175</td></tr><tr><td>train/train_runtime</td><td>95.0089</td></tr><tr><td>train/train_samples_per_second</td><td>7.715</td></tr><tr><td>train/train_steps_per_second</td><td>3.863</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">honest-sweep-2</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_121602-8p97mqyj/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cufx9n8t with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.226951404890168e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.23759176734591644\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.13227163155096622\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121831-cufx9n8t</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">grateful-sweep-3</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.571300</td>\n","      <td>0.956762</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95676</td></tr><tr><td>eval/runtime</td><td>2.7129</td></tr><tr><td>eval/samples_per_second</td><td>30.226</td></tr><tr><td>eval/steps_per_second</td><td>6.266</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5713</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.57131</td></tr><tr><td>train/train_runtime</td><td>89.3504</td></tr><tr><td>train/train_samples_per_second</td><td>8.204</td></tr><tr><td>train/train_steps_per_second</td><td>2.742</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">grateful-sweep-3</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_121831-cufx9n8t/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y2zo0avu with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007890211017920526\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2153084724244564\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.03750263309251056\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122053-y2zo0avu</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">misty-sweep-4</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.394700</td>\n","      <td>0.852979</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85298</td></tr><tr><td>eval/runtime</td><td>2.7128</td></tr><tr><td>eval/samples_per_second</td><td>30.227</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>1.3947</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.39468</td></tr><tr><td>train/train_runtime</td><td>81.7228</td></tr><tr><td>train/train_samples_per_second</td><td>8.969</td></tr><tr><td>train/train_steps_per_second</td><td>1.799</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">misty-sweep-4</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_122053-y2zo0avu/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6zl4nshz with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00013060682353049685\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6581358201308465\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.010288732393246668\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122304-6zl4nshz</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">noble-sweep-5</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.125200</td>\n","      <td>0.843749</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.84375</td></tr><tr><td>eval/runtime</td><td>2.7146</td></tr><tr><td>eval/samples_per_second</td><td>30.207</td></tr><tr><td>eval/steps_per_second</td><td>6.262</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1252</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.12516</td></tr><tr><td>train/train_runtime</td><td>96.13</td></tr><tr><td>train/train_samples_per_second</td><td>7.625</td></tr><tr><td>train/train_steps_per_second</td><td>3.818</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">noble-sweep-5</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_122304-6zl4nshz/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lmlh43bi with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.6544061486102166e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.601761705072325\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5485382582443594\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122548-lmlh43bi</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">spring-sweep-6</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.511200</td>\n","      <td>0.959907</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95991</td></tr><tr><td>eval/runtime</td><td>2.7127</td></tr><tr><td>eval/samples_per_second</td><td>30.228</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5112</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5112</td></tr><tr><td>train/train_runtime</td><td>89.39</td></tr><tr><td>train/train_samples_per_second</td><td>8.2</td></tr><tr><td>train/train_steps_per_second</td><td>2.741</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">spring-sweep-6</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_122548-lmlh43bi/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b3709lrr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.01812368676995e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.3414514505517595\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.06590909422021479\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122808-b3709lrr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">worldly-sweep-7</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.298400</td>\n","      <td>0.943387</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.94339</td></tr><tr><td>eval/runtime</td><td>2.7141</td></tr><tr><td>eval/samples_per_second</td><td>30.212</td></tr><tr><td>eval/steps_per_second</td><td>6.264</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2984</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.2984</td></tr><tr><td>train/train_runtime</td><td>88.4049</td></tr><tr><td>train/train_samples_per_second</td><td>8.291</td></tr><tr><td>train/train_steps_per_second</td><td>2.771</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">worldly-sweep-7</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_122808-b3709lrr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ixh1wkga with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.665404061522188e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2025899023149373\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.30403171896970477\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123025-ixh1wkga</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">giddy-sweep-8</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.600400</td>\n","      <td>0.898786</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89879</td></tr><tr><td>eval/runtime</td><td>2.7076</td></tr><tr><td>eval/samples_per_second</td><td>30.285</td></tr><tr><td>eval/steps_per_second</td><td>6.279</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6004</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.60037</td></tr><tr><td>train/train_runtime</td><td>83.0477</td></tr><tr><td>train/train_samples_per_second</td><td>8.826</td></tr><tr><td>train/train_steps_per_second</td><td>1.77</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">giddy-sweep-8</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123025-ixh1wkga/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yqxwql6m with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009940796140095907\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.5740543904824967\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.2462419315938406\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123241-yqxwql6m</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">rosy-sweep-9</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.284500</td>\n","      <td>0.848199</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.8482</td></tr><tr><td>eval/runtime</td><td>2.7189</td></tr><tr><td>eval/samples_per_second</td><td>30.159</td></tr><tr><td>eval/steps_per_second</td><td>6.253</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.2845</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.28448</td></tr><tr><td>train/train_runtime</td><td>96.6069</td></tr><tr><td>train/train_samples_per_second</td><td>7.587</td></tr><tr><td>train/train_steps_per_second</td><td>3.799</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">rosy-sweep-9</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123241-yqxwql6m/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6z8kvttx with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.136396657280805e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.496992386293468\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.09128048050662484\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"440615e853584cf29c16e9393772b1e3","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668863250000263, max=1.0â€¦"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123510-6z8kvttx</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">lemon-sweep-10</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.633700</td>\n","      <td>0.925104</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9251</td></tr><tr><td>eval/runtime</td><td>2.7135</td></tr><tr><td>eval/samples_per_second</td><td>30.22</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6337</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.63375</td></tr><tr><td>train/train_runtime</td><td>82.7991</td></tr><tr><td>train/train_samples_per_second</td><td>8.853</td></tr><tr><td>train/train_steps_per_second</td><td>1.775</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">lemon-sweep-10</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123510-6z8kvttx/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m9sb4aqc with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.292925960874299e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.1392332134258406\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.33276367556881936\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123730-m9sb4aqc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">resilient-sweep-11</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.377200</td>\n","      <td>0.921299</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9213</td></tr><tr><td>eval/runtime</td><td>2.7224</td></tr><tr><td>eval/samples_per_second</td><td>30.12</td></tr><tr><td>eval/steps_per_second</td><td>6.244</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3772</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.37722</td></tr><tr><td>train/train_runtime</td><td>97.2966</td></tr><tr><td>train/train_samples_per_second</td><td>7.534</td></tr><tr><td>train/train_steps_per_second</td><td>3.772</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">resilient-sweep-11</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123730-m9sb4aqc/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jbput8ui with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.444484556126347e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.29893712569494857\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.26117783521919574\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123958-jbput8ui</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">snowy-sweep-12</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.432100</td>\n","      <td>0.896062</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89606</td></tr><tr><td>eval/runtime</td><td>2.708</td></tr><tr><td>eval/samples_per_second</td><td>30.281</td></tr><tr><td>eval/steps_per_second</td><td>6.278</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4321</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.43209</td></tr><tr><td>train/train_runtime</td><td>88.9488</td></tr><tr><td>train/train_samples_per_second</td><td>8.241</td></tr><tr><td>train/train_steps_per_second</td><td>2.754</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">snowy-sweep-12</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123958-jbput8ui/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4fwhdrrr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.5593238990374552e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2943749543935819\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.12398175089457102\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124220-4fwhdrrr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">daily-sweep-13</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:30, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.699900</td>\n","      <td>0.852140</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85214</td></tr><tr><td>eval/runtime</td><td>2.7191</td></tr><tr><td>eval/samples_per_second</td><td>30.157</td></tr><tr><td>eval/steps_per_second</td><td>6.252</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6999</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.69991</td></tr><tr><td>train/train_runtime</td><td>85.2131</td></tr><tr><td>train/train_samples_per_second</td><td>8.602</td></tr><tr><td>train/train_steps_per_second</td><td>1.725</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">daily-sweep-13</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_124220-4fwhdrrr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1bz3dbic with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.890480473611398e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2378445346533837\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.4209643755950993\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124438-1bz3dbic</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">eternal-sweep-14</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.483200</td>\n","      <td>0.875917</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.87592</td></tr><tr><td>eval/runtime</td><td>2.7525</td></tr><tr><td>eval/samples_per_second</td><td>29.792</td></tr><tr><td>eval/steps_per_second</td><td>6.176</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4832</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.48315</td></tr><tr><td>train/train_runtime</td><td>90.2171</td></tr><tr><td>train/train_samples_per_second</td><td>8.125</td></tr><tr><td>train/train_steps_per_second</td><td>2.716</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">eternal-sweep-14</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_124438-1bz3dbic/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ho6ta14m with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002774553527447285\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6714497099264989\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.03656663081592687\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124701-ho6ta14m</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">kind-sweep-15</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.124700</td>\n","      <td>0.822917</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.82292</td></tr><tr><td>eval/runtime</td><td>2.7172</td></tr><tr><td>eval/samples_per_second</td><td>30.178</td></tr><tr><td>eval/steps_per_second</td><td>6.256</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.1247</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.12474</td></tr><tr><td>train/train_runtime</td><td>96.7926</td></tr><tr><td>train/train_samples_per_second</td><td>7.573</td></tr><tr><td>train/train_steps_per_second</td><td>3.792</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">kind-sweep-15</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_124701-ho6ta14m/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wmlfiw0r with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003923791647223955\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.06807537344840917\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5604330614348828\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124934-wmlfiw0r</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">radiant-sweep-16</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.500600</td>\n","      <td>0.949637</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.94964</td></tr><tr><td>eval/runtime</td><td>2.7103</td></tr><tr><td>eval/samples_per_second</td><td>30.255</td></tr><tr><td>eval/steps_per_second</td><td>6.272</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.5006</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5006</td></tr><tr><td>train/train_runtime</td><td>83.6072</td></tr><tr><td>train/train_samples_per_second</td><td>8.767</td></tr><tr><td>train/train_steps_per_second</td><td>1.758</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">radiant-sweep-16</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_124934-wmlfiw0r/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r8gcrole with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.821341363881095e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 50\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.4377052667800509\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.28337028938356845\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125204-r8gcrole</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">dainty-sweep-17</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:31, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.846200</td>\n","      <td>0.981831</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.98183</td></tr><tr><td>eval/runtime</td><td>2.7136</td></tr><tr><td>eval/samples_per_second</td><td>30.218</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8462</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.8462</td></tr><tr><td>train/train_runtime</td><td>84.9129</td></tr><tr><td>train/train_samples_per_second</td><td>8.632</td></tr><tr><td>train/train_steps_per_second</td><td>1.731</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">dainty-sweep-17</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_125204-r8gcrole/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: phwfj18n with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.811279212646426e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2317434997460037\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.4361895012572056\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125428-phwfj18n</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">apricot-sweep-18</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.639600</td>\n","      <td>0.980084</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.98008</td></tr><tr><td>eval/runtime</td><td>2.767</td></tr><tr><td>eval/samples_per_second</td><td>29.635</td></tr><tr><td>eval/steps_per_second</td><td>6.144</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6396</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.63955</td></tr><tr><td>train/train_runtime</td><td>83.6783</td></tr><tr><td>train/train_samples_per_second</td><td>8.76</td></tr><tr><td>train/train_steps_per_second</td><td>1.757</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">apricot-sweep-18</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_125428-phwfj18n/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jlqkadbj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010056956001033137\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6390337876205812\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.23792329132405943\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125655-jlqkadbj</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">good-sweep-19</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.611900</td>\n","      <td>0.873367</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.87337</td></tr><tr><td>eval/runtime</td><td>2.7126</td></tr><tr><td>eval/samples_per_second</td><td>30.23</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.6119</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.61191</td></tr><tr><td>train/train_runtime</td><td>83.1352</td></tr><tr><td>train/train_samples_per_second</td><td>8.817</td></tr><tr><td>train/train_steps_per_second</td><td>1.768</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">good-sweep-19</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_125655-jlqkadbj/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6p270685 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.129742665577746e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.39725467091195105\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5004309074101329\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125915-6p270685</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">pious-sweep-20</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.459300</td>\n","      <td>0.955068</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95507</td></tr><tr><td>eval/runtime</td><td>2.7243</td></tr><tr><td>eval/samples_per_second</td><td>30.099</td></tr><tr><td>eval/steps_per_second</td><td>6.24</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4593</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.45931</td></tr><tr><td>train/train_runtime</td><td>89.8845</td></tr><tr><td>train/train_samples_per_second</td><td>8.155</td></tr><tr><td>train/train_steps_per_second</td><td>2.726</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">pious-sweep-20</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_125915-6p270685/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gcv6axp9 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.252438217932992e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.29046645972247725\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.2600785813543463\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130144-gcv6axp9</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">dutiful-sweep-21</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.316900</td>\n","      <td>0.971379</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.97138</td></tr><tr><td>eval/runtime</td><td>2.7496</td></tr><tr><td>eval/samples_per_second</td><td>29.823</td></tr><tr><td>eval/steps_per_second</td><td>6.183</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3169</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.31693</td></tr><tr><td>train/train_runtime</td><td>97.0731</td></tr><tr><td>train/train_samples_per_second</td><td>7.551</td></tr><tr><td>train/train_steps_per_second</td><td>3.781</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">dutiful-sweep-21</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_130144-gcv6axp9/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yhyy9e23 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.647196100197014e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.1717366963251063\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.1316624948710261\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130418-yhyy9e23</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">glowing-sweep-22</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:38, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.396900</td>\n","      <td>0.856822</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85682</td></tr><tr><td>eval/runtime</td><td>2.7137</td></tr><tr><td>eval/samples_per_second</td><td>30.217</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3969</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.3969</td></tr><tr><td>train/train_runtime</td><td>91.6977</td></tr><tr><td>train/train_samples_per_second</td><td>7.994</td></tr><tr><td>train/train_steps_per_second</td><td>2.672</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">glowing-sweep-22</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_130418-yhyy9e23/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xup68ew4 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.637652455538814e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.677355252029728\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.16163588455481578\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130645-xup68ew4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">devoted-sweep-23</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.687100</td>\n","      <td>0.952795</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9528</td></tr><tr><td>eval/runtime</td><td>2.7376</td></tr><tr><td>eval/samples_per_second</td><td>29.953</td></tr><tr><td>eval/steps_per_second</td><td>6.21</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6871</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.68711</td></tr><tr><td>train/train_runtime</td><td>83.5213</td></tr><tr><td>train/train_samples_per_second</td><td>8.776</td></tr><tr><td>train/train_steps_per_second</td><td>1.76</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">devoted-sweep-23</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_130645-xup68ew4/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wa2re6yd with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00015372099844614283\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.4593404124892092\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5384324544438147\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130904-wa2re6yd</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">deft-sweep-24</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.402800</td>\n","      <td>0.823874</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.82387</td></tr><tr><td>eval/runtime</td><td>2.7275</td></tr><tr><td>eval/samples_per_second</td><td>30.064</td></tr><tr><td>eval/steps_per_second</td><td>6.233</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4028</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.40277</td></tr><tr><td>train/train_runtime</td><td>89.583</td></tr><tr><td>train/train_samples_per_second</td><td>8.182</td></tr><tr><td>train/train_steps_per_second</td><td>2.735</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">deft-sweep-24</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_130904-wa2re6yd/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i305ffth with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.284698923411304e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6295786463189464\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.6968639258681786\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_131131-i305ffth</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">sunny-sweep-25</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:36, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.509300</td>\n","      <td>0.986804</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9868</td></tr><tr><td>eval/runtime</td><td>2.7162</td></tr><tr><td>eval/samples_per_second</td><td>30.189</td></tr><tr><td>eval/steps_per_second</td><td>6.259</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5093</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5093</td></tr><tr><td>train/train_runtime</td><td>90.604</td></tr><tr><td>train/train_samples_per_second</td><td>8.09</td></tr><tr><td>train/train_steps_per_second</td><td>2.704</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">sunny-sweep-25</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_131131-i305ffth/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# %%wandb\n","\n","def train(config = None):\n","\n","  with wandb.init(config = config):\n","\n","    # seed\n","    torch.manual_seed(50)\n","\n","    # set sweep configuration\n","    config = wandb.config\n","\n","    # split the data\n","    split_data(config.random_state)\n","\n","    # let us recuperate the datasets\n","    train_dataset, test_dataset = recuperate_datasets(config.wf_char_p, config.wf_word_p)\n","\n","    # get train and test datasets according to the config\n","\n","    # train_dataset = datasets[config.dataset_aug]['train_dataset']\n","\n","    # test_dataset = datasets[config.dataset_aug]['test_dataset']\n","\n","    # set training arguments\n","    training_args = TrainingArguments(f\"{path}training2/Results1\",\n","                                      report_to = f\"wandb\",\n","                                      num_train_epochs=config.epochs,\n","                                      # logging_steps=100,\n","                                      load_best_model_at_end=True,\n","                                      save_strategy=\"epoch\",\n","                                      evaluation_strategy=\"epoch\",\n","                                      logging_strategy = 'epoch',\n","                                      per_device_train_batch_size=config.batch_size, \n","                                      per_device_eval_batch_size=5,\n","                                      learning_rate=config.learning_rate,\n","                                      weight_decay=config.weight_decay,\n","                                      remove_unused_columns = False,\n","                                      fp16 = True,\n","                                      )   \n","\n","    # define training loop\n","    trainer = Trainer(model_init=partial(gpt2_model_init, tokenizer = train_dataset.tokenizer),\n","                      args=training_args,\n","                      train_dataset=train_dataset, \n","                      eval_dataset=test_dataset,\n","                      data_collator=data_collator,\n","                      # compute_metrics=translation_eval.compute_metrics\n","                      )\n","\n","    # start training loop\n","    trainer.train()\n","\n","agent = wandb.agent(sweep_id, train, count = 25)\n"]},{"cell_type":"markdown","metadata":{"id":"3DIrLmGrW3AP"},"source":["-----------"]},{"cell_type":"markdown","metadata":{"id":"WLu_sR9yW3AQ"},"source":["## Colab download and remove step"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3063,"status":"ok","timestamp":1682856555863,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"vvqj0ijnW3AQ"},"outputs":[],"source":["import shutil\n","\n","# shutil.rmtree('/content/drive/MyDrive/Memoire/subject2/training2/Results1')\n","# shutil.rmtree('wandb')\n","# shutil.make_archive('wandb', 'zip', 'wanbd')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUz2Le60ESVZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"pytorch1-HleOW5am-py3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"01613034172e4b00bee7c1dbc37404ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27da5478ae3943a3877bd11559c5c82b","IPY_MODEL_05bb4d42d5634732b02ecdad88eb6113","IPY_MODEL_5a0a004f54454161bc0a72fc40bd5311"],"layout":"IPY_MODEL_7eaf2ba083d84df8ac4ad32ce4ed10e7"}},"05bb4d42d5634732b02ecdad88eb6113":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0f3f82056bc4dbf9fc36aa07444704a","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8b8fdb2947c45edb6c11cf4f9115979","value":548118077}},"0fd9d3313f6c43c9ba23e5ab70cd0213":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15ecb66090e4439a9bd2b3dba056471b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d1088b3661e4ea397d7aa0bddd30649":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1dbcf8f3699a495bb0643eab17cea27b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2672f8670b704e1584624c4c3307d651":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_efe22bb7e28c4c46af2a7f82dddf0bef","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d6c16f00283434db57d86feea4e2eb2","value":1}},"27da5478ae3943a3877bd11559c5c82b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad927445b97942b7a3e6e2c26c607a94","placeholder":"â€‹","style":"IPY_MODEL_3a02f284c2244d4aa8759d7c8caa7dd5","value":"Downloading pytorch_model.bin: 100%"}},"2b488c71e9ce434e9af5c2fc4b68355d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b8b8c0820cf4f7fa226961d85129d6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bd00e6995c2483199e6c667c40b79ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2da5b9ec1b144375840702623eb01253":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f4aec705bc840268c3113b08e088dbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_338e1d1e2d144fb5848840e008928c04","IPY_MODEL_72bddef17ce7475b884e9b7ec4cf2d1d"],"layout":"IPY_MODEL_2bd00e6995c2483199e6c667c40b79ef"}},"2fd1230d14fb48f1bfab3237610ff2d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"338e1d1e2d144fb5848840e008928c04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb2d1996cc3b4256832da78d8b21be03","placeholder":"â€‹","style":"IPY_MODEL_15ecb66090e4439a9bd2b3dba056471b","value":"Waiting for wandb.init()...\r"}},"3a02f284c2244d4aa8759d7c8caa7dd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bed3e0675bf4961adbad59fe5559276":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"410cfe6ea2494c149bcaa299547162e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4308d419d5b4460eb6cbed09ad28f00d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"440615e853584cf29c16e9393772b1e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e51d668e16b14ee68792b76c651425b1","IPY_MODEL_2672f8670b704e1584624c4c3307d651"],"layout":"IPY_MODEL_410cfe6ea2494c149bcaa299547162e3"}},"46a2d31366b546fbb7aef8e9dcdadb2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48a68082c7c144f38c143ab915169a7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4abd1a2e0e584a9f8b1d84f74a4f23bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7952368ec6084469a27c61bfa43c5342","max":8146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dbcf8f3699a495bb0643eab17cea27b","value":8146}},"5a0a004f54454161bc0a72fc40bd5311":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81a80a3ef5b74876bfe4d4342fb9a5b4","placeholder":"â€‹","style":"IPY_MODEL_2fd1230d14fb48f1bfab3237610ff2d5","value":" 548M/548M [00:26&lt;00:00, 23.8MB/s]"}},"5ad758aeffe344a9bcbe49fa225671b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6eb5c08b7d594f36aa1900739151e663":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706408202679485481da12cc439c65a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"727a7c008d89405d825bd24ad290b125":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72bddef17ce7475b884e9b7ec4cf2d1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2da5b9ec1b144375840702623eb01253","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ad758aeffe344a9bcbe49fa225671b1","value":1}},"7880628963764d81b7f02350a1c2f04a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e775795965144e938535b0a6fb54d880","placeholder":"â€‹","style":"IPY_MODEL_db3eaa3328144b1fb2531df2864c7430","value":" 665/665 [00:00&lt;00:00, 15.7kB/s]"}},"7952368ec6084469a27c61bfa43c5342":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eaf2ba083d84df8ac4ad32ce4ed10e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a80a3ef5b74876bfe4d4342fb9a5b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa672fbbe6c40c697d9faa687ac2e20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eb5c08b7d594f36aa1900739151e663","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bed3e0675bf4961adbad59fe5559276","value":124}},"8b59e277cd98427fa5fc58808a2de6e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2dc59c7fa5e44a6864591df27888586","placeholder":"â€‹","style":"IPY_MODEL_0fd9d3313f6c43c9ba23e5ab70cd0213","value":"Downloading (â€¦)lve/main/config.json: 100%"}},"8ff179976b294d78a55c05512de3117f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebd5507dbcb2490985432977aba34797","placeholder":"â€‹","style":"IPY_MODEL_48a68082c7c144f38c143ab915169a7b","value":" 8.15k/8.15k [00:00&lt;00:00, 330kB/s]"}},"99d11e532b7c4bcda7e3d9c19c1b3bd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46a2d31366b546fbb7aef8e9dcdadb2c","placeholder":"â€‹","style":"IPY_MODEL_a654ca3a23b243edb5b8e0a3e7a5c488","value":"Downloading (â€¦)neration_config.json: 100%"}},"9d6c16f00283434db57d86feea4e2eb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0f3f82056bc4dbf9fc36aa07444704a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a654ca3a23b243edb5b8e0a3e7a5c488":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad927445b97942b7a3e6e2c26c607a94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae1fc5bcdfa840efaf51bf505c6fa933":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_727a7c008d89405d825bd24ad290b125","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d1088b3661e4ea397d7aa0bddd30649","value":665}},"b4e89c244bf544d2b6c03c987aea33cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be2c259b7fcd4e309c2e9bd63551e7c7","placeholder":"â€‹","style":"IPY_MODEL_2b8b8c0820cf4f7fa226961d85129d6b","value":"Downloading builder script: 100%"}},"be2c259b7fcd4e309c2e9bd63551e7c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c03b053582484d708d8150ca3d575244":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7537d902cf343d5bed2616b021b88de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8b8fdb2947c45edb6c11cf4f9115979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0532ce3e6dd4409b8a1471ecb421e6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2dc59c7fa5e44a6864591df27888586":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d524cd529a654786a7659e5d6f10eb48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd2377aeab634cbc83441e11e2c8a6c5","placeholder":"â€‹","style":"IPY_MODEL_d0532ce3e6dd4409b8a1471ecb421e6b","value":" 124/124 [00:00&lt;00:00, 6.71kB/s]"}},"db3eaa3328144b1fb2531df2864c7430":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db7b4297d2f54e23b6c1a67cfc44411d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4e89c244bf544d2b6c03c987aea33cf","IPY_MODEL_4abd1a2e0e584a9f8b1d84f74a4f23bd","IPY_MODEL_8ff179976b294d78a55c05512de3117f"],"layout":"IPY_MODEL_c03b053582484d708d8150ca3d575244"}},"e341e084df494c2db150abf75a57894b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99d11e532b7c4bcda7e3d9c19c1b3bd7","IPY_MODEL_8aa672fbbe6c40c697d9faa687ac2e20","IPY_MODEL_d524cd529a654786a7659e5d6f10eb48"],"layout":"IPY_MODEL_2b488c71e9ce434e9af5c2fc4b68355d"}},"e51d668e16b14ee68792b76c651425b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_706408202679485481da12cc439c65a6","placeholder":"â€‹","style":"IPY_MODEL_4308d419d5b4460eb6cbed09ad28f00d","value":"Waiting for wandb.init()...\r"}},"e775795965144e938535b0a6fb54d880":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb2d1996cc3b4256832da78d8b21be03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebd5507dbcb2490985432977aba34797":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efe22bb7e28c4c46af2a7f82dddf0bef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73b2f84da9a4928ab0465094e5ec9cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b59e277cd98427fa5fc58808a2de6e3","IPY_MODEL_ae1fc5bcdfa840efaf51bf505c6fa933","IPY_MODEL_7880628963764d81b7f02350a1c2f04a"],"layout":"IPY_MODEL_c7537d902cf343d5bed2616b021b88de"}},"fd2377aeab634cbc83441e11e2c8a6c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
