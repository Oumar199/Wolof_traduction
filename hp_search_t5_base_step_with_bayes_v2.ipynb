{"cells":[{"cell_type":"markdown","metadata":{"id":"YTsVWwCgLAJl"},"source":["Hyper-parameter search with the Text-To-Text Transformer ü§ñ (Bayes)\n","-----------------------------------\n","\n","We have already tried to fine-tune the Text-To-Text Transformer on the original sentences. Now that we extracted new sentences from the book intituled **Grammaire de Wolof Moderne**, we want to verify if the T5 model will perform better on them than previously. We will use, again, the `Bayesian Hyperparamter Optimization` to search for the best combination of hyperparameter (the best model). The `wandb` library will be used to make a clear evaluation of the model with the following charts `Parallel coordinate` and `Parameter Importance`. After finding the best model, we will take the checkpoints and continue the training in another notebook. Let us dive into the process."]},{"cell_type":"markdown","metadata":{"id":"ibHZ3hipw20S"},"source":["We want to know the best combination of values of the following hyperparameters:\n","\n","- **learning rate** $\\sim Log U(1e-2, 1e-5)$\n","- **weight decay** $\\in \\{0.0, 0.1, 0.2, 0.3, 0.4, 0.5\\}$\n","- **random state** (seed of the data splitting generator) $\\in range(1, 100)$ \n","\n","1. For the translation from French to Wolof\n","\n","  - **fr_char_p** (probability of modifying a character from a French word) $\\sim U(0.0, 0.9)$\n","  - **fr_word_p** (probability of modifying a word from a French sentence) $\\sim U(0.0, 0.9)$\n","\n","2. For the translation from Wolof to French\n","\n","  - **wf_char_p** (probability of modifying a character from a Wolof word) $\\sim U(0.0, 0.9)$\n","  - **fr_word_p** (probability of modifying a word from a Wolof sentence) $\\sim U(0.0, 0.9)$\n","\n","\n","The Bayes method requires to define a metric. We will evaluate the model on the test set, so the metric that we will add in the hyperparameter setting can be either the `cross entropy loss` calculated on the test set or `BLEU` score. Since it is a machine translation, a BLEU score will be more useful as evaluation metric. \n","\n","**Objective**: We will try to `maximize the metric.` For the moment, we want to obtain a `BLEU` score more than `20`."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":304,"status":"ok","timestamp":1683386887756,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"0NmODpFxX2Ik"},"outputs":[],"source":["# let us extend the paths of the system\n","import sys\n","\n","path = \"/content/drive/MyDrive/Memoire/subject2/T5/\"\n","\n","sys.path.extend([path, f\"{path}new_data\"])"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683386888142,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"JqaQuyv3XvHl","outputId":"4f884b49-2c73-4236-8f80-c4076b9ee561"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: WANDB_LOG_MODEL=true\n","env: WANDB_NOTEBOOK_NAME=/content/drive/MyDrive/Memoire/subject2/T5/hp_search_t5_small_step_with_bayes_v2.ipynb\n","env: WANDB_API_KEY=237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\n"]}],"source":["# define wandb environment\n","%env WANDB_LOG_MODEL=true\n","%env WANDB_NOTEBOOK_NAME=/content/drive/MyDrive/Memoire/subject2/T5/hp_search_t5_small_step_with_bayes_v2.ipynb\n","%env WANDB_API_KEY=237a8450cd2568ea1c8e1f8e0400708e79b6b4ee "]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8308,"status":"ok","timestamp":1683386896446,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"rOALYu0I1th2"},"outputs":[],"source":["!pip install -qq wandb --upgrade"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86822,"status":"ok","timestamp":1683386983261,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"YqElKFkPLAJq","outputId":"64652819-203f-4aae-fb10-c22c9ccbbb1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-06 15:29:11.277917: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-06 15:29:13.212505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-05-06 15:29:16.893001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-06 15:29:16.893486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-06 15:29:16.893717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fr-core-news-lg==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.5.0/fr_core_news_lg-3.5.0-py3-none-any.whl (571.8 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-lg==3.5.0) (3.5.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.0.9)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (4.65.0)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.1.1)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.7.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.4.6)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.0.8)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.0.12)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (23.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (67.7.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.27.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.8)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.22.4)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (8.1.9)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.10.7)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.1.2)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.0.4)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (6.3.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.3.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.7)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2022.12.7)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.1.2)\n","\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_lg')\n"]}],"source":["!pip install evaluate -qq\n","!pip install sacrebleu -qq\n","# !pip install optuna -qq\n","!pip install transformers -qq \n","!pip install tokenizers -qq\n","!pip install nlpaug -qq\n","!pip install ray[tune] -qq\n","!python -m spacy download fr_core_news_lg "]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":37869,"status":"ok","timestamp":1683387021125,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"dF37F8_nLAJr"},"outputs":[],"source":["# let us import all necessary libraries\n","from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, T5TokenizerFast, set_seed\n","from wolof_translate.utils.sent_transformers import TransformerSequences\n","from wolof_translate.data.dataset_v2 import T5SentenceDataset\n","from wolof_translate.utils.sent_corrections import *\n","from sklearn.model_selection import train_test_split\n","from nlpaug.augmenter import char as nac\n","from torch.utils.data import DataLoader\n","# from datasets  import load_metric # make pip install evaluate instead\n","# and pip install sacrebleu for instance\n","from functools import partial\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import evaluate\n","import wandb\n","import torch\n"]},{"cell_type":"markdown","metadata":{"id":"ypAj4KXBLAJs"},"source":["We will create two models: \n","\n","- One translating the french corpus to a wolof corpus [french_to_wolof](#french-to-wolof)\n","- One translating the wolof corpus to a french corpus [wolof_to_french](#wolof-to-french)"]},{"cell_type":"markdown","metadata":{"id":"mtgeyZoxLAJs"},"source":["--------------"]},{"cell_type":"markdown","metadata":{"id":"19MVywzSLAJt"},"source":["## French to wolof"]},{"cell_type":"markdown","metadata":{"id":"n4tP0YGyLAJt"},"source":["### Configure dataset üî†"]},{"cell_type":"markdown","metadata":{"id":"e6dLQ3poLAJu"},"source":["We will split the sentences between train (for the model's training), validation (to find the best performance) and test (to make final predictions) sets. The samples added as train, validation and test sets are identified according to `the random state.` We will tune the random state to the groups that guarantee the model's best fitting. In other words, we want the model to identify many training sentences and generalize that learning on the validation sentences. It is not sometimes the case, mainly when using a small dataset like ours. \n","\n","Notice that when continuing to train the model from the checkpoints we will use the train_set plus the validation set. Then we need to save the dataset part which doesn't contain the test set for latter. "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1683387021130,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"GyCZiVSvLAJu"},"outputs":[],"source":["def split_data(random_state: int = 50):\n","  \"\"\"Split data between train, validation and test sets\n","\n","  Args:\n","    random_state (int): the seed of the splitting generator. Defaults to 50\n","  \"\"\"\n","  # load the corpora and split into train and test sets\n","  corpora = pd.read_csv(f\"{path}diagne_sentences/extractions.csv\")\n","\n","  train_set, test_set = train_test_split(corpora, test_size=0.1, random_state=random_state)\n","\n","  # let us save the final training set when performing\n","\n","  train_set, valid_set = train_test_split(train_set, test_size=0.1, random_state=random_state)\n","\n","  train_set.to_csv(f\"{path}diagne_sentences/final_train_set.csv\", index=False)\n","\n","  # let us save the sets\n","  train_set.to_csv(f\"{path}diagne_sentences/train_set.csv\", index=False)\n","\n","  valid_set.to_csv(f\"{path}diagne_sentences/valid_set.csv\", index=False)\n","\n","  test_set.to_csv(f\"{path}diagne_sentences/test_set.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"WahLNKJ0LAJv"},"source":["Let us load the French and Wolof corpora's common tokenizer."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1683387021131,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"QyrikXX6eBPd"},"outputs":[],"source":["# recuperate the tokenizer from a json file\n","tokenizer = T5TokenizerFast(tokenizer_file=f\"{path}wolof_translate/tokenizers/t5_tokenizers/tokenizer_v2.json\")\n"]},{"cell_type":"markdown","metadata":{"id":"d1UTpkFTlXr5"},"source":["The following function will make recuperate the datasets."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1683387021132,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"BIjksuH9LAJv"},"outputs":[],"source":["def recuperate_datasets(fr_char_p: float, fr_word_p: float):\n","\n","  # Create augmentation to add on French sentences\n","  fr_augmentation = TransformerSequences(nac.KeyboardAug(aug_char_p=fr_char_p, aug_word_p=fr_word_p),\n","                                        remove_mark_space, delete_guillemet_space)\n","\n","  # Recuperate the train dataset\n","  train_dataset_aug = T5SentenceDataset(f\"{path}diagne_sentences/train_set.csv\",\n","                                        tokenizer,\n","                                        truncation = True,\n","                                        cp1_transformer = fr_augmentation)\n","\n","  # Recuperate the validation dataset\n","  valid_dataset = T5SentenceDataset(f\"{path}diagne_sentences/valid_set.csv\",\n","                                        tokenizer,\n","                                        truncation = True)\n","  \n","  # Return the datasets\n","  return train_dataset_aug, valid_dataset"]},{"cell_type":"markdown","metadata":{"id":"eLlcsICXpOmj"},"source":["### Configure hyperparameter search ‚öôÔ∏è"]},{"cell_type":"markdown","metadata":{"id":"JR9MwAFQppk0"},"source":["We have to configure the search space, the search method and the metric. "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2123,"status":"ok","timestamp":1683387023215,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"QSNJ1s_ypZWg","outputId":"eb62e6e8-eebd-4e07-ec4d-16ca9e12f55b"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moumar-kane\u001b[0m (\u001b[33moumar-kane-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["Create sweep with ID: 4bfvex0q\n","Sweep URL: https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q\n"]}],"source":["wandb.login(key=\"237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\")\n","\n","# hyperparameters\n","sweep_config = {\n","    'method': 'bayes',\n","    'metric':{\n","          'goal': 'maximize',\n","          'name': 'bleu'\n","      },\n","    'parameters':\n","    {\n","      'epochs': {\n","          'value': 1\n","      },\n","      'batch_size': {\n","          'values': [16, 32] \n","      },\n","      'learning_rate': {\n","          'distribution': 'log_uniform_values',\n","          'min': 1e-6,\n","          'max': 1e-2 \n","      },\n","      'weight_decay': {\n","          'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7] \n","      },\n","     'fr_char_p': {\n","         'min': 0.0,\n","         'max': 1.0 \n","     },\n","     'fr_word_p': {\n","          'min': 0.0,\n","          'max': 1.0 \n","     },\n","     'random_state': {\n","         'values': list(range(1, 80))\n","     }\n","    }\n","}\n","\n","# Initialize the hyperparameter search\n","sweep_id = wandb.sweep(sweep_config, project = \"base-t5-fw-translation-bayes-hpsearch-v2\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0vhzP3IaLAJv"},"source":["### Configure the model and the evaluation function ‚öôÔ∏è"]},{"cell_type":"markdown","metadata":{"id":"Ts_cesDLLAJw"},"source":["Let us recuperate the model and resize the token embeddings.\n","\n","**Note**: In the first training we want to use the t5-small. If we don't obtain good results we will take the t5-base which contains more parameters. See bellow the configuration of the t5-small and the t5-base models, respectively."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":14083,"status":"ok","timestamp":1683387037284,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"6cFW4alLpcb8"},"outputs":[],"source":["small_model_name = 't5-small'\n","base_model_name = 't5-base'\n","\n","# import the small model with its pre-trained weights\n","small_model = AutoModelForSeq2SeqLM.from_pretrained(small_model_name)\n","\n","# import the base model with its pre-trained weights\n","base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1683387037285,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"JTGhq0I3q1qU","outputId":"194bd75f-f252-4053-92e8-346d4911a831"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5Config {\n","  \"_name_or_path\": \"t5-small\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 6,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}"]},"metadata":{},"execution_count":12}],"source":["# print the small configuration\n","small_model.config"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1683387037285,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"Z5jH56DMrLd3","outputId":"ece0d900-6b2f-43c2-b4ba-f7bb7c04053e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5Config {\n","  \"_name_or_path\": \"t5-base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}"]},"metadata":{},"execution_count":13}],"source":["# print the base configuration\n","base_model.config"]},{"cell_type":"markdown","metadata":{"id":"ehutM-8GrSld"},"source":["The small model have the same architecture than the original transformer of Ashish Vaswani, Noam Shazeer, and all. in the article [Attention_is_all_you_need](https://arxiv.org/pdf/1706.03762).\n","\n","The base model contains more parameters since it use 12 heads in place of 8 and, 12 stack decoder layers in place of 6, the number of feed forward features is of 3072 so 1024 more features than the small one and the embedding dimension is of 768 in place of 512. The base model contains exactly 220 millions of parameters which is a huge number. But since it is pre-trained, we can directly make transfer learning with already trained weights. The base model was firstly explained in the article [Text_To_Text_Transformer](https://arxiv.org/pdf/1910.10683). "]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1683387037286,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"CO1jx85eLAJw"},"outputs":[],"source":["def t5_model_init(tokenizer):\n","\n","  # Initialize the model name\n","  model_name = 't5-base'\n","\n","  # import the model with its pre-trained weights\n","  model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","  # resize the token embeddings\n","  model.resize_token_embeddings(len(tokenizer))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"R8I3tm4WLAJx"},"source":["Let us evaluate the predictions with the `bleu` metric. We use a method that we found int the following `HuggingFace` tutorial [translation](https://huggingface.co/docs/transformers/tasks/translation). We will use a class to add more methods if necessary."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1008,"status":"ok","timestamp":1683387038274,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"IerZolDNLAJx"},"outputs":[],"source":["# %%writefile wolof-translate/wolof_translate/utils/evaluation.py\n","from tokenizers import Tokenizer\n","from typing import *\n","import numpy as np\n","import evaluate\n","\n","class TranslationEvaluation:\n","    \n","    def __init__(self, \n","                 tokenizer: Tokenizer,\n","                 decoder: Union[Callable, None] = None,\n","                 metric = evaluate.load('sacrebleu'),\n","                 ):\n","        \n","        self.tokenizer = tokenizer\n","        \n","        self.decoder = decoder\n","        \n","        self.metric = metric\n","    \n","    def postprocess_text(self, preds, labels):\n","        \n","        preds = [pred.strip() for pred in preds]\n","        \n","        labels = [[label.strip()] for label in labels]\n","        \n","        return preds, labels\n","\n","    def compute_metrics(self, eval_preds):\n","\n","        preds, labels = eval_preds\n","\n","        if isinstance(preds, tuple):\n","        \n","            preds = preds[0]\n","        \n","        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","        \n","        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","        decoded_preds, decoded_labels = self.postprocess_text(decoded_preds, decoded_labels)\n","\n","        result = self.metric.compute(predictions=decoded_preds, references=decoded_labels)\n","        \n","        result = {\"bleu\": result[\"score\"]}\n","\n","        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","        \n","        result[\"gen_len\"] = np.mean(prediction_lens)\n","        \n","        result = {k: round(v, 4) for k, v in result.items()}\n","        \n","        return result"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683387038274,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"OEvlO5mtLAJx"},"outputs":[],"source":["# %run wolof-translate/wolof_translate/utils/evaluation.py"]},{"cell_type":"markdown","metadata":{"id":"YtmCXLk29eJu"},"source":["Let us initialize the evaluation object."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683387038274,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"67e2stQk9g-C"},"outputs":[],"source":["evaluation = TranslationEvaluation(tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"xT17hB19LAJy"},"source":["### Searching for the best parameters üïñ"]},{"cell_type":"markdown","metadata":{"id":"XQ5evOG5LAJw"},"source":["Let us define the data collator."]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683387038275,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"SgVN115tLAJw"},"outputs":[],"source":["def data_collator(batch):\n","    \"\"\"Generate a batch of data to provide to trainer\n","\n","    Args:\n","        batch (_type_): The batch\n","\n","    Returns:\n","        dict: A dictionary containing the ids, the attention mask and the labels\n","    \"\"\"\n","    input_ids = torch.stack([b[0].squeeze(0) for b in batch])\n","    \n","    attention_mask = torch.stack([b[1].squeeze(0) for b in batch])\n","    \n","    labels = torch.stack([b[2].squeeze(0) for b in batch])\n","    \n","    return {'input_ids': input_ids, 'attention_mask': attention_mask,\n","            'labels': labels}"]},{"cell_type":"markdown","metadata":{"id":"Ry3DmkBuLAJy"},"source":["Let us initialize the training arguments and search for the best model. The latter will be saved as an artefact inside our `wandb` project."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["5b2ce64b536048489c9d8338ea3f7130","f068973dcbbe45b3aca109cc94f9a560","e8b164fa619044128a3474bcc174432c","efe63bd586c640e0afdfd4b233833b0d","6cb643b5e4e44fa085a3050117b64b14","ac279ea1ccd04943a8542e4998da2dfb","f92c9d0d6dd54f5bbfd08d49c94a0b41","b75d78dbc89c46f89e7525fff5823e84","9afcef7124be4de59fba26b8ba32e9ab","45d96f8c7a394c3a9fe356c933bddc37","42378bb3380a4799b0e5e76ad6f9775a","30ad0c21530e442ea6d680be485bad75","d3af7a32769940e785bb647a71dc8139","e5fd02b4a6374dca85a026ef0d14f5b0","c5e74fa0dd20455b9729e84a549eda00","86418c36a76342dfb9f872a6e20e499e"]},"id":"D_yP2Ny6LAJy","outputId":"ae51aff4-e99a-4de5-971c-2c9621196353"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9o3am2rs with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.12292040263145376\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.18798261447081863\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003035797888444438\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230506_153039-9o3am2rs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/9o3am2rs' target=\"_blank\">deep-sweep-1</a></strong> to <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/9o3am2rs' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/9o3am2rs</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='152' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [151/151 00:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.570300</td>\n","      <td>0.517335</td>\n","      <td>0.508800</td>\n","      <td>6.063700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>‚ñÅ</td></tr><tr><td>eval/gen_len</td><td>‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.5088</td></tr><tr><td>eval/gen_len</td><td>6.0637</td></tr><tr><td>eval/loss</td><td>0.51733</td></tr><tr><td>eval/runtime</td><td>8.1645</td></tr><tr><td>eval/samples_per_second</td><td>32.703</td></tr><tr><td>eval/steps_per_second</td><td>2.082</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>151</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>0.5703</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">deep-sweep-1</strong> at: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/9o3am2rs' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/9o3am2rs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230506_153039-9o3am2rs/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Run 9o3am2rs errored: RuntimeError('[enforce fail at inline_container.cc:337] . unexpected pos 747297152 vs 747297040')\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 9o3am2rs errored: RuntimeError('[enforce fail at inline_container.cc:337] . unexpected pos 747297152 vs 747297040')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 23gog2kq with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.18878758750089888\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.567748128566054\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.074411084913552e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 21\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230506_153240-23gog2kq</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/23gog2kq' target=\"_blank\">ruby-sweep-2</a></strong> to <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/23gog2kq' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/23gog2kq</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='152' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [151/151 00:32, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.463100</td>\n","      <td>2.823335</td>\n","      <td>0.031100</td>\n","      <td>17.640400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2ce64b536048489c9d8338ea3f7130"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>‚ñÅ</td></tr><tr><td>eval/gen_len</td><td>‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0311</td></tr><tr><td>eval/gen_len</td><td>17.6404</td></tr><tr><td>eval/loss</td><td>2.82333</td></tr><tr><td>eval/runtime</td><td>7.3005</td></tr><tr><td>eval/samples_per_second</td><td>36.573</td></tr><tr><td>eval/steps_per_second</td><td>2.329</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>151</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>2.4631</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">ruby-sweep-2</strong> at: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/23gog2kq' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/23gog2kq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230506_153240-23gog2kq/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Run 23gog2kq errored: RuntimeError('File /content/drive/MyDrive/Memoire/subject2/T5//training/bayes_search_results_fw_v2/checkpoint-151/pytorch_model.bin cannot be opened.')\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 23gog2kq errored: RuntimeError('File /content/drive/MyDrive/Memoire/subject2/T5//training/bayes_search_results_fw_v2/checkpoint-151/pytorch_model.bin cannot be opened.')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f7ymlmqa with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.8955748250605376\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.8702889822100995\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.05641916237049e-06\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 41\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230506_153339-f7ymlmqa</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/f7ymlmqa' target=\"_blank\">wise-sweep-3</a></strong> to <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/f7ymlmqa' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/f7ymlmqa</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='77' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [76/76 00:22, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.337500</td>\n","      <td>4.897536</td>\n","      <td>0.087700</td>\n","      <td>18.786500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9afcef7124be4de59fba26b8ba32e9ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>‚ñÅ</td></tr><tr><td>eval/gen_len</td><td>‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.0877</td></tr><tr><td>eval/gen_len</td><td>18.7865</td></tr><tr><td>eval/loss</td><td>4.89754</td></tr><tr><td>eval/runtime</td><td>7.0155</td></tr><tr><td>eval/samples_per_second</td><td>38.058</td></tr><tr><td>eval/steps_per_second</td><td>2.423</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>76</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.3375</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">wise-sweep-3</strong> at: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/f7ymlmqa' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/f7ymlmqa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230506_153339-f7ymlmqa/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Run f7ymlmqa errored: RuntimeError('[enforce fail at inline_container.cc:337] . unexpected pos 64 vs 0')\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run f7ymlmqa errored: RuntimeError('[enforce fail at inline_container.cc:337] . unexpected pos 64 vs 0')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7ouqh0ln with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.2883692365882101\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.2473592446497811\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0035965430127454885\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 29\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230506_153431-7ouqh0ln</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/7ouqh0ln' target=\"_blank\">lucky-sweep-4</a></strong> to <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/7ouqh0ln' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/7ouqh0ln</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">lucky-sweep-4</strong> at: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/7ouqh0ln' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/7ouqh0ln</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230506_153431-7ouqh0ln/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Run 7ouqh0ln errored: OSError(28, 'No space left on device')\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 7ouqh0ln errored: OSError(28, 'No space left on device')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8c578sq0 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.5782074714631498\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.10786159420355323\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.3891029806115398e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 25\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.7\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230506_153441-8c578sq0</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/8c578sq0' target=\"_blank\">neat-sweep-5</a></strong> to <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/8c578sq0' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/8c578sq0</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='77' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [76/76 00:21, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.513600</td>\n","      <td>3.737563</td>\n","      <td>0.156000</td>\n","      <td>18.254700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>‚ñÅ</td></tr><tr><td>eval/gen_len</td><td>‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>0.156</td></tr><tr><td>eval/gen_len</td><td>18.2547</td></tr><tr><td>eval/loss</td><td>3.73756</td></tr><tr><td>eval/runtime</td><td>7.0469</td></tr><tr><td>eval/samples_per_second</td><td>37.889</td></tr><tr><td>eval/steps_per_second</td><td>2.412</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>76</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.5136</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">neat-sweep-5</strong> at: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/8c578sq0' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/8c578sq0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230506_153441-8c578sq0/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Run 8c578sq0 errored: RuntimeError('File /content/drive/MyDrive/Memoire/subject2/T5//training/bayes_search_results_fw_v2/checkpoint-76/pytorch_model.bin cannot be opened.')\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 8c578sq0 errored: RuntimeError('File /content/drive/MyDrive/Memoire/subject2/T5//training/bayes_search_results_fw_v2/checkpoint-76/pytorch_model.bin cannot be opened.')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sq2lduf6 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_char_p: 0.8485418784288574\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfr_word_p: 0.7912855357451397\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005741849087508461\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 47\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230506_153542-sq2lduf6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/sq2lduf6' target=\"_blank\">noble-sweep-6</a></strong> to <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/sweeps/4bfvex0q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/sq2lduf6' target=\"_blank\">https://wandb.ai/oumar-kane-team/base-t5-fw-translation-bayes-hpsearch-v2/runs/sq2lduf6</a>"]},"metadata":{}}],"source":["# %%wandb\n","\n","def train(config = None):\n","\n","  with wandb.init(config = config):\n","\n","    # seed\n","    set_seed(0)\n","\n","    # set sweep configuration\n","    config = wandb.config\n","\n","    # split the data\n","    split_data(config.random_state)\n","\n","    # let us recuperate the datasets\n","    train_dataset, valid_dataset = recuperate_datasets(config.fr_char_p, config.fr_word_p)\n","\n","    # set training arguments\n","    training_args = Seq2SeqTrainingArguments(f\"{path}/training/bayes_search_results_fw_v2\",\n","                                      report_to = f\"wandb\",\n","                                      num_train_epochs=config.epochs,\n","                                      load_best_model_at_end=True,\n","                                      save_strategy=\"epoch\",\n","                                      evaluation_strategy=\"epoch\",\n","                                      logging_strategy = 'epoch',\n","                                      per_device_train_batch_size=config.batch_size, \n","                                      per_device_eval_batch_size=16,\n","                                      learning_rate=config.learning_rate,\n","                                      weight_decay=config.weight_decay,\n","                                      predict_with_generate=True, # we will use predict with generate in order to obtain more valuable test results\n","                                      fp16 = True,\n","                                      )   \n","\n","    # define training loop\n","    trainer = Seq2SeqTrainer(model_init=partial(t5_model_init, tokenizer = train_dataset.tokenizer),\n","                      args=training_args,\n","                      train_dataset=train_dataset, \n","                      eval_dataset=valid_dataset,\n","                      data_collator=data_collator,\n","                      compute_metrics=evaluation.compute_metrics\n","                      )\n","\n","    # start training loop\n","    trainer.train()\n","\n","agent = wandb.agent(sweep_id, train, count = 30)\n"]},{"cell_type":"markdown","metadata":{"id":"u7NPlNlPgRz9"},"source":["------------------"]},{"cell_type":"markdown","metadata":{"id":"DO_49vgmTu8B"},"source":["## Wolof to french"]},{"cell_type":"markdown","metadata":{"id":"8BehHF09W3AK"},"source":["The only thing that we will change is that is this time it is the Wolof sentences that we will provide as inputs and the French sentences, as targets. "]},{"cell_type":"markdown","metadata":{"id":"nYjqfwjzW3AK"},"source":["### Configure dataset üî†"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPjxkXryY15-"},"outputs":[],"source":["def split_data(random_state: int = 50):\n","  \"\"\"Split data between train, validation and test sets\n","\n","  Args:\n","    random_state (int): the seed of the splitting generator. Defaults to 50\n","  \"\"\"\n","  # load the corpora and split into train and test sets\n","  corpora = pd.read_csv(f\"{path}diagne_sentences/extractions.csv\")\n","\n","  train_set, test_set = train_test_split(corpora, test_size=0.1, random_state=random_state)\n","\n","  # let us save the final training set when performing\n","\n","  train_set, valid_set = train_test_split(train_set, test_size=0.1, random_state=random_state)\n","\n","  train_set.to_csv(f\"{path}diagne_sentences/final_train_set.csv\", index=False)\n","\n","  # let us save the sets\n","  train_set.to_csv(f\"{path}diagne_sentences/train_set.csv\", index=False)\n","\n","  valid_set.to_csv(f\"{path}diagne_sentences/valid_set.csv\", index=False)\n","\n","  test_set.to_csv(f\"{path}diagne_sentences/test_set.csv\", index=False)"]},{"cell_type":"code","source":["# recuperate the tokenizer from a json file\n","tokenizer = T5TokenizerFast(tokenizer_file=f\"{path}wolof_translate/tokenizers/t5_tokenizers/tokenizer_v2.json\")"],"metadata":{"id":"41orbv3gLIaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nt7rn_dW3AK"},"outputs":[],"source":["def recuperate_datasets(wf_char_p: float, wf_word_p: float):\n","\n","  # Create augmentation to add on Wolof sentences\n","  wf_augmentation = TransformerSequences(nac.KeyboardAug(aug_char_p=wf_char_p, aug_word_p=wf_word_p),\n","                                        remove_mark_space, delete_guillemet_space)\n","\n","  # Recuperate the train dataset\n","  train_dataset_aug = T5SentenceDataset(f\"{path}diagne_sentences/train_set.csv\",\n","                                        tokenizer,\n","                                        corpus_1 = 'wolof',\n","                                        corpus_2 = 'french',\n","                                        truncation = True,\n","                                        cp1_transformer = wf_augmentation)\n","\n","  # Recuperate the validation dataset\n","  valid_dataset = T5SentenceDataset(f\"{path}diagne_sentences/valid_set.csv\",\n","                                        tokenizer,\n","                                        corpus_1 = 'wolof',\n","                                        corpus_2 = 'french',\n","                                        truncation = True)\n","  \n","  # Return the datasets\n","  return train_dataset_aug, valid_dataset"]},{"cell_type":"markdown","metadata":{"id":"sUt9UGWuW3AL"},"source":["### Configure hyperparameter search ‚öôÔ∏è"]},{"cell_type":"markdown","metadata":{"id":"L64gK2UgW3AL"},"source":["We have to configure the search space and the search method (\"random\" in our case). ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2743,"status":"ok","timestamp":1682856760036,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"m0UqeLmDW3AL","outputId":"96d11bcf-37a7-49a6-9225-5c6db35911db"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moumar-kane\u001b[0m (\u001b[33moumar-kane-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"name":"stdout","output_type":"stream","text":["Create sweep with ID: alygo14y\n","Sweep URL: https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y\n"]}],"source":["wandb.login(key=\"237a8450cd2568ea1c8e1f8e0400708e79b6b4ee\")\n","\n","# hyperparameters\n","sweep_config = {\n","    'method': 'bayes',\n","    'metric':{\n","          'goal': 'maximize',\n","          'name': 'bleu'\n","      },\n","    'parameters':\n","    {\n","      'epochs': {\n","          'value': 1\n","      },\n","      'batch_size': {\n","          'values': [16, 32] \n","      },\n","      'learning_rate': {\n","          'distribution': 'log_uniform_values',\n","          'min': 1e-6,\n","          'max': 1e-2 \n","      },\n","      'weight_decay': {\n","          'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7] \n","      },\n","     'fr_char_p': {\n","         'min': 0.0,\n","         'max': 1.0 \n","     },\n","     'fr_word_p': {\n","          'min': 0.0,\n","          'max': 1.0 \n","     },\n","     'random_state': {\n","         'values': list(range(1, 80))\n","     }\n","    }\n","}\n","\n","# Initialize the hyperparameter search\n","sweep_id = wandb.sweep(sweep_config, project = \"base-t5-wf-translation-bayes-hpsearch-v2\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JM7hEUdsW3AM"},"source":["### Configure the model and the evaluation function ‚öôÔ∏è"]},{"cell_type":"markdown","metadata":{"id":"h0-iQcATW3AM"},"source":["Let us recuperate the model and resize the token embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBaPD_qRW3AM"},"outputs":[],"source":["def t5_model_init(tokenizer):\n","\n","  # Initialize the model name\n","  model_name = 't5-small'\n","\n","  # import the model with its pre-trained weights\n","  model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","  # resize the token embeddings\n","  model.resize_token_embeddings(len(tokenizer))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"U1xTTv_PW3AN"},"source":["Let us evaluate the predictions with the `bleu` metric."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["db7b4297d2f54e23b6c1a67cfc44411d","b4e89c244bf544d2b6c03c987aea33cf","4abd1a2e0e584a9f8b1d84f74a4f23bd","8ff179976b294d78a55c05512de3117f","c03b053582484d708d8150ca3d575244","be2c259b7fcd4e309c2e9bd63551e7c7","2b8b8c0820cf4f7fa226961d85129d6b","7952368ec6084469a27c61bfa43c5342","1dbcf8f3699a495bb0643eab17cea27b","ebd5507dbcb2490985432977aba34797","48a68082c7c144f38c143ab915169a7b"]},"executionInfo":{"elapsed":1550,"status":"ok","timestamp":1682856761583,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"cnPoI-vdW3AN","outputId":"8517895c-ecf5-4d6c-c5a2-29572fdcd47f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db7b4297d2f54e23b6c1a67cfc44411d","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# %%writefile wolof-translate/wolof_translate/utils/evaluation.py\n","from tokenizers import Tokenizer\n","from typing import *\n","import numpy as np\n","import evaluate\n","\n","class TranslationEvaluation:\n","    \n","    def __init__(self, \n","                 tokenizer: Tokenizer,\n","                 decoder: Union[Callable, None] = None,\n","                 metric = evaluate.load('sacrebleu'),\n","                 ):\n","        \n","        self.tokenizer = tokenizer\n","        \n","        self.decoder = decoder\n","        \n","        self.metric = metric\n","    \n","    def postprocess_text(self, preds, labels):\n","        \n","        preds = [pred.strip() for pred in preds]\n","        \n","        labels = [[label.strip()] for label in labels]\n","        \n","        return preds, labels\n","\n","    def compute_metrics(self, eval_preds):\n","\n","        preds, labels = eval_preds\n","\n","        if isinstance(preds, tuple):\n","        \n","            preds = preds[0]\n","        \n","        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","        \n","        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","        decoded_preds, decoded_labels = self.postprocess_text(decoded_preds, decoded_labels)\n","\n","        result = self.metric.compute(predictions=decoded_preds, references=decoded_labels)\n","        \n","        result = {\"bleu\": result[\"score\"]}\n","\n","        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","        \n","        result[\"gen_len\"] = np.mean(prediction_lens)\n","        \n","        result = {k: round(v, 4) for k, v in result.items()}\n","        \n","        return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75UKFiPtW3AN"},"outputs":[],"source":["# %run wolof-translate/wolof_translate/utils/evaluation.py"]},{"cell_type":"markdown","metadata":{"id":"ovar55kYW3AO"},"source":["Let us initialize the evaluation object."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEjuC9_2W3AO"},"outputs":[],"source":["evaluation = TranslationEvaluation(tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"qwsA3gtGW3AO"},"source":["### Searching for the best parameters üïñ"]},{"cell_type":"markdown","metadata":{"id":"YAiR1MvmW3AO"},"source":["Let us define the data collator."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DR6XzHQW3AO"},"outputs":[],"source":["def data_collator(batch):\n","    \"\"\"Generate a batch of data to provide to trainer\n","\n","    Args:\n","        batch (_type_): The batch\n","\n","    Returns:\n","        dict: A dictionary containing the ids, the attention mask and the labels\n","    \"\"\"\n","    input_ids = torch.stack([b[0].squeeze(0) for b in batch])\n","    \n","    attention_mask = torch.stack([b[1].squeeze(0) for b in batch])\n","    \n","    labels = torch.stack([b[2].squeeze(0) for b in batch])\n","    \n","    return {'input_ids': input_ids, 'attention_mask': attention_mask,\n","            'labels': labels}"]},{"cell_type":"markdown","metadata":{"id":"2P1qVBmlW3AP"},"source":["Let us initialize the training arguments and make random search."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f73b2f84da9a4928ab0465094e5ec9cb","8b59e277cd98427fa5fc58808a2de6e3","ae1fc5bcdfa840efaf51bf505c6fa933","7880628963764d81b7f02350a1c2f04a","c7537d902cf343d5bed2616b021b88de","d2dc59c7fa5e44a6864591df27888586","0fd9d3313f6c43c9ba23e5ab70cd0213","727a7c008d89405d825bd24ad290b125","1d1088b3661e4ea397d7aa0bddd30649","e775795965144e938535b0a6fb54d880","db3eaa3328144b1fb2531df2864c7430","01613034172e4b00bee7c1dbc37404ed","27da5478ae3943a3877bd11559c5c82b","05bb4d42d5634732b02ecdad88eb6113","5a0a004f54454161bc0a72fc40bd5311","7eaf2ba083d84df8ac4ad32ce4ed10e7","ad927445b97942b7a3e6e2c26c607a94","3a02f284c2244d4aa8759d7c8caa7dd5","a0f3f82056bc4dbf9fc36aa07444704a","c8b8fdb2947c45edb6c11cf4f9115979","81a80a3ef5b74876bfe4d4342fb9a5b4","2fd1230d14fb48f1bfab3237610ff2d5","e341e084df494c2db150abf75a57894b","99d11e532b7c4bcda7e3d9c19c1b3bd7","8aa672fbbe6c40c697d9faa687ac2e20","d524cd529a654786a7659e5d6f10eb48","2b488c71e9ce434e9af5c2fc4b68355d","46a2d31366b546fbb7aef8e9dcdadb2c","a654ca3a23b243edb5b8e0a3e7a5c488","6eb5c08b7d594f36aa1900739151e663","3bed3e0675bf4961adbad59fe5559276","fd2377aeab634cbc83441e11e2c8a6c5","d0532ce3e6dd4409b8a1471ecb421e6b","440615e853584cf29c16e9393772b1e3","e51d668e16b14ee68792b76c651425b1","2672f8670b704e1584624c4c3307d651","410cfe6ea2494c149bcaa299547162e3","706408202679485481da12cc439c65a6","4308d419d5b4460eb6cbed09ad28f00d","efe22bb7e28c4c46af2a7f82dddf0bef","9d6c16f00283434db57d86feea4e2eb2"]},"executionInfo":{"elapsed":3667664,"status":"ok","timestamp":1682860429233,"user":{"displayName":"Oumar Kane","userId":"17294747353228494883"},"user_tz":0},"id":"o8dXJjfhW3AP","outputId":"7173bdb4-63f5-44d2-a990-2f13ca3a418c"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0u0t6k2 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.702369179262155e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2819068695463206\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.3271474379445852\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121244-a0u0t6k2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">usual-sweep-1</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f73b2f84da9a4928ab0465094e5ec9cb","version_major":2,"version_minor":0},"text/plain":["Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01613034172e4b00bee7c1dbc37404ed","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e341e084df494c2db150abf75a57894b","version_major":2,"version_minor":0},"text/plain":["Downloading (‚Ä¶)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.331400</td>\n","      <td>0.972646</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.97265</td></tr><tr><td>eval/runtime</td><td>2.7358</td></tr><tr><td>eval/samples_per_second</td><td>29.973</td></tr><tr><td>eval/steps_per_second</td><td>6.214</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3314</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.33135</td></tr><tr><td>train/train_runtime</td><td>98.9652</td></tr><tr><td>train/train_samples_per_second</td><td>7.407</td></tr><tr><td>train/train_steps_per_second</td><td>3.708</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">usual-sweep-1</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/a0u0t6k2</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_121244-a0u0t6k2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8p97mqyj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000687378518112751\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.10242928904824668\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.3761238934195836\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121602-8p97mqyj</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">honest-sweep-2</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:40, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.211800</td>\n","      <td>0.902809</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.90281</td></tr><tr><td>eval/runtime</td><td>2.7187</td></tr><tr><td>eval/samples_per_second</td><td>30.162</td></tr><tr><td>eval/steps_per_second</td><td>6.253</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2118</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.21175</td></tr><tr><td>train/train_runtime</td><td>95.0089</td></tr><tr><td>train/train_samples_per_second</td><td>7.715</td></tr><tr><td>train/train_steps_per_second</td><td>3.863</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">honest-sweep-2</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/8p97mqyj</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_121602-8p97mqyj/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cufx9n8t with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.226951404890168e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 70\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.23759176734591644\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.13227163155096622\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_121831-cufx9n8t</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">grateful-sweep-3</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.571300</td>\n","      <td>0.956762</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95676</td></tr><tr><td>eval/runtime</td><td>2.7129</td></tr><tr><td>eval/samples_per_second</td><td>30.226</td></tr><tr><td>eval/steps_per_second</td><td>6.266</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5713</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.57131</td></tr><tr><td>train/train_runtime</td><td>89.3504</td></tr><tr><td>train/train_samples_per_second</td><td>8.204</td></tr><tr><td>train/train_steps_per_second</td><td>2.742</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">grateful-sweep-3</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/cufx9n8t</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_121831-cufx9n8t/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y2zo0avu with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007890211017920526\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2153084724244564\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.03750263309251056\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122053-y2zo0avu</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">misty-sweep-4</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.394700</td>\n","      <td>0.852979</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85298</td></tr><tr><td>eval/runtime</td><td>2.7128</td></tr><tr><td>eval/samples_per_second</td><td>30.227</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>1.3947</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.39468</td></tr><tr><td>train/train_runtime</td><td>81.7228</td></tr><tr><td>train/train_samples_per_second</td><td>8.969</td></tr><tr><td>train/train_steps_per_second</td><td>1.799</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">misty-sweep-4</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/y2zo0avu</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_122053-y2zo0avu/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6zl4nshz with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00013060682353049685\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6581358201308465\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.010288732393246668\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122304-6zl4nshz</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">noble-sweep-5</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.125200</td>\n","      <td>0.843749</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.84375</td></tr><tr><td>eval/runtime</td><td>2.7146</td></tr><tr><td>eval/samples_per_second</td><td>30.207</td></tr><tr><td>eval/steps_per_second</td><td>6.262</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1252</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.12516</td></tr><tr><td>train/train_runtime</td><td>96.13</td></tr><tr><td>train/train_samples_per_second</td><td>7.625</td></tr><tr><td>train/train_steps_per_second</td><td>3.818</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">noble-sweep-5</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6zl4nshz</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_122304-6zl4nshz/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lmlh43bi with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.6544061486102166e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.601761705072325\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5485382582443594\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122548-lmlh43bi</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">spring-sweep-6</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.511200</td>\n","      <td>0.959907</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95991</td></tr><tr><td>eval/runtime</td><td>2.7127</td></tr><tr><td>eval/samples_per_second</td><td>30.228</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5112</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5112</td></tr><tr><td>train/train_runtime</td><td>89.39</td></tr><tr><td>train/train_samples_per_second</td><td>8.2</td></tr><tr><td>train/train_steps_per_second</td><td>2.741</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">spring-sweep-6</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/lmlh43bi</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_122548-lmlh43bi/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b3709lrr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.01812368676995e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.3414514505517595\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.06590909422021479\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_122808-b3709lrr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">worldly-sweep-7</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.298400</td>\n","      <td>0.943387</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.94339</td></tr><tr><td>eval/runtime</td><td>2.7141</td></tr><tr><td>eval/samples_per_second</td><td>30.212</td></tr><tr><td>eval/steps_per_second</td><td>6.264</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2984</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.2984</td></tr><tr><td>train/train_runtime</td><td>88.4049</td></tr><tr><td>train/train_samples_per_second</td><td>8.291</td></tr><tr><td>train/train_steps_per_second</td><td>2.771</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">worldly-sweep-7</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/b3709lrr</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_122808-b3709lrr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ixh1wkga with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.665404061522188e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2025899023149373\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.30403171896970477\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123025-ixh1wkga</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">giddy-sweep-8</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.600400</td>\n","      <td>0.898786</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89879</td></tr><tr><td>eval/runtime</td><td>2.7076</td></tr><tr><td>eval/samples_per_second</td><td>30.285</td></tr><tr><td>eval/steps_per_second</td><td>6.279</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6004</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.60037</td></tr><tr><td>train/train_runtime</td><td>83.0477</td></tr><tr><td>train/train_samples_per_second</td><td>8.826</td></tr><tr><td>train/train_steps_per_second</td><td>1.77</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">giddy-sweep-8</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ixh1wkga</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123025-ixh1wkga/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yqxwql6m with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009940796140095907\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.5740543904824967\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.2462419315938406\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123241-yqxwql6m</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">rosy-sweep-9</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.284500</td>\n","      <td>0.848199</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.8482</td></tr><tr><td>eval/runtime</td><td>2.7189</td></tr><tr><td>eval/samples_per_second</td><td>30.159</td></tr><tr><td>eval/steps_per_second</td><td>6.253</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.2845</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.28448</td></tr><tr><td>train/train_runtime</td><td>96.6069</td></tr><tr><td>train/train_samples_per_second</td><td>7.587</td></tr><tr><td>train/train_steps_per_second</td><td>3.799</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">rosy-sweep-9</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yqxwql6m</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123241-yqxwql6m/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6z8kvttx with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.136396657280805e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.496992386293468\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.09128048050662484\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"440615e853584cf29c16e9393772b1e3","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668863250000263, max=1.0‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123510-6z8kvttx</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">lemon-sweep-10</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.633700</td>\n","      <td>0.925104</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9251</td></tr><tr><td>eval/runtime</td><td>2.7135</td></tr><tr><td>eval/samples_per_second</td><td>30.22</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6337</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.63375</td></tr><tr><td>train/train_runtime</td><td>82.7991</td></tr><tr><td>train/train_samples_per_second</td><td>8.853</td></tr><tr><td>train/train_steps_per_second</td><td>1.775</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">lemon-sweep-10</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6z8kvttx</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123510-6z8kvttx/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m9sb4aqc with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.292925960874299e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 80\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.1392332134258406\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.33276367556881936\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123730-m9sb4aqc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">resilient-sweep-11</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.377200</td>\n","      <td>0.921299</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9213</td></tr><tr><td>eval/runtime</td><td>2.7224</td></tr><tr><td>eval/samples_per_second</td><td>30.12</td></tr><tr><td>eval/steps_per_second</td><td>6.244</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3772</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.37722</td></tr><tr><td>train/train_runtime</td><td>97.2966</td></tr><tr><td>train/train_samples_per_second</td><td>7.534</td></tr><tr><td>train/train_steps_per_second</td><td>3.772</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">resilient-sweep-11</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/m9sb4aqc</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123730-m9sb4aqc/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jbput8ui with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.444484556126347e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.29893712569494857\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.26117783521919574\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_123958-jbput8ui</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">snowy-sweep-12</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:34, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.432100</td>\n","      <td>0.896062</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89606</td></tr><tr><td>eval/runtime</td><td>2.708</td></tr><tr><td>eval/samples_per_second</td><td>30.281</td></tr><tr><td>eval/steps_per_second</td><td>6.278</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4321</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.43209</td></tr><tr><td>train/train_runtime</td><td>88.9488</td></tr><tr><td>train/train_samples_per_second</td><td>8.241</td></tr><tr><td>train/train_steps_per_second</td><td>2.754</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">snowy-sweep-12</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jbput8ui</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_123958-jbput8ui/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4fwhdrrr with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.5593238990374552e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2943749543935819\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.12398175089457102\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124220-4fwhdrrr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">daily-sweep-13</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:30, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.699900</td>\n","      <td>0.852140</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85214</td></tr><tr><td>eval/runtime</td><td>2.7191</td></tr><tr><td>eval/samples_per_second</td><td>30.157</td></tr><tr><td>eval/steps_per_second</td><td>6.252</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6999</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.69991</td></tr><tr><td>train/train_runtime</td><td>85.2131</td></tr><tr><td>train/train_samples_per_second</td><td>8.602</td></tr><tr><td>train/train_steps_per_second</td><td>1.725</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">daily-sweep-13</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/4fwhdrrr</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_124220-4fwhdrrr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1bz3dbic with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.890480473611398e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2378445346533837\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.4209643755950993\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124438-1bz3dbic</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">eternal-sweep-14</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.483200</td>\n","      <td>0.875917</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.87592</td></tr><tr><td>eval/runtime</td><td>2.7525</td></tr><tr><td>eval/samples_per_second</td><td>29.792</td></tr><tr><td>eval/steps_per_second</td><td>6.176</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4832</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.48315</td></tr><tr><td>train/train_runtime</td><td>90.2171</td></tr><tr><td>train/train_samples_per_second</td><td>8.125</td></tr><tr><td>train/train_steps_per_second</td><td>2.716</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">eternal-sweep-14</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/1bz3dbic</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_124438-1bz3dbic/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ho6ta14m with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002774553527447285\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 40\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6714497099264989\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.03656663081592687\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124701-ho6ta14m</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">kind-sweep-15</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.124700</td>\n","      <td>0.822917</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.82292</td></tr><tr><td>eval/runtime</td><td>2.7172</td></tr><tr><td>eval/samples_per_second</td><td>30.178</td></tr><tr><td>eval/steps_per_second</td><td>6.256</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.1247</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.12474</td></tr><tr><td>train/train_runtime</td><td>96.7926</td></tr><tr><td>train/train_samples_per_second</td><td>7.573</td></tr><tr><td>train/train_steps_per_second</td><td>3.792</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">kind-sweep-15</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/ho6ta14m</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_124701-ho6ta14m/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wmlfiw0r with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003923791647223955\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.06807537344840917\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5604330614348828\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_124934-wmlfiw0r</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">radiant-sweep-16</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.500600</td>\n","      <td>0.949637</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.94964</td></tr><tr><td>eval/runtime</td><td>2.7103</td></tr><tr><td>eval/samples_per_second</td><td>30.255</td></tr><tr><td>eval/steps_per_second</td><td>6.272</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.5006</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5006</td></tr><tr><td>train/train_runtime</td><td>83.6072</td></tr><tr><td>train/train_samples_per_second</td><td>8.767</td></tr><tr><td>train/train_steps_per_second</td><td>1.758</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">radiant-sweep-16</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wmlfiw0r</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_124934-wmlfiw0r/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r8gcrole with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.821341363881095e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 50\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.4377052667800509\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.28337028938356845\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125204-r8gcrole</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">dainty-sweep-17</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:31, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.846200</td>\n","      <td>0.981831</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.98183</td></tr><tr><td>eval/runtime</td><td>2.7136</td></tr><tr><td>eval/samples_per_second</td><td>30.218</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8462</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.8462</td></tr><tr><td>train/train_runtime</td><td>84.9129</td></tr><tr><td>train/train_samples_per_second</td><td>8.632</td></tr><tr><td>train/train_steps_per_second</td><td>1.731</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">dainty-sweep-17</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/r8gcrole</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_125204-r8gcrole/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: phwfj18n with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.811279212646426e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.2317434997460037\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.4361895012572056\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125428-phwfj18n</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">apricot-sweep-18</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.639600</td>\n","      <td>0.980084</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.98008</td></tr><tr><td>eval/runtime</td><td>2.767</td></tr><tr><td>eval/samples_per_second</td><td>29.635</td></tr><tr><td>eval/steps_per_second</td><td>6.144</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6396</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.63955</td></tr><tr><td>train/train_runtime</td><td>83.6783</td></tr><tr><td>train/train_samples_per_second</td><td>8.76</td></tr><tr><td>train/train_steps_per_second</td><td>1.757</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">apricot-sweep-18</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/phwfj18n</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_125428-phwfj18n/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jlqkadbj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010056956001033137\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6390337876205812\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.23792329132405943\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125655-jlqkadbj</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">good-sweep-19</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:29, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.611900</td>\n","      <td>0.873367</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.87337</td></tr><tr><td>eval/runtime</td><td>2.7126</td></tr><tr><td>eval/samples_per_second</td><td>30.23</td></tr><tr><td>eval/steps_per_second</td><td>6.267</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.6119</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.61191</td></tr><tr><td>train/train_runtime</td><td>83.1352</td></tr><tr><td>train/train_samples_per_second</td><td>8.817</td></tr><tr><td>train/train_steps_per_second</td><td>1.768</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">good-sweep-19</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/jlqkadbj</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_125655-jlqkadbj/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6p270685 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.129742665577746e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 20\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.39725467091195105\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5004309074101329\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_125915-6p270685</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">pious-sweep-20</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.459300</td>\n","      <td>0.955068</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.95507</td></tr><tr><td>eval/runtime</td><td>2.7243</td></tr><tr><td>eval/samples_per_second</td><td>30.099</td></tr><tr><td>eval/steps_per_second</td><td>6.24</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4593</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.45931</td></tr><tr><td>train/train_runtime</td><td>89.8845</td></tr><tr><td>train/train_samples_per_second</td><td>8.155</td></tr><tr><td>train/train_steps_per_second</td><td>2.726</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">pious-sweep-20</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/6p270685</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_125915-6p270685/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gcv6axp9 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.252438217932992e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.29046645972247725\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.2600785813543463\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130144-gcv6axp9</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">dutiful-sweep-21</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='367' max='367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [367/367 01:43, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.316900</td>\n","      <td>0.971379</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.97138</td></tr><tr><td>eval/runtime</td><td>2.7496</td></tr><tr><td>eval/samples_per_second</td><td>29.823</td></tr><tr><td>eval/steps_per_second</td><td>6.183</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>367</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3169</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.31693</td></tr><tr><td>train/train_runtime</td><td>97.0731</td></tr><tr><td>train/train_samples_per_second</td><td>7.551</td></tr><tr><td>train/train_steps_per_second</td><td>3.781</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">dutiful-sweep-21</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/gcv6axp9</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_130144-gcv6axp9/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yhyy9e23 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.647196100197014e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.1717366963251063\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.1316624948710261\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130418-yhyy9e23</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">glowing-sweep-22</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:38, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.396900</td>\n","      <td>0.856822</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85682</td></tr><tr><td>eval/runtime</td><td>2.7137</td></tr><tr><td>eval/samples_per_second</td><td>30.217</td></tr><tr><td>eval/steps_per_second</td><td>6.265</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3969</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.3969</td></tr><tr><td>train/train_runtime</td><td>91.6977</td></tr><tr><td>train/train_samples_per_second</td><td>7.994</td></tr><tr><td>train/train_steps_per_second</td><td>2.672</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">glowing-sweep-22</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/yhyy9e23</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_130418-yhyy9e23/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xup68ew4 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.637652455538814e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.677355252029728\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.16163588455481578\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130645-xup68ew4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">devoted-sweep-23</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [147/147 01:28, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.687100</td>\n","      <td>0.952795</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9528</td></tr><tr><td>eval/runtime</td><td>2.7376</td></tr><tr><td>eval/samples_per_second</td><td>29.953</td></tr><tr><td>eval/steps_per_second</td><td>6.21</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6871</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.68711</td></tr><tr><td>train/train_runtime</td><td>83.5213</td></tr><tr><td>train/train_samples_per_second</td><td>8.776</td></tr><tr><td>train/train_steps_per_second</td><td>1.76</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">devoted-sweep-23</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/xup68ew4</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_130645-xup68ew4/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wa2re6yd with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00015372099844614283\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.4593404124892092\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.5384324544438147\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_130904-wa2re6yd</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">deft-sweep-24</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:35, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.402800</td>\n","      <td>0.823874</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.82387</td></tr><tr><td>eval/runtime</td><td>2.7275</td></tr><tr><td>eval/samples_per_second</td><td>30.064</td></tr><tr><td>eval/steps_per_second</td><td>6.233</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4028</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.40277</td></tr><tr><td>train/train_runtime</td><td>89.583</td></tr><tr><td>train/train_samples_per_second</td><td>8.182</td></tr><tr><td>train/train_steps_per_second</td><td>2.735</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">deft-sweep-24</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/wa2re6yd</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_130904-wa2re6yd/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i305ffth with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.284698923411304e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_char_p: 0.6295786463189464\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twf_word_p: 0.6968639258681786\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find training_gpt2_2.ipynb.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230430_131131-i305ffth</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">sunny-sweep-25</a></strong> to <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/sweeps/alygo14y</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [245/245 01:36, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.509300</td>\n","      <td>0.986804</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9868</td></tr><tr><td>eval/runtime</td><td>2.7162</td></tr><tr><td>eval/samples_per_second</td><td>30.189</td></tr><tr><td>eval/steps_per_second</td><td>6.259</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>245</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5093</td></tr><tr><td>train/total_flos</td><td>216590170752000.0</td></tr><tr><td>train/train_loss</td><td>1.5093</td></tr><tr><td>train/train_runtime</td><td>90.604</td></tr><tr><td>train/train_samples_per_second</td><td>8.09</td></tr><tr><td>train/train_steps_per_second</td><td>2.704</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">sunny-sweep-25</strong> at: <a href='https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth' target=\"_blank\">https://wandb.ai/oumar-kane-team/gpt2-wolof-french-translation_bayes1_1/runs/i305ffth</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230430_131131-i305ffth/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# %%wandb\n","\n","def train(config = None):\n","\n","  with wandb.init(config = config):\n","\n","    # seed\n","    set_seed(0)\n","\n","    # set sweep configuration\n","    config = wandb.config\n","\n","    # split the data\n","    split_data(config.random_state)\n","\n","    # let us recuperate the datasets\n","    train_dataset, valid_dataset = recuperate_datasets(config.fr_char_p, config.fr_word_p)\n","\n","    # set training arguments\n","    training_args = Seq2SeqTrainingArguments(f\"{path}/training/bayes_search_results_fw_v2\",\n","                                      report_to = f\"wandb\",\n","                                      num_train_epochs=config.epochs,\n","                                      load_best_model_at_end=True,\n","                                      save_strategy=\"epoch\",\n","                                      evaluation_strategy=\"epoch\",\n","                                      logging_strategy = 'epoch',\n","                                      per_device_train_batch_size=config.batch_size, \n","                                      per_device_eval_batch_size=16,\n","                                      learning_rate=config.learning_rate,\n","                                      weight_decay=config.weight_decay,\n","                                      predict_with_generate=True, # we will use predict with generate in order to obtain more valuable test results\n","                                      fp16 = True,\n","                                      )   \n","\n","    # define training loop\n","    trainer = Seq2SeqTrainer(model_init=partial(t5_model_init, tokenizer = train_dataset.tokenizer),\n","                      args=training_args,\n","                      train_dataset=train_dataset, \n","                      eval_dataset=valid_dataset,\n","                      data_collator=data_collator,\n","                      compute_metrics=evaluation.compute_metrics\n","                      )\n","\n","    # start training loop\n","    trainer.train()\n","\n","agent = wandb.agent(sweep_id, train, count = 30)\n"]},{"cell_type":"markdown","metadata":{"id":"3DIrLmGrW3AP"},"source":["-----------"]},{"cell_type":"markdown","metadata":{"id":"WLu_sR9yW3AQ"},"source":["## Colab download and remove step"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683386883668,"user":{"displayName":"Oumar Kane","userId":"08930403675502989258"},"user_tz":0},"id":"vvqj0ijnW3AQ"},"outputs":[],"source":["import shutil\n","\n","# shutil.rmtree('/content/drive/MyDrive/Memoire/subject2/T5/training/bayes_search_results')\n","shutil.rmtree('wandb')\n","# shutil.make_archive('wandb', 'zip', 'wanbd')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"pytorch1-HleOW5am-py3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01613034172e4b00bee7c1dbc37404ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27da5478ae3943a3877bd11559c5c82b","IPY_MODEL_05bb4d42d5634732b02ecdad88eb6113","IPY_MODEL_5a0a004f54454161bc0a72fc40bd5311"],"layout":"IPY_MODEL_7eaf2ba083d84df8ac4ad32ce4ed10e7"}},"05bb4d42d5634732b02ecdad88eb6113":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0f3f82056bc4dbf9fc36aa07444704a","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8b8fdb2947c45edb6c11cf4f9115979","value":548118077}},"0fd9d3313f6c43c9ba23e5ab70cd0213":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d1088b3661e4ea397d7aa0bddd30649":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1dbcf8f3699a495bb0643eab17cea27b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2672f8670b704e1584624c4c3307d651":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_efe22bb7e28c4c46af2a7f82dddf0bef","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d6c16f00283434db57d86feea4e2eb2","value":1}},"27da5478ae3943a3877bd11559c5c82b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad927445b97942b7a3e6e2c26c607a94","placeholder":"‚Äã","style":"IPY_MODEL_3a02f284c2244d4aa8759d7c8caa7dd5","value":"Downloading pytorch_model.bin: 100%"}},"2b488c71e9ce434e9af5c2fc4b68355d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b8b8c0820cf4f7fa226961d85129d6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fd1230d14fb48f1bfab3237610ff2d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a02f284c2244d4aa8759d7c8caa7dd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bed3e0675bf4961adbad59fe5559276":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"410cfe6ea2494c149bcaa299547162e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4308d419d5b4460eb6cbed09ad28f00d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"440615e853584cf29c16e9393772b1e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e51d668e16b14ee68792b76c651425b1","IPY_MODEL_2672f8670b704e1584624c4c3307d651"],"layout":"IPY_MODEL_410cfe6ea2494c149bcaa299547162e3"}},"46a2d31366b546fbb7aef8e9dcdadb2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48a68082c7c144f38c143ab915169a7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4abd1a2e0e584a9f8b1d84f74a4f23bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7952368ec6084469a27c61bfa43c5342","max":8146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dbcf8f3699a495bb0643eab17cea27b","value":8146}},"5a0a004f54454161bc0a72fc40bd5311":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81a80a3ef5b74876bfe4d4342fb9a5b4","placeholder":"‚Äã","style":"IPY_MODEL_2fd1230d14fb48f1bfab3237610ff2d5","value":" 548M/548M [00:26&lt;00:00, 23.8MB/s]"}},"6eb5c08b7d594f36aa1900739151e663":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706408202679485481da12cc439c65a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"727a7c008d89405d825bd24ad290b125":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7880628963764d81b7f02350a1c2f04a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e775795965144e938535b0a6fb54d880","placeholder":"‚Äã","style":"IPY_MODEL_db3eaa3328144b1fb2531df2864c7430","value":" 665/665 [00:00&lt;00:00, 15.7kB/s]"}},"7952368ec6084469a27c61bfa43c5342":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eaf2ba083d84df8ac4ad32ce4ed10e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a80a3ef5b74876bfe4d4342fb9a5b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa672fbbe6c40c697d9faa687ac2e20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eb5c08b7d594f36aa1900739151e663","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bed3e0675bf4961adbad59fe5559276","value":124}},"8b59e277cd98427fa5fc58808a2de6e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2dc59c7fa5e44a6864591df27888586","placeholder":"‚Äã","style":"IPY_MODEL_0fd9d3313f6c43c9ba23e5ab70cd0213","value":"Downloading (‚Ä¶)lve/main/config.json: 100%"}},"8ff179976b294d78a55c05512de3117f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebd5507dbcb2490985432977aba34797","placeholder":"‚Äã","style":"IPY_MODEL_48a68082c7c144f38c143ab915169a7b","value":" 8.15k/8.15k [00:00&lt;00:00, 330kB/s]"}},"99d11e532b7c4bcda7e3d9c19c1b3bd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46a2d31366b546fbb7aef8e9dcdadb2c","placeholder":"‚Äã","style":"IPY_MODEL_a654ca3a23b243edb5b8e0a3e7a5c488","value":"Downloading (‚Ä¶)neration_config.json: 100%"}},"9d6c16f00283434db57d86feea4e2eb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0f3f82056bc4dbf9fc36aa07444704a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a654ca3a23b243edb5b8e0a3e7a5c488":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad927445b97942b7a3e6e2c26c607a94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae1fc5bcdfa840efaf51bf505c6fa933":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_727a7c008d89405d825bd24ad290b125","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d1088b3661e4ea397d7aa0bddd30649","value":665}},"b4e89c244bf544d2b6c03c987aea33cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be2c259b7fcd4e309c2e9bd63551e7c7","placeholder":"‚Äã","style":"IPY_MODEL_2b8b8c0820cf4f7fa226961d85129d6b","value":"Downloading builder script: 100%"}},"be2c259b7fcd4e309c2e9bd63551e7c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c03b053582484d708d8150ca3d575244":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7537d902cf343d5bed2616b021b88de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8b8fdb2947c45edb6c11cf4f9115979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0532ce3e6dd4409b8a1471ecb421e6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2dc59c7fa5e44a6864591df27888586":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d524cd529a654786a7659e5d6f10eb48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd2377aeab634cbc83441e11e2c8a6c5","placeholder":"‚Äã","style":"IPY_MODEL_d0532ce3e6dd4409b8a1471ecb421e6b","value":" 124/124 [00:00&lt;00:00, 6.71kB/s]"}},"db3eaa3328144b1fb2531df2864c7430":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db7b4297d2f54e23b6c1a67cfc44411d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4e89c244bf544d2b6c03c987aea33cf","IPY_MODEL_4abd1a2e0e584a9f8b1d84f74a4f23bd","IPY_MODEL_8ff179976b294d78a55c05512de3117f"],"layout":"IPY_MODEL_c03b053582484d708d8150ca3d575244"}},"e341e084df494c2db150abf75a57894b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99d11e532b7c4bcda7e3d9c19c1b3bd7","IPY_MODEL_8aa672fbbe6c40c697d9faa687ac2e20","IPY_MODEL_d524cd529a654786a7659e5d6f10eb48"],"layout":"IPY_MODEL_2b488c71e9ce434e9af5c2fc4b68355d"}},"e51d668e16b14ee68792b76c651425b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_706408202679485481da12cc439c65a6","placeholder":"‚Äã","style":"IPY_MODEL_4308d419d5b4460eb6cbed09ad28f00d","value":"Waiting for wandb.init()...\r"}},"e775795965144e938535b0a6fb54d880":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebd5507dbcb2490985432977aba34797":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efe22bb7e28c4c46af2a7f82dddf0bef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73b2f84da9a4928ab0465094e5ec9cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b59e277cd98427fa5fc58808a2de6e3","IPY_MODEL_ae1fc5bcdfa840efaf51bf505c6fa933","IPY_MODEL_7880628963764d81b7f02350a1c2f04a"],"layout":"IPY_MODEL_c7537d902cf343d5bed2616b021b88de"}},"fd2377aeab634cbc83441e11e2c8a6c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b2ce64b536048489c9d8338ea3f7130":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f068973dcbbe45b3aca109cc94f9a560","IPY_MODEL_e8b164fa619044128a3474bcc174432c"],"layout":"IPY_MODEL_efe63bd586c640e0afdfd4b233833b0d"}},"f068973dcbbe45b3aca109cc94f9a560":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cb643b5e4e44fa085a3050117b64b14","placeholder":"‚Äã","style":"IPY_MODEL_ac279ea1ccd04943a8542e4998da2dfb","value":"0.001 MB of 0.020 MB uploaded (0.000 MB deduped)\r"}},"e8b164fa619044128a3474bcc174432c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f92c9d0d6dd54f5bbfd08d49c94a0b41","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b75d78dbc89c46f89e7525fff5823e84","value":0.054822237209750456}},"efe63bd586c640e0afdfd4b233833b0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cb643b5e4e44fa085a3050117b64b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac279ea1ccd04943a8542e4998da2dfb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f92c9d0d6dd54f5bbfd08d49c94a0b41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b75d78dbc89c46f89e7525fff5823e84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9afcef7124be4de59fba26b8ba32e9ab":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_45d96f8c7a394c3a9fe356c933bddc37","IPY_MODEL_42378bb3380a4799b0e5e76ad6f9775a"],"layout":"IPY_MODEL_30ad0c21530e442ea6d680be485bad75"}},"45d96f8c7a394c3a9fe356c933bddc37":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3af7a32769940e785bb647a71dc8139","placeholder":"‚Äã","style":"IPY_MODEL_e5fd02b4a6374dca85a026ef0d14f5b0","value":"0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"}},"42378bb3380a4799b0e5e76ad6f9775a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5e74fa0dd20455b9729e84a549eda00","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86418c36a76342dfb9f872a6e20e499e","value":1}},"30ad0c21530e442ea6d680be485bad75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3af7a32769940e785bb647a71dc8139":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5fd02b4a6374dca85a026ef0d14f5b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5e74fa0dd20455b9729e84a549eda00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86418c36a76342dfb9f872a6e20e499e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}